<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Persistence &bull; Akka Documentation</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="Akka is a toolkit for building highly concurrent, distributed, and resilient message-driven applications for Java and Scala."/>
<link rel="canonical" href="https://doc.akka.io/docs/akka/current/persistence.html"/>
<script type="text/javascript" src="../lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="../lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="../lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="../lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="../css/icons.css"/>
<link rel="stylesheet" type="text/css" href="../css/page.css"/>
<link rel="shortcut icon" href="../images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="../images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="../images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="../images/favicon-16x16.png">
<link rel="manifest" href="../images/manifest.json">
<meta name="msapplication-TileImage" content="../images/mstile-150x150.png">
<meta name="msapplication-TileColor" content="#15a9ce">
<meta name="theme-color" content="#15a9ce">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!--Google Analytics-->
<script type="text/javascript">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', 'UA-21117439-1']);
_gaq.push(['_setDomainName', 'akka.io']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<!--Google Analytics & Marketo-->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-23127719-1', 'lightbend.com', {'allowLinker': true, 'name': 'tsTracker'});
ga('tsTracker.require', 'linker');
ga('tsTracker.linker:autoLink', ['lightbend.com','playframework.com','scala-lang.org','scaladays.org','spray.io','akka.io','scala-sbt.org','scala-ide.org']);
ga('tsTracker.send', 'pageview');
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702');
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>

</head>

<body id="underlay" data-toggler="nav-open">

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="https://akka.io"><img class="logo" src="../images/akka-logo-reverse.svg"></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="../scala/index.html">Akka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 2.5.5
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Languages"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div id="overlay-search-container" class="nav-header-search">
<input id="overlay-search" type="search" class="search" placeholder="Search"/>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="../scala/security/index.html" class="page">Security Announcements</a></li>
  <li><a href="../scala/guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="../scala/general/index.html" class="page">General Concepts</a></li>
  <li><a href="../scala/index-actors.html" class="page">Actors</a>
  <ul>
    <li><a href="../scala/actors.html" class="page">Actors</a></li>
    <li><a href="../scala/typed.html" class="page">Akka Typed</a></li>
    <li><a href="../scala/fault-tolerance.html" class="page">Fault Tolerance</a></li>
    <li><a href="../scala/dispatchers.html" class="page">Dispatchers</a></li>
    <li><a href="../scala/mailboxes.html" class="page">Mailboxes</a></li>
    <li><a href="../scala/routing.html" class="page">Routing</a></li>
    <li><a href="../scala/fsm.html" class="page">FSM</a></li>
    <li><a href="../scala/persistence.html#persistence" class="active page">Persistence</a>
    <ul>
      <li><a href="../scala/persistence.html#dependencies" class="header">Dependencies</a></li>
      <li><a href="../scala/persistence.html#architecture" class="header">Architecture</a></li>
      <li><a href="../scala/persistence.html#event-sourcing" class="header">Event sourcing</a></li>
      <li><a href="../scala/persistence.html#snapshots" class="header">Snapshots</a></li>
      <li><a href="../scala/persistence.html#at-least-once-delivery" class="header">At-Least-Once Delivery</a></li>
      <li><a href="../scala/persistence.html#event-adapters" class="header">Event Adapters</a></li>
      <li><a href="../scala/persistence.html#persistent-fsm" class="header">Persistent FSM</a></li>
      <li><a href="../scala/persistence.html#periodical-snapshot-by-snapshot-after" class="header">Periodical snapshot by snapshot-after</a></li>
      <li><a href="../scala/persistence.html#storage-plugins" class="header">Storage plugins</a></li>
      <li><a href="../scala/persistence.html#pre-packaged-plugins" class="header">Pre-packaged plugins</a></li>
      <li><a href="../scala/persistence.html#custom-serialization" class="header">Custom serialization</a></li>
      <li><a href="../scala/persistence.html#testing" class="header">Testing</a></li>
      <li><a href="../scala/persistence.html#configuration" class="header">Configuration</a></li>
      <li><a href="../scala/persistence.html#multiple-persistence-plugin-configurations" class="header">Multiple persistence plugin configurations</a></li>
    </ul></li>
    <li><a href="../scala/persistence-schema-evolution.html" class="page">Persistence - Schema Evolution</a></li>
    <li><a href="../scala/persistence-query.html" class="page">Persistence Query</a></li>
    <li><a href="../scala/persistence-query-leveldb.html" class="page">Persistence Query for LevelDB</a></li>
    <li><a href="../scala/testing.html" class="page">Testing Actor Systems</a></li>
    <li><a href="../scala/typed-actors.html" class="page">Typed Actors</a></li>
  </ul></li>
  <li><a href="../scala/index-network.html" class="page">Networking</a></li>
  <li><a href="../scala/stream/index.html" class="page">Streams</a></li>
  <li><a href="../scala/index-futures.html" class="page">Futures and Agents</a></li>
  <li><a href="../scala/index-utilities.html" class="page">Utilities</a></li>
  <li><a href="../scala/common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="../scala/howto.html" class="page">HowTo: Common Patterns</a></li>
  <li><a href="../scala/project/index.html" class="page">Project Information</a></li>
  <li><a href="../scala/additional/index.html" class="page">Additional Information</a></li>
</ul>
</nav>
</div>
</header>

<aside class="show-for-large">
<header class="nav-header fixed-sidebar-header">
<div class="nav-header-title">
<h1><a href="../scala/index.html">Akka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 2.5.5
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Languages"><option class="group" value="group-scala">Scala</option><option class="group" value="group-java">Java</option></select>
</div>
<div class="nav-header-search">
<input id="search" type="search" class="search" placeholder="Search"/>
</div>
</header>
<nav class="site-nav fixed-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="../scala/security/index.html" class="page">Security Announcements</a></li>
  <li><a href="../scala/guide/index.html" class="page">Getting Started Guide</a></li>
  <li><a href="../scala/general/index.html" class="page">General Concepts</a></li>
  <li><a href="../scala/index-actors.html" class="page">Actors</a>
  <ul>
    <li><a href="../scala/actors.html" class="page">Actors</a></li>
    <li><a href="../scala/typed.html" class="page">Akka Typed</a></li>
    <li><a href="../scala/fault-tolerance.html" class="page">Fault Tolerance</a></li>
    <li><a href="../scala/dispatchers.html" class="page">Dispatchers</a></li>
    <li><a href="../scala/mailboxes.html" class="page">Mailboxes</a></li>
    <li><a href="../scala/routing.html" class="page">Routing</a></li>
    <li><a href="../scala/fsm.html" class="page">FSM</a></li>
    <li><a href="../scala/persistence.html#persistence" class="active page">Persistence</a>
    <ul>
      <li><a href="../scala/persistence.html#dependencies" class="header">Dependencies</a></li>
      <li><a href="../scala/persistence.html#architecture" class="header">Architecture</a></li>
      <li><a href="../scala/persistence.html#event-sourcing" class="header">Event sourcing</a></li>
      <li><a href="../scala/persistence.html#snapshots" class="header">Snapshots</a></li>
      <li><a href="../scala/persistence.html#at-least-once-delivery" class="header">At-Least-Once Delivery</a></li>
      <li><a href="../scala/persistence.html#event-adapters" class="header">Event Adapters</a></li>
      <li><a href="../scala/persistence.html#persistent-fsm" class="header">Persistent FSM</a></li>
      <li><a href="../scala/persistence.html#periodical-snapshot-by-snapshot-after" class="header">Periodical snapshot by snapshot-after</a></li>
      <li><a href="../scala/persistence.html#storage-plugins" class="header">Storage plugins</a></li>
      <li><a href="../scala/persistence.html#pre-packaged-plugins" class="header">Pre-packaged plugins</a></li>
      <li><a href="../scala/persistence.html#custom-serialization" class="header">Custom serialization</a></li>
      <li><a href="../scala/persistence.html#testing" class="header">Testing</a></li>
      <li><a href="../scala/persistence.html#configuration" class="header">Configuration</a></li>
      <li><a href="../scala/persistence.html#multiple-persistence-plugin-configurations" class="header">Multiple persistence plugin configurations</a></li>
    </ul></li>
    <li><a href="../scala/persistence-schema-evolution.html" class="page">Persistence - Schema Evolution</a></li>
    <li><a href="../scala/persistence-query.html" class="page">Persistence Query</a></li>
    <li><a href="../scala/persistence-query-leveldb.html" class="page">Persistence Query for LevelDB</a></li>
    <li><a href="../scala/testing.html" class="page">Testing Actor Systems</a></li>
    <li><a href="../scala/typed-actors.html" class="page">Typed Actors</a></li>
  </ul></li>
  <li><a href="../scala/index-network.html" class="page">Networking</a></li>
  <li><a href="../scala/stream/index.html" class="page">Streams</a></li>
  <li><a href="../scala/index-futures.html" class="page">Futures and Agents</a></li>
  <li><a href="../scala/index-utilities.html" class="page">Utilities</a></li>
  <li><a href="../scala/common/other-modules.html" class="page">Other Akka modules</a></li>
  <li><a href="../scala/howto.html" class="page">HowTo: Common Patterns</a></li>
  <li><a href="../scala/project/index.html" class="page">Project Information</a></li>
  <li><a href="../scala/additional/index.html" class="page">Additional Information</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer fixed-sidebar-footer">
<a href="https://akka.io"><img class="logo" src="../images/akka-logo-reverse.svg"></a>

</footer>
</aside>

<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">

<article class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#persistence" name="persistence" class="anchor"><span class="anchor-link"></span></a>Persistence</h1>
<p>Akka persistence enables stateful actors to persist their internal state so that it can be recovered when an actor is started, restarted after a JVM crash or by a supervisor, or migrated in a cluster. The key concept behind Akka persistence is that only changes to an actor&rsquo;s internal state are persisted but never its current state directly (except for optional snapshots). These changes are only ever appended to storage, nothing is ever mutated, which allows for very high transaction rates and efficient replication. Stateful actors are recovered by replaying stored changes to these actors from which they can rebuild internal state. This can be either the full history of changes or starting from a snapshot which can dramatically reduce recovery times. Akka persistence also provides point-to-point communication with at-least-once message delivery semantics.</p>
<p>Akka persistence is inspired by and the official replacement of the <a href="https://github.com/eligosource/eventsourced">eventsourced</a> library. It follows the same concepts and architecture of <a href="https://github.com/eligosource/eventsourced">eventsourced</a> but significantly differs on API and implementation level. See also <a href="project/migration-guide-eventsourced-2.3.x.html">migration-eventsourced-2.3</a></p>
<h2><a href="#dependencies" name="dependencies" class="anchor"><span class="anchor-link"></span></a>Dependencies</h2>
<p>Akka persistence is a separate jar file. Make sure that you have the following dependency in your project:</p>
<dl>
  <dt>sbt</dt>
  <dd>
  <pre><code>&quot;com.typesafe.akka&quot; %% &quot;akka-persistence&quot; % &quot;2.5.5&quot;
</code></pre></dd>
  <dt>Gradle</dt>
  <dd>
  <pre><code>compile group: &#39;com.typesafe.akka&#39;, name: &#39;akka-persistence_2.12&#39;, version: &#39;2.5.5&#39;
</code></pre></dd>
  <dt>Maven</dt>
  <dd>
  <pre><code>&lt;dependency&gt;
  &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;
  &lt;artifactId&gt;akka-persistence_2.12&lt;/artifactId&gt;
  &lt;version&gt;2.5.5&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></dd>
</dl>
<p>The Akka persistence extension comes with few built-in persistence plugins, including in-memory heap based journal, local file-system based snapshot-store and LevelDB based journal.</p>
<p>LevelDB based plugins will require the following additional dependency declaration:</p>
<dl>
  <dt>sbt</dt>
  <dd>
  <pre><code>&quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.9&quot;
&quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;
</code></pre></dd>
  <dt>Gradle</dt>
  <dd>
  <pre><code>compile group: &#39;org.iq80.leveldb&#39;, name: &#39;leveldb&#39;, version: &#39;0.9&#39;
compile group: &#39;org.fusesource.leveldbjni&#39;, name: &#39;leveldbjni-all&#39;, version: &#39;1.8&#39; 
</code></pre></dd>
  <dt>Maven</dt>
  <dd>
  <pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.iq80.leveldb&lt;/groupId&gt;
  &lt;artifactId&gt;leveldb&lt;/artifactId&gt;
  &lt;version&gt;0.9&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.fusesource.leveldbjni&lt;/groupId&gt;
  &lt;artifactId&gt;leveldbjni-all&lt;/artifactId&gt;
  &lt;version&gt;1.8&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></dd>
</dl>
<h2><a href="#architecture" name="architecture" class="anchor"><span class="anchor-link"></span></a>Architecture</h2>
<ul>
  <li><span class="group-scala"><code>PersistentActor</code></span><span class="group-java"><code>AbstractPersistentActor</code></span>: Is a persistent, stateful actor. It is able to persist events to a journal and can react to them in a thread-safe manner. It can be used to implement both <em>command</em> as well as <em>event sourced</em> actors. When a persistent actor is started or restarted, journaled messages are replayed to that actor so that it can recover internal state from these messages.</li>
  <li><span class="group-scala"><code>AtLeastOnceDelivery</code></span><span class="group-java"><code>AbstractPersistentActorAtLeastOnceDelivery</code></span>: To send messages with at-least-once delivery semantics to destinations, also in case of sender and receiver JVM crashes.</li>
  <li><code>AsyncWriteJournal</code>: A journal stores the sequence of messages sent to a persistent actor. An application can control which messages are journaled and which are received by the persistent actor without being journaled. Journal maintains <code>highestSequenceNr</code> that is increased on each message. The storage backend of a journal is pluggable. The persistence extension comes with a &ldquo;leveldb&rdquo; journal plugin, which writes to the local filesystem. Replicated journals are available as <a href="https://akka.io/community/">Community plugins</a>.</li>
  <li><em>Snapshot store</em>: A snapshot store persists snapshots of a persistent actor&rsquo;s internal state. Snapshots are used for optimizing recovery times. The storage backend of a snapshot store is pluggable. The persistence extension comes with a &ldquo;local&rdquo; snapshot storage plugin, which writes to the local filesystem.</li>
  <li><em>Event sourcing</em>. Based on the building blocks described above, Akka persistence provides abstractions for the development of event sourced applications (see section <a href="#event-sourcing">Event sourcing</a>) Replicated snapshot stores are available as <a href="https://akka.io/community/">Community plugins</a>.</li>
</ul>
<a id="event-sourcing"></a>
<h2><a href="#event-sourcing" name="event-sourcing" class="anchor"><span class="anchor-link"></span></a>Event sourcing</h2>
<p>The basic idea behind <a href="http://martinfowler.com/eaaDev/EventSourcing.html">Event Sourcing</a> is quite simple. A persistent actor receives a (non-persistent) command which is first validated if it can be applied to the current state. Here validation can mean anything, from simple inspection of a command message&rsquo;s fields up to a conversation with several external services, for example. If validation succeeds, events are generated from the command, representing the effect of the command. These events are then persisted and, after successful persistence, used to change the actor&rsquo;s state. When the persistent actor needs to be recovered, only the persisted events are replayed of which we know that they can be successfully applied. In other words, events cannot fail when being replayed to a persistent actor, in contrast to commands. Event sourced actors may of course also process commands that do not change application state such as query commands for example.</p>
<p>Akka persistence supports event sourcing with the <span class="group-scala"><code>PersistentActor</code> trait</span><span class="group-java"><code>AbstractPersistentActor</code> abstract class</span>. An actor that extends this <span class="group-scala">trait</span><span class="group-java">class</span> uses the <code>persist</code> method to persist and handle events. The behavior of <span class="group-scala">a <code>PersistentActor</code></span><span class="group-java">an <code>AbstractPersistentActor</code></span> is defined by implementing <span class="group-scala"><code>receiveRecover</code></span><span class="group-java"><code>createReceiveRecover</code></span> and <span class="group-scala"><code>receiveCommand</code></span><span class="group-java"><code>createReceive</code></span>. This is demonstrated in the following example.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">import akka.actor._
import akka.persistence._

case class Cmd(data: String)
case class Evt(data: String)

case class ExampleState(events: List[String] = Nil) {
  def updated(evt: Evt): ExampleState = copy(evt.data :: events)
  def size: Int = events.length
  override def toString: String = events.reverse.toString
}

class ExamplePersistentActor extends PersistentActor {
  override def persistenceId = &quot;sample-id-1&quot;

  var state = ExampleState()

  def updateState(event: Evt): Unit =
    state = state.updated(event)

  def numEvents =
    state.size

  val receiveRecover: Receive = {
    case evt: Evt =&gt; updateState(evt)
    case SnapshotOffer(_, snapshot: ExampleState) =&gt; state = snapshot
  }

  val snapShotInterval = 1000
  val receiveCommand: Receive = {
    case Cmd(data) =&gt;
      persist(Evt(s&quot;${data}-${numEvents}&quot;)) { event =&gt;
        updateState(event)
        context.system.eventStream.publish(event)
        if (lastSequenceNr % snapShotInterval == 0 &amp;&amp; lastSequenceNr != 0)
          saveSnapshot(state)
      }
    case &quot;print&quot; =&gt; println(state)
  }

}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java"><br/>import akka.actor.ActorRef;
import akka.actor.ActorSystem;
import akka.actor.Props;
import akka.persistence.AbstractPersistentActor;
import akka.persistence.SnapshotOffer;

import java.io.Serializable;
import java.util.ArrayList;

class Cmd implements Serializable {
    private static final long serialVersionUID = 1L;
    private final String data;

    public Cmd(String data) {
        this.data = data;
    }

    public String getData() {
        return data;
    }
}

class Evt implements Serializable {
    private static final long serialVersionUID = 1L;
    private final String data;

    public Evt(String data) {
        this.data = data;
    }

    public String getData() {
        return data;
    }
}

class ExampleState implements Serializable {
    private static final long serialVersionUID = 1L;
    private final ArrayList&lt;String&gt; events;

    public ExampleState() {
        this(new ArrayList&lt;&gt;());
    }

    public ExampleState(ArrayList&lt;String&gt; events) {
        this.events = events;
    }

    public ExampleState copy() {
        return new ExampleState(new ArrayList&lt;&gt;(events));
    }

    public void update(Evt evt) {
        events.add(evt.getData());
    }

    public int size() {
        return events.size();
    }

    @Override
    public String toString() {
        return events.toString();
    }
}

class ExamplePersistentActor extends AbstractPersistentActor {

    private ExampleState state = new ExampleState();
    private int snapShotInterval = 1000;

    public int getNumEvents() {
        return state.size();
    }

    @Override
    public String persistenceId() { return &quot;sample-id-1&quot;; }

    @Override
    public Receive createReceiveRecover() {
        return receiveBuilder()
            .match(Evt.class, state::update)
            .match(SnapshotOffer.class, ss -&gt; state = (ExampleState) ss.snapshot())
            .build();
    }

    @Override
    public Receive createReceive() {
        return receiveBuilder()
            .match(Cmd.class, c -&gt; {
              final String data = c.getData();
              final Evt evt = new Evt(data + &quot;-&quot; + getNumEvents());
              persist(evt, (Evt e) -&gt; {
                  state.update(e);
                  getContext().getSystem().eventStream().publish(e);
                  if (lastSequenceNr() % snapShotInterval == 0 &amp;&amp; lastSequenceNr() != 0)
                      // IMPORTANT: create a copy of snapshot because ExampleState is mutable
                      saveSnapshot(state.copy());
              });
            })
            .matchEquals(&quot;print&quot;, s -&gt; System.out.println(state))
            .build();
    }
}</code></pre></dd>
</dl>
<p>The example defines two data types, <code>Cmd</code> and <code>Evt</code> to represent commands and events, respectively. The <code>state</code> of the <code>ExamplePersistentActor</code> is a list of persisted event data contained in <code>ExampleState</code>.</p>
<p>The persistent actor&rsquo;s <span class="group-scala"><code>receiveRecover</code></span><span class="group-java"><code>createReceiveRecover</code></span> method defines how <code>state</code> is updated during recovery by handling <code>Evt</code> and <code>SnapshotOffer</code> messages. The persistent actor&rsquo;s <span class="group-scala"><code>receiveCommand</code></span><span class="group-java"><code>createReceive</code></span> method is a command handler. In this example, a command is handled by generating an event which is then persisted and handled. Events are persisted by calling <code>persist</code> with an event (or a sequence of events) as first argument and an event handler as second argument.</p>
<p>The <code>persist</code> method persists events asynchronously and the event handler is executed for successfully persisted events. Successfully persisted events are internally sent back to the persistent actor as individual messages that trigger event handler executions. An event handler may close over persistent actor state and mutate it. The sender of a persisted event is the sender of the corresponding command. This allows event handlers to reply to the sender of a command (not shown).</p>
<p>The main responsibility of an event handler is changing persistent actor state using event data and notifying others about successful state changes by publishing events.</p>
<p>When persisting events with <code>persist</code> it is guaranteed that the persistent actor will not receive further commands between the <code>persist</code> call and the execution(s) of the associated event handler. This also holds for multiple <code>persist</code> calls in context of a single command. Incoming messages are <a href="#internal-stash">stashed</a> until the <code>persist</code> is completed.</p>
<p>If persistence of an event fails, <code>onPersistFailure</code> will be invoked (logging the error by default), and the actor will unconditionally be stopped. If persistence of an event is rejected before it is stored, e.g. due to serialization error, <code>onPersistRejected</code> will be invoked (logging a warning by default) and the actor continues with the next message.</p>
<p>The easiest way to run this example yourself is to download the ready to run <span class="group-scala"><a href="https://example.lightbend.com/v1/download/akka-samples-persistence-scala">Akka Persistence Sample with Scala</a></span> <span class="group-java"><a href="https://example.lightbend.com/v1/download/akka-samples-persistence-java">Akka Persistence Sample with Java</a></span> together with the tutorial. It contains instructions on how to run the <code>PersistentActorExample</code>. The source code of this sample can be found in the <span class="group-scala"><a href="https://github.com/akka/akka-samples/tree/2.5/akka-sample-persistence-scala">Akka Samples Repository</a></span><span class="group-java"><a href="https://github.com/akka/akka-samples/tree/2.5/akka-sample-persistence-java">Akka Samples Repository</a></span>.</p><div class="callout note "><div class="callout-title">Note</div>
<p>It&rsquo;s also possible to switch between different command handlers during normal processing and recovery with <span class="group-scala"><code>context.become()</code></span><span class="group-java"><code>getContext().become()</code></span> and <span class="group-scala"><code>context.unbecome()</code></span><span class="group-java"><code>getContext().unbecome()</code></span>. To get the actor into the same state after recovery you need to take special care to perform the same state transitions with <code>become</code> and <code>unbecome</code> in the <span class="group-scala"><code>receiveRecover</code></span><span class="group-java"><code>createReceiveRecover</code></span> method as you would have done in the command handler. Note that when using <code>become</code> from <span class="group-scala"><code>receiveRecover</code></span><span class="group-java"><code>createReceiveRecover</code></span> it will still only use the <span class="group-scala"><code>receiveRecover</code></span><span class="group-java"><code>createReceiveRecover</code></span> behavior when replaying the events. When replay is completed it will use the new behavior.</p></div>
<a id="persistence-id"></a>
<h3><a href="#identifiers" name="identifiers" class="anchor"><span class="anchor-link"></span></a>Identifiers</h3>
<p>A persistent actor must have an identifier that doesn&rsquo;t change across different actor incarnations. The identifier must be defined with the <code>persistenceId</code> method.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def persistenceId = &quot;my-stable-persistence-id&quot;</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public String persistenceId() {
  return &quot;my-stable-persistence-id&quot;;
}
</code></pre></dd>
</dl><div class="callout note "><div class="callout-title">Note</div>
<p><code>persistenceId</code> must be unique to a given entity in the journal (database table/keyspace). When replaying messages persisted to the journal, you query messages with a <code>persistenceId</code>. So, if two different entities share the same <code>persistenceId</code>, message-replaying behavior is corrupted.</p></div>
<a id="recovery"></a>
<h3><a href="#recovery" name="recovery" class="anchor"><span class="anchor-link"></span></a>Recovery</h3>
<p>By default, a persistent actor is automatically recovered on start and on restart by replaying journaled messages. New messages sent to a persistent actor during recovery do not interfere with replayed messages. They are stashed and received by a persistent actor after recovery phase completes.</p>
<p>The number of concurrent recoveries that can be in progress at the same time is limited to not overload the system and the backend data store. When exceeding the limit the actors will wait until other recoveries have been completed. This is configured by:</p>
<pre><code>akka.persistence.max-concurrent-recoveries = 50
</code></pre><div class="callout note "><div class="callout-title">Note</div>
<p>Accessing the <span class="group-scala"><code>sender()</code></span><span class="group-java">sender with <code>getSender()</code></span> for replayed messages will always result in a <code>deadLetters</code> reference, as the original sender is presumed to be long gone. If you indeed have to notify an actor during recovery in the future, store its <code>ActorPath</code> explicitly in your persisted events.</p></div>
<a id="recovery-custom"></a>
<h4><a href="#recovery-customization" name="recovery-customization" class="anchor"><span class="anchor-link"></span></a>Recovery customization</h4>
<p>Applications may also customise how recovery is performed by returning a customised <code>Recovery</code> object in the <code>recovery</code> method of a <span class="group-scala"><code>PersistentActor</code></span><span class="group-java"><code>AbstractPersistentActor</code></span>,</p>
<p>To skip loading snapshots and replay all events you can use <span class="group-scala"><code>SnapshotSelectionCriteria.None</code></span><span class="group-java"><code>SnapshotSelectionCriteria.none()</code></span>. This can be useful if snapshot serialization format has changed in an incompatible way. It should typically not be used when events have been deleted.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def recovery =
  Recovery(fromSnapshot = SnapshotSelectionCriteria.None)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public Recovery recovery() {
  return Recovery.create(SnapshotSelectionCriteria.none());
}</code></pre></dd>
</dl>
<p>Another possible recovery customization, which can be useful for debugging, is setting an upper bound on the replay, causing the actor to be replayed only up to a certain point &ldquo;in the past&rdquo; (instead of being replayed to its most up to date state). Note that after that it is a bad idea to persist new events because a later recovery will probably be confused by the new events that follow the events that were previously skipped.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def recovery = Recovery(toSequenceNr = 457L)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public Recovery recovery() {
  return Recovery.create(457L);
}</code></pre></dd>
</dl>
<p>Recovery can be disabled by returning <code>Recovery.none()</code> in the <code>recovery</code> method of a <code>PersistentActor</code>:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def recovery = Recovery.none</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public Recovery recovery() {
  return Recovery.none();
}</code></pre></dd>
</dl>
<h4><a href="#recovery-status" name="recovery-status" class="anchor"><span class="anchor-link"></span></a>Recovery status</h4>
<p>A persistent actor can query its own recovery status via the methods</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">def recoveryRunning: Boolean
def recoveryFinished: Boolean</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">public boolean recoveryRunning();
public boolean recoveryFinished();</code></pre></dd>
</dl>
<p>Sometimes there is a need for performing additional initialization when the recovery has completed before processing any other message sent to the persistent actor. The persistent actor will receive a special <code>RecoveryCompleted</code> message right after recovery and before any other received messages.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala"><br/>override def receiveRecover: Receive = {
  case RecoveryCompleted =&gt;
  // perform init after recovery, before any other messages
  //...
  case evt =&gt; //...
}

override def receiveCommand: Receive = {
  case msg =&gt; //...
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyPersistentActor5 extends AbstractPersistentActor {

  @Override public String persistenceId() {
    return &quot;my-stable-persistence-id&quot;;
  }

  @Override public Receive createReceiveRecover() {
    return receiveBuilder().
      match(RecoveryCompleted.class, r -&gt; {
        // perform init after recovery, before any other messages
        // ...
      }).
      match(String.class, this::handleEvent).build();
  }

  @Override public Receive createReceive() {
    return receiveBuilder().
      match(String.class, s -&gt; s.equals(&quot;cmd&quot;),
        s -&gt; persist(&quot;evt&quot;, this::handleEvent)).build();
  }

  private void handleEvent(String event) {
    // update state
    // ...
  }

}</code></pre></dd>
</dl>
<p>The actor will always receive a <code>RecoveryCompleted</code> message, even if there are no events in the journal and the snapshot store is empty, or if it&rsquo;s a new persistent actor with a previously unused <code>persistenceId</code>.</p>
<p>If there is a problem with recovering the state of the actor from the journal, <code>onRecoveryFailure</code> is called (logging the error by default) and the actor will be stopped.</p>
<a id="internal-stash"></a>
<h3><a href="#internal-stash" name="internal-stash" class="anchor"><span class="anchor-link"></span></a>Internal stash</h3>
<p>The persistent actor has a private <a href="actors.html#stash">stash</a> for internally caching incoming messages during <a href="#recovery">recovery</a> or the <code>persist\persistAll</code> method persisting events. You can still use/inherit from the <code>Stash</code> interface. The internal stash cooperates with the normal stash by hooking into <code>unstashAll</code> method and making sure messages are unstashed properly to the internal stash to maintain ordering guarantees.</p>
<p>You should be careful to not send more messages to a persistent actor than it can keep up with, otherwise the number of stashed messages will grow without bounds. It can be wise to protect against <code>OutOfMemoryError</code> by defining a maximum stash capacity in the mailbox configuration:</p>
<pre><code>akka.actor.default-mailbox.stash-capacity=10000
</code></pre>
<p>Note that the stash capacity is per actor. If you have many persistent actors, e.g. when using cluster sharding, you may need to define a small stash capacity to ensure that the total number of stashed messages in the system doesn&rsquo;t consume too much memory. Additionally, the persistent actor defines three strategies to handle failure when the internal stash capacity is exceeded. The default overflow strategy is the <code>ThrowOverflowExceptionStrategy</code>, which discards the current received message and throws a <code>StashOverflowException</code>, causing actor restart if the default supervision strategy is used. You can override the <code>internalStashOverflowStrategy</code> method to return <code>DiscardToDeadLetterStrategy</code> or <code>ReplyToStrategy</code> for any &ldquo;individual&rdquo; persistent actor, or define the &ldquo;default&rdquo; for all persistent actors by providing FQCN, which must be a subclass of <code>StashOverflowStrategyConfigurator</code>, in the persistence configuration:</p>
<pre><code>akka.persistence.internal-stash-overflow-strategy=
  &quot;akka.persistence.ThrowExceptionConfigurator&quot;
</code></pre>
<p>The <code>DiscardToDeadLetterStrategy</code> strategy also has a pre-packaged companion configurator <code>akka.persistence.DiscardConfigurator</code>.</p>
<p>You can also query the default strategy via the Akka persistence extension singleton: </p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre><code>Persistence(context.system).defaultInternalStashOverflowStrategy
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre><code>Persistence.get(getContext().getSystem()).defaultInternalStashOverflowStrategy();
</code></pre></dd>
</dl><div class="callout note "><div class="callout-title">Note</div>
<p>The bounded mailbox should be avoided in the persistent actor, by which the messages come from storage backends may be discarded. You can use bounded stash instead of it.</p></div>
<a id="persist-async"></a>
<h3><a href="#relaxed-local-consistency-requirements-and-high-throughput-use-cases" name="relaxed-local-consistency-requirements-and-high-throughput-use-cases" class="anchor"><span class="anchor-link"></span></a>Relaxed local consistency requirements and high throughput use-cases</h3>
<p>If faced with relaxed local consistency requirements and high throughput demands sometimes <code>PersistentActor</code> and its <code>persist</code> may not be enough in terms of consuming incoming Commands at a high rate, because it has to wait until all Events related to a given Command are processed in order to start processing the next Command. While this abstraction is very useful for most cases, sometimes you may be faced with relaxed requirements about consistency – for example you may want to process commands as fast as you can, assuming that the Event will eventually be persisted and handled properly in the background, retroactively reacting to persistence failures if needed.</p>
<p>The <code>persistAsync</code> method provides a tool for implementing high-throughput persistent actors. It will <em>not</em> stash incoming Commands while the Journal is still working on persisting and/or user code is executing event callbacks.</p>
<p>In the below example, the event callbacks may be called &ldquo;at any time&rdquo;, even after the next Command has been processed. The ordering between events is still guaranteed (&ldquo;evt-b-1&rdquo; will be sent after &ldquo;evt-a-2&rdquo;, which will be sent after &ldquo;evt-a-1&rdquo; etc.).</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MyPersistentActor extends PersistentActor {

  override def persistenceId = &quot;my-stable-persistence-id&quot;

  override def receiveRecover: Receive = {
    case _ =&gt; // handle recovery here
  }

  override def receiveCommand: Receive = {
    case c: String =&gt; {
      sender() ! c
      persistAsync(s&quot;evt-$c-1&quot;) { e =&gt; sender() ! e }
      persistAsync(s&quot;evt-$c-2&quot;) { e =&gt; sender() ! e }
    }
  }
}

// usage
persistentActor ! &quot;a&quot;
persistentActor ! &quot;b&quot;

// possible order of received messages:
// a
// b
// evt-a-1
// evt-a-2
// evt-b-1
// evt-b-2
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyPersistentActor extends AbstractPersistentActor {

  @Override public String persistenceId() {
    return &quot;my-stable-persistence-id&quot;;
  }

  private void handleCommand(String c) {
    getSender().tell(c, getSelf());

    persistAsync(String.format(&quot;evt-%s-1&quot;, c), e -&gt; {
      getSender().tell(e, getSelf());
    });
    persistAsync(String.format(&quot;evt-%s-2&quot;, c), e -&gt; {
      getSender().tell(e, getSelf());
    });
  }

  @Override public Receive createReceiveRecover() {
    return receiveBuilder().
      match(String.class, this::handleCommand).build();
  }

  @Override public Receive createReceive() {
    return receiveBuilder().
      match(String.class, this::handleCommand).build();
  }
}</code></pre></dd>
</dl><div class="callout note "><div class="callout-title">Note</div>
<p>In order to implement the pattern known as &ldquo;<em>command sourcing</em>&rdquo; simply call <span class="group-scala"><code>persistAsync(cmd)(...)</code></span><span class="group-java"><code>persistAsync</code></span> right away on all incoming messages and handle them in the callback.</p></div><div class="callout warning "><div class="callout-title">Warning</div>
<p>The callback will not be invoked if the actor is restarted (or stopped) in between the call to <code>persistAsync</code> and the journal has confirmed the write.</p></div>
<a id="defer"></a>
<h3><a href="#deferring-actions-until-preceding-persist-handlers-have-executed" name="deferring-actions-until-preceding-persist-handlers-have-executed" class="anchor"><span class="anchor-link"></span></a>Deferring actions until preceding persist handlers have executed</h3>
<p>Sometimes when working with <code>persistAsync</code> or <code>persist</code> you may find that it would be nice to define some actions in terms of &lsquo;&lsquo;happens-after the previous <code>persistAsync</code>/<code>persist</code> handlers have been invoked&rsquo;&rsquo;. <code>PersistentActor</code> provides an utility method called <code>deferAsync</code>, which works similarly to <code>persistAsync</code> yet does not persist the passed in event. It is recommended to use it for <em>read</em> operations, and actions which do not have corresponding events in your domain model.</p>
<p>Using this method is very similar to the persist family of methods, yet it does <strong>not</strong> persist the passed in event. It will be kept in memory and used when invoking the handler.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MyPersistentActor extends PersistentActor {

  override def persistenceId = &quot;my-stable-persistence-id&quot;

  override def receiveRecover: Receive = {
    case _ =&gt; // handle recovery here
  }

  override def receiveCommand: Receive = {
    case c: String =&gt; {
      sender() ! c
      persistAsync(s&quot;evt-$c-1&quot;) { e =&gt; sender() ! e }
      persistAsync(s&quot;evt-$c-2&quot;) { e =&gt; sender() ! e }
      deferAsync(s&quot;evt-$c-3&quot;) { e =&gt; sender() ! e }
    }
  }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyPersistentActor extends AbstractPersistentActor {

  @Override public String persistenceId() {
    return &quot;my-stable-persistence-id&quot;;
  }

  private void handleCommand(String c) {
    persistAsync(String.format(&quot;evt-%s-1&quot;, c), e -&gt; {
      getSender().tell(e, getSelf());
    });
    persistAsync(String.format(&quot;evt-%s-2&quot;, c), e -&gt; {
      getSender().tell(e, getSelf());
    });

    deferAsync(String.format(&quot;evt-%s-3&quot;, c), e -&gt; {
      getSender().tell(e, getSelf());
    });
  }

  @Override public Receive createReceiveRecover() {
    return receiveBuilder().
      match(String.class, this::handleCommand).build();
  }

  @Override public Receive createReceive() {
    return receiveBuilder().
      match(String.class, this::handleCommand).build();
  }
}</code></pre></dd>
</dl>
<p>Notice that the <code>sender()</code> is <strong>safe</strong> to access in the handler callback, and will be pointing to the original sender of the command for which this <code>deferAsync</code> handler was called.</p>
<p>The calling side will get the responses in this (guaranteed) order:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">persistentActor ! &quot;a&quot;
persistentActor ! &quot;b&quot;

// order of received messages:
// a
// b
// evt-a-1
// evt-a-2
// evt-a-3
// evt-b-1
// evt-b-2
// evt-b-3
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">final ActorRef persistentActor = system.actorOf(Props.create(MyPersistentActor.class));
persistentActor.tell(&quot;a&quot;, sender);
persistentActor.tell(&quot;b&quot;, sender);

// order of received messages:
// a
// b
// evt-a-1
// evt-a-2
// evt-a-3
// evt-b-1
// evt-b-2
// evt-b-3</code></pre></dd>
</dl>
<p>You can also call <code>deferAsync</code> with <code>persist</code>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MyPersistentActor extends PersistentActor {

  override def persistenceId = &quot;my-stable-persistence-id&quot;

  override def receiveRecover: Receive = {
    case _ =&gt; // handle recovery here
  }

  override def receiveCommand: Receive = {
    case c: String =&gt; {
      sender() ! c
      persist(s&quot;evt-$c-1&quot;) { e =&gt; sender() ! e }
      persist(s&quot;evt-$c-2&quot;) { e =&gt; sender() ! e }
      deferAsync(s&quot;evt-$c-3&quot;) { e =&gt; sender() ! e }
    }
  }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyPersistentActor extends AbstractPersistentActor {

  @Override public String persistenceId() {
    return &quot;my-stable-persistence-id&quot;;
  }

  private void handleCommand(String c) {
    persist(String.format(&quot;evt-%s-1&quot;, c), e -&gt; {
      sender().tell(e, self());
    });
    persist(String.format(&quot;evt-%s-2&quot;, c), e -&gt; {
      sender().tell(e, self());
    });

    deferAsync(String.format(&quot;evt-%s-3&quot;, c), e -&gt; {
      sender().tell(e, self());
    });
  }

  @Override public Receive createReceiveRecover() {
    return receiveBuilder().
            match(String.class, this::handleCommand).build();
  }

  @Override public Receive createReceive() {
    return receiveBuilder().
            match(String.class, this::handleCommand).build();
  }
}</code></pre></dd>
</dl><div class="callout warning "><div class="callout-title">Warning</div>
<p>The callback will not be invoked if the actor is restarted (or stopped) in between the call to <code>deferAsync</code> and the journal has processed and confirmed all preceding writes.</p></div>
<a id="nested-persist-calls"></a>
<h3><a href="#nested-persist-calls" name="nested-persist-calls" class="anchor"><span class="anchor-link"></span></a>Nested persist calls</h3>
<p>It is possible to call <code>persist</code> and <code>persistAsync</code> inside their respective callback blocks and they will properly retain both the thread safety (including the right value of <span class="group-scala"><code>sender()</code></span><span class="group-java"><code>getSender()</code></span>) as well as stashing guarantees.</p>
<p>In general it is encouraged to create command handlers which do not need to resort to nested event persisting, however there are situations where it may be useful. It is important to understand the ordering of callback execution in those situations, as well as their implication on the stashing behaviour (that <code>persist()</code> enforces). In the following example two persist calls are issued, and each of them issues another persist inside its callback:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def receiveCommand: Receive = {
  case c: String =&gt;
    sender() ! c

    persist(s&quot;$c-1-outer&quot;) { outer1 =&gt;
      sender() ! outer1
      persist(s&quot;$c-1-inner&quot;) { inner1 =&gt;
        sender() ! inner1
      }
    }

    persist(s&quot;$c-2-outer&quot;) { outer2 =&gt;
      sender() ! outer2
      persist(s&quot;$c-2-inner&quot;) { inner2 =&gt;
        sender() ! inner2
      }
    }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override public Receive createReceiveRecover() {
  final Procedure&lt;String&gt; replyToSender = event -&gt; getSender().tell(event, getSelf());

  return receiveBuilder()
    .match(String.class, msg -&gt; {
      persist(String.format(&quot;%s-outer-1&quot;, msg), event -&gt; {
        getSender().tell(event, getSelf());
        persist(String.format(&quot;%s-inner-1&quot;, event), replyToSender);
      });

      persist(String.format(&quot;%s-outer-2&quot;, msg), event -&gt; {
        getSender().tell(event, getSelf());
        persist(String.format(&quot;%s-inner-2&quot;, event), replyToSender);
      });
    })
    .build();
}</code></pre></dd>
</dl>
<p>When sending two commands to this <code>PersistentActor</code>, the persist handlers will be executed in the following order:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">persistentActor ! &quot;a&quot;
persistentActor ! &quot;b&quot;

// order of received messages:
// a
// a-outer-1
// a-outer-2
// a-inner-1
// a-inner-2
// and only then process &quot;b&quot;
// b
// b-outer-1
// b-outer-2
// b-inner-1
// b-inner-2
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">persistentActor.tell(&quot;a&quot;, ActorRef.noSender());
persistentActor.tell(&quot;b&quot;, ActorRef.noSender());

// order of received messages:
// a
// a-outer-1
// a-outer-2
// a-inner-1
// a-inner-2
// and only then process &quot;b&quot;
// b
// b-outer-1
// b-outer-2
// b-inner-1
// b-inner-2
</code></pre></dd>
</dl>
<p>First the &ldquo;outer layer&rdquo; of persist calls is issued and their callbacks are applied. After these have successfully completed, the inner callbacks will be invoked (once the events they are persisting have been confirmed to be persisted by the journal). Only after all these handlers have been successfully invoked will the next command be delivered to the persistent Actor. In other words, the stashing of incoming commands that is guaranteed by initially calling <code>persist()</code> on the outer layer is extended until all nested <code>persist</code> callbacks have been handled.</p>
<p>It is also possible to nest <code>persistAsync</code> calls, using the same pattern:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def receiveCommand: Receive = {
  case c: String =&gt;
    sender() ! c
    persistAsync(c + &quot;-outer-1&quot;) { outer =&gt;
      sender() ! outer
      persistAsync(c + &quot;-inner-1&quot;) { inner =&gt; sender() ! inner }
    }
    persistAsync(c + &quot;-outer-2&quot;) { outer =&gt;
      sender() ! outer
      persistAsync(c + &quot;-inner-2&quot;) { inner =&gt; sender() ! inner }
    }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override 
public Receive createReceive() {
    final Procedure&lt;String&gt; replyToSender = event -&gt; getSender().tell(event, getSelf());

  return receiveBuilder()
    .match(String.class, msg -&gt; {
      persistAsync(String.format(&quot;%s-outer-1&quot;, msg ), event -&gt; {
        getSender().tell(event, getSelf());
        persistAsync(String.format(&quot;%s-inner-1&quot;, event), replyToSender);
      });

      persistAsync(String.format(&quot;%s-outer-2&quot;, msg ), event -&gt; {
        getSender().tell(event, getSelf());
        persistAsync(String.format(&quot;%s-inner-1&quot;, event), replyToSender);
      });
    })
    .build();
}</code></pre></dd>
</dl>
<p>In this case no stashing is happening, yet events are still persisted and callbacks are executed in the expected order:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">persistentActor ! &quot;a&quot;
persistentActor ! &quot;b&quot;

// order of received messages:
// a
// b
// a-outer-1
// a-outer-2
// b-outer-1
// b-outer-2
// a-inner-1
// a-inner-2
// b-inner-1
// b-inner-2

// which can be seen as the following causal relationship:
// a -&gt; a-outer-1 -&gt; a-outer-2 -&gt; a-inner-1 -&gt; a-inner-2
// b -&gt; b-outer-1 -&gt; b-outer-2 -&gt; b-inner-1 -&gt; b-inner-2
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">persistentActor.tell(&quot;a&quot;, getSelf());
persistentActor.tell(&quot;b&quot;, getSelf());

// order of received messages:
// a
// b
// a-outer-1
// a-outer-2
// b-outer-1
// b-outer-2
// a-inner-1
// a-inner-2
// b-inner-1
// b-inner-2

// which can be seen as the following causal relationship:
// a -&gt; a-outer-1 -&gt; a-outer-2 -&gt; a-inner-1 -&gt; a-inner-2
// b -&gt; b-outer-1 -&gt; b-outer-2 -&gt; b-inner-1 -&gt; b-inner-2
</code></pre></dd>
</dl>
<p>While it is possible to nest mixed <code>persist</code> and <code>persistAsync</code> with keeping their respective semantics it is not a recommended practice, as it may lead to overly complex nesting.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>While it is possible to nest <code>persist</code> calls within one another, it is <em>not</em> legal call <code>persist</code> from any other Thread than the Actors message processing Thread. For example, it is not legal to call <code>persist</code> from Futures! Doing so will break the guarantees that the persist methods aim to provide. Always call <code>persist</code> and <code>persistAsync</code> from within the Actor&rsquo;s receive block (or methods synchronously invoked from there).</p></div>
<a id="failures"></a>
<h3><a href="#failures" name="failures" class="anchor"><span class="anchor-link"></span></a>Failures</h3>
<p>If persistence of an event fails, <code>onPersistFailure</code> will be invoked (logging the error by default), and the actor will unconditionally be stopped.</p>
<p>The reason that it cannot resume when persist fails is that it is unknown if the event was actually persisted or not, and therefore it is in an inconsistent state. Restarting on persistent failures will most likely fail anyway since the journal is probably unavailable. It is better to stop the actor and after a back-off timeout start it again. The <code>akka.pattern.BackoffSupervisor</code> actor is provided to support such restarts.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val childProps = Props[MyPersistentActor]
val props = BackoffSupervisor.props(
  Backoff.onStop(
    childProps,
    childName = &quot;myActor&quot;,
    minBackoff = 3.seconds,
    maxBackoff = 30.seconds,
    randomFactor = 0.2))
context.actorOf(props, name = &quot;mySupervisor&quot;)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public void preStart() throws Exception {
  final Props childProps = Props.create(MyPersistentActor1.class);
  final Props props = BackoffSupervisor.props(
    childProps,
    &quot;myActor&quot;,
    Duration.create(3, TimeUnit.SECONDS),
    Duration.create(30, TimeUnit.SECONDS),
    0.2);
  getContext().actorOf(props, &quot;mySupervisor&quot;);
  super.preStart();
}</code></pre></dd>
</dl>
<p>If persistence of an event is rejected before it is stored, e.g. due to serialization error, <code>onPersistRejected</code> will be invoked (logging a warning by default), and the actor continues with next message.</p>
<p>If there is a problem with recovering the state of the actor from the journal when the actor is started, <code>onRecoveryFailure</code> is called (logging the error by default), and the actor will be stopped. Note that failure to load snapshot is also treated like this, but you can disable loading of snapshots if you for example know that serialization format has changed in an incompatible way, see <a href="#recovery-custom">Recovery customization</a>.</p>
<h3><a href="#atomic-writes" name="atomic-writes" class="anchor"><span class="anchor-link"></span></a>Atomic writes</h3>
<p>Each event is of course stored atomically, but it is also possible to store several events atomically by using the <code>persistAll</code> or <code>persistAllAsync</code> method. That means that all events passed to that method are stored or none of them are stored if there is an error.</p>
<p>The recovery of a persistent actor will therefore never be done partially with only a subset of events persisted by <em>persistAll</em>.</p>
<p>Some journals may not support atomic writes of several events and they will then reject the <code>persistAll</code> command, i.e. <code>onPersistRejected</code> is called with an exception (typically <code>UnsupportedOperationException</code>).</p>
<a id="batch-writes"></a>
<h3><a href="#batch-writes" name="batch-writes" class="anchor"><span class="anchor-link"></span></a>Batch writes</h3>
<p>In order to optimize throughput when using <code>persistAsync</code>, a persistent actor internally batches events to be stored under high load before writing them to the journal (as a single batch). The batch size is dynamically determined by how many events are emitted during the time of a journal round-trip: after sending a batch to the journal no further batch can be sent before confirmation has been received that the previous batch has been written. Batch writes are never timer-based which keeps latencies at a minimum.</p>
<h3><a href="#message-deletion" name="message-deletion" class="anchor"><span class="anchor-link"></span></a>Message deletion</h3>
<p>It is possible to delete all messages (journaled by a single persistent actor) up to a specified sequence number; Persistent actors may call the <code>deleteMessages</code> method to this end.</p>
<p>Deleting messages in event sourcing based applications is typically either not used at all, or used in conjunction with <a href="#snapshots">snapshotting</a>, i.e. after a snapshot has been successfully stored, a <code>deleteMessages(toSequenceNr)</code> up until the sequence number of the data held by that snapshot can be issued to safely delete the previous events while still having access to the accumulated state during replays - by loading the snapshot.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>If you are using <a href="persistence-query.html">Persistence Query</a>, query results may be missing deleted messages in a journal, depending on how deletions are implemented in the journal plugin. Unless you use a plugin which still shows deleted messages in persistence query results, you have to design your application so that it is not affected by missing messages.</p></div>
<p>The result of the <code>deleteMessages</code> request is signaled to the persistent actor with a <code>DeleteMessagesSuccess</code> message if the delete was successful or a <code>DeleteMessagesFailure</code> message if it failed.</p>
<p>Message deletion doesn&rsquo;t affect the highest sequence number of the journal, even if all messages were deleted from it after <code>deleteMessages</code> invocation.</p>
<h3><a href="#persistence-status-handling" name="persistence-status-handling" class="anchor"><span class="anchor-link"></span></a>Persistence status handling</h3>
<p>Persisting, deleting, and replaying messages can either succeed or fail.</p>
<table>
  <thead>
    <tr>
      <th><strong>Method</strong> </th>
      <th><strong>Success</strong> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>persist</code> / <code>persistAsync</code> </td>
      <td>persist handler invoked</td>
    </tr>
    <tr>
      <td><code>onPersistRejected</code> </td>
      <td>No automatic actions. </td>
    </tr>
    <tr>
      <td><code>recovery</code> </td>
      <td><code>RecoveryCompleted</code> </td>
    </tr>
    <tr>
      <td><code>deleteMessages</code> </td>
      <td><code>DeleteMessagesSuccess</code></td>
    </tr>
  </tbody>
</table>
<p>The most important operations (<code>persist</code> and <code>recovery</code>) have failure handlers modelled as explicit callbacks which the user can override in the <code>PersistentActor</code>. The default implementations of these handlers emit a log message (<code>error</code> for persist/recovery failures, and <code>warning</code> for others), logging the failure cause and information about which message caused the failure.</p>
<p>For critical failures, such as recovery or persisting events failing, the persistent actor will be stopped after the failure handler is invoked. This is because if the underlying journal implementation is signalling persistence failures it is most likely either failing completely or overloaded and restarting right-away and trying to persist the event again will most likely not help the journal recover – as it would likely cause a <a href="https://en.wikipedia.org/wiki/Thundering_herd_problem">Thundering herd problem</a>, as many persistent actors would restart and try to persist their events again. Instead, using a <code>BackoffSupervisor</code> (as described in <a href="#failures">Failures</a>) which implements an exponential-backoff strategy which allows for more breathing room for the journal to recover between restarts of the persistent actor.</p><div class="callout note "><div class="callout-title">Note</div>
<p>Journal implementations may choose to implement a retry mechanism, e.g. such that only after a write fails N number of times a persistence failure is signalled back to the user. In other words, once a journal returns a failure, it is considered <em>fatal</em> by Akka Persistence, and the persistent actor which caused the failure will be stopped.</p>
<p>Check the documentation of the journal implementation you are using for details if/how it is using this technique.</p></div>
<a id="safe-shutdown"></a>
<h3><a href="#safely-shutting-down-persistent-actors" name="safely-shutting-down-persistent-actors" class="anchor"><span class="anchor-link"></span></a>Safely shutting down persistent actors</h3>
<p>Special care should be given when shutting down persistent actors from the outside. With normal Actors it is often acceptable to use the special <a href="actors.html#poison-pill">PoisonPill</a> message to signal to an Actor that it should stop itself once it receives this message – in fact this message is handled automatically by Akka, leaving the target actor no way to refuse stopping itself when given a poison pill.</p>
<p>This can be dangerous when used with <code>PersistentActor</code> due to the fact that incoming commands are <em>stashed</em> while the persistent actor is awaiting confirmation from the Journal that events have been written when <code>persist()</code> was used. Since the incoming commands will be drained from the Actor&rsquo;s mailbox and put into its internal stash while awaiting the confirmation (thus, before calling the persist handlers) the Actor <strong>may receive and (auto)handle the PoisonPill before it processes the other messages which have been put into its stash</strong>, causing a pre-mature shutdown of the Actor.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>Consider using explicit shut-down messages instead of <code>PoisonPill</code> when working with persistent actors.</p></div>
<p>The example below highlights how messages arrive in the Actor&rsquo;s mailbox and how they interact with its internal stashing mechanism when <code>persist()</code> is used. Notice the early stop behaviour that occurs when <code>PoisonPill</code> is used:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">/** Explicit shutdown message */
case object Shutdown

class SafePersistentActor extends PersistentActor {
  override def persistenceId = &quot;safe-actor&quot;

  override def receiveCommand: Receive = {
    case c: String =&gt;
      println(c)
      persist(s&quot;handle-$c&quot;) { println(_) }
    case Shutdown =&gt;
      context.stop(self)
  }

  override def receiveRecover: Receive = {
    case _ =&gt; // handle recovery here
  }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">final class Shutdown {
}

class MyPersistentActor extends AbstractPersistentActor {
  @Override
  public String persistenceId() {
    return &quot;some-persistence-id&quot;;
  }

  @Override
  public Receive createReceive() {
    return receiveBuilder()
      .match(Shutdown.class, shutdown -&gt; {
        getContext().stop(getSelf());
      })
      .match(String.class, msg -&gt; {
        System.out.println(msg);
        persist(&quot;handle-&quot; + msg, e -&gt; System.out.println(e));
      })
      .build();
  }

  @Override
  public Receive createReceiveRecover() {
    return receiveBuilder().matchAny(any -&gt; {}).build();
  }

}</code></pre></dd>
</dl>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">// UN-SAFE, due to PersistentActor&#39;s command stashing:
persistentActor ! &quot;a&quot;
persistentActor ! &quot;b&quot;
persistentActor ! PoisonPill
// order of received messages:
// a
//   # b arrives at mailbox, stashing;        internal-stash = [b]
// PoisonPill is an AutoReceivedMessage, is handled automatically
// !! stop !!
// Actor is stopped without handling `b` nor the `a` handler!</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">// UN-SAFE, due to PersistentActor&#39;s command stashing:
persistentActor.tell(&quot;a&quot;, ActorRef.noSender());
persistentActor.tell(&quot;b&quot;, ActorRef.noSender());
persistentActor.tell(PoisonPill.getInstance(), ActorRef.noSender());
// order of received messages:
// a
//   # b arrives at mailbox, stashing;        internal-stash = [b]
//   # PoisonPill arrives at mailbox, stashing; internal-stash = [b, Shutdown]
// PoisonPill is an AutoReceivedMessage, is handled automatically
// !! stop !!
// Actor is stopped without handling `b` nor the `a` handler!</code></pre></dd>
</dl>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">// SAFE:
persistentActor ! &quot;a&quot;
persistentActor ! &quot;b&quot;
persistentActor ! Shutdown
// order of received messages:
// a
//   # b arrives at mailbox, stashing;        internal-stash = [b]
//   # Shutdown arrives at mailbox, stashing; internal-stash = [b, Shutdown]
// handle-a
//   # unstashing;                            internal-stash = [Shutdown]
// b
// handle-b
//   # unstashing;                            internal-stash = []
// Shutdown
// -- stop --</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">// SAFE:
persistentActor.tell(&quot;a&quot;, ActorRef.noSender());
persistentActor.tell(&quot;b&quot;, ActorRef.noSender());
persistentActor.tell(new Shutdown(), ActorRef.noSender());
// order of received messages:
// a
//   # b arrives at mailbox, stashing;        internal-stash = [b]
//   # Shutdown arrives at mailbox, stashing; internal-stash = [b, Shutdown]
// handle-a
//   # unstashing;                            internal-stash = [Shutdown]
// b
// handle-b
//   # unstashing;                            internal-stash = []
// Shutdown
// -- stop --</code></pre></dd>
</dl>
<a id="replay-filter"></a>
<h3><a href="#replay-filter" name="replay-filter" class="anchor"><span class="anchor-link"></span></a>Replay Filter</h3>
<p>There could be cases where event streams are corrupted and multiple writers (i.e. multiple persistent actor instances) journaled different messages with the same sequence number. In such a case, you can configure how you filter replayed messages from multiple writers, upon recovery.</p>
<p>In your configuration, under the <code>akka.persistence.journal.xxx.replay-filter</code> section (where <code>xxx</code> is your journal plugin id), you can select the replay filter <code>mode</code> from one of the following values:</p>
<ul>
  <li>repair-by-discard-old</li>
  <li>fail</li>
  <li>warn</li>
  <li>off</li>
</ul>
<p>For example, if you configure the replay filter for leveldb plugin, it looks like this:</p>
<pre><code># The replay filter can detect a corrupt event stream by inspecting
# sequence numbers and writerUuid when replaying events.
akka.persistence.journal.leveldb.replay-filter {
  # What the filter should do when detecting invalid events.
  # Supported values:
  # `repair-by-discard-old` : discard events from old writers,
  #                           warning is logged
  # `fail` : fail the replay, error is logged
  # `warn` : log warning but emit events untouched
  # `off` : disable this feature completely
  mode = repair-by-discard-old
}
</code></pre>
<a id="snapshots"></a>
<h2><a href="#snapshots" name="snapshots" class="anchor"><span class="anchor-link"></span></a>Snapshots</h2>
<p>As you model your domain using actors, you may notice that some actors may be prone to accumulating extremely long event logs and experiencing long recovery times. Sometimes, the right approach may be to split out into a set of shorter lived actors. However, when this is not an option, you can use snapshots to reduce recovery times drastically. </p>
<p>Persistent actors can save snapshots of internal state by calling the <code>saveSnapshot</code> method. If saving of a snapshot succeeds, the persistent actor receives a <code>SaveSnapshotSuccess</code> message, otherwise a <code>SaveSnapshotFailure</code> message</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">var state: Any = _

val snapShotInterval = 1000
override def receiveCommand: Receive = {
  case SaveSnapshotSuccess(metadata) =&gt; // ...
  case SaveSnapshotFailure(metadata, reason) =&gt; // ...
  case cmd: String =&gt;
    persist(s&quot;evt-$cmd&quot;) { e =&gt;
      updateState(e)
      if (lastSequenceNr % snapShotInterval == 0 &amp;&amp; lastSequenceNr != 0)
        saveSnapshot(state)
    }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">private Object state;
private int snapShotInterval = 1000;

@Override public Receive createReceive() {
  return receiveBuilder().
    match(SaveSnapshotSuccess.class, ss -&gt; {
      SnapshotMetadata metadata = ss.metadata();
      // ...
    }).
    match(SaveSnapshotFailure.class, sf -&gt; {
      SnapshotMetadata metadata = sf.metadata();
      // ...
    }).
    match(String.class, cmd -&gt; {
      persist( &quot;evt-&quot; + cmd, e -&gt; {
        updateState(e);
        if (lastSequenceNr() % snapShotInterval == 0 &amp;&amp; lastSequenceNr() != 0)
          saveSnapshot(state);
      });
    }).build();
}</code></pre></dd>
</dl>
<p>where <code>metadata</code> is of type <code>SnapshotMetadata</code>:</p>
<pre class="prettyprint"><code class="language-scala">final case class SnapshotMetadata(persistenceId: String, sequenceNr: Long, timestamp: Long = 0L)</code></pre>
<p>During recovery, the persistent actor is offered a previously saved snapshot via a <code>SnapshotOffer</code> message from which it can initialize internal state.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">var state: Any = _

override def receiveRecover: Receive = {
  case SnapshotOffer(metadata, offeredSnapshot) =&gt; state = offeredSnapshot
  case RecoveryCompleted =&gt;
  case event =&gt; // ...
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">private Object state;

@Override public Receive createReceiveRecover() {
  return receiveBuilder().
    match(SnapshotOffer.class, s -&gt; {
      state = s.snapshot();
      // ...
    }).
    match(String.class, s -&gt; {/* ...*/}).build();
}</code></pre></dd>
</dl>
<p>The replayed messages that follow the <code>SnapshotOffer</code> message, if any, are younger than the offered snapshot. They finally recover the persistent actor to its current (i.e. latest) state.</p>
<p>In general, a persistent actor is only offered a snapshot if that persistent actor has previously saved one or more snapshots and at least one of these snapshots matches the <code>SnapshotSelectionCriteria</code> that can be specified for recovery.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def recovery = Recovery(fromSnapshot = SnapshotSelectionCriteria(
  maxSequenceNr = 457L,
  maxTimestamp = System.currentTimeMillis))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public Recovery recovery() {
  return Recovery.create(
    SnapshotSelectionCriteria
      .create(457L, System.currentTimeMillis()));
}</code></pre></dd>
</dl>
<p>If not specified, they default to <span class="group-scala"><code>SnapshotSelectionCriteria.Latest</code></span><span class="group-java"><code>SnapshotSelectionCriteria.latest()</code></span> which selects the latest (= youngest) snapshot. To disable snapshot-based recovery, applications should use <span class="group-scala"><code>SnapshotSelectionCriteria.None</code></span><span class="group-java"><code>SnapshotSelectionCriteria.none()</code></span>. A recovery where no saved snapshot matches the specified <code>SnapshotSelectionCriteria</code> will replay all journaled messages.</p><div class="callout note "><div class="callout-title">Note</div>
<p>In order to use snapshots, a default snapshot-store (<code>akka.persistence.snapshot-store.plugin</code>) must be configured, or the <span class="group-scala"><code>PersistentActor</code></span><span class="group-java">persistent actor</span> can pick a snapshot store explicitly by overriding <span class="group-scala"><code>def snapshotPluginId: String</code></span><span class="group-java"><code>String snapshotPluginId()</code></span>.</p>
<p>Since it is acceptable for some applications to not use any snapshotting, it is legal to not configure a snapshot store. However, Akka will log a warning message when this situation is detected and then continue to operate until an actor tries to store a snapshot, at which point the operation will fail (by replying with an <code>SaveSnapshotFailure</code> for example).</p>
<p>Note that the &ldquo;persistence mode&rdquo; of <a href="cluster-sharding.html">Cluster Sharding</a> makes use of snapshots. If you use that mode, you&rsquo;ll need to define a snapshot store plugin.</p></div>
<h3><a href="#snapshot-deletion" name="snapshot-deletion" class="anchor"><span class="anchor-link"></span></a>Snapshot deletion</h3>
<p>A persistent actor can delete individual snapshots by calling the <code>deleteSnapshot</code> method with the sequence number of when the snapshot was taken.</p>
<p>To bulk-delete a range of snapshots matching <code>SnapshotSelectionCriteria</code>, persistent actors should use the <code>deleteSnapshots</code> method.</p>
<h3><a href="#snapshot-status-handling" name="snapshot-status-handling" class="anchor"><span class="anchor-link"></span></a>Snapshot status handling</h3>
<p>Saving or deleting snapshots can either succeed or fail – this information is reported back to the persistent actor via status messages as illustrated in the following table.</p>
<table>
  <thead>
    <tr>
      <th><strong>Method</strong> </th>
      <th><strong>Success</strong> </th>
      <th><strong>Failure message</strong> </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code>saveSnapshot(Any)</code> </td>
      <td><code>SaveSnapshotSuccess</code> </td>
      <td><code>SaveSnapshotFailure</code> </td>
    </tr>
    <tr>
      <td><code>deleteSnapshot(Long)</code> </td>
      <td><code>DeleteSnapshotSuccess</code> </td>
      <td><code>DeleteSnapshotFailure</code> </td>
    </tr>
    <tr>
      <td><code>deleteSnapshots(SnapshotSelectionCriteria)</code> </td>
      <td><code>DeleteSnapshotsSuccess</code> </td>
      <td><code>DeleteSnapshotsFailure</code></td>
    </tr>
  </tbody>
</table>
<p>If failure messages are left unhandled by the actor, a default warning log message will be logged for each incoming failure message. No default action is performed on the success messages, however you&rsquo;re free to handle them e.g. in order to delete an in memory representation of the snapshot, or in the case of failure to attempt save the snapshot again.</p>
<a id="at-least-once-delivery"></a>
<h2><a href="#at-least-once-delivery" name="at-least-once-delivery" class="anchor"><span class="anchor-link"></span></a>At-Least-Once Delivery</h2>
<p>To send messages with at-least-once delivery semantics to destinations you can <span class="group-scala">mix-in <code>AtLeastOnceDelivery</code> trait to your <code>PersistentActor</code></span><span class="group-java">extend the <code>AbstractPersistentActorWithAtLeastOnceDelivery</code> class instead of <code>AbstractPersistentActor</code></span> on the sending side. It takes care of re-sending messages when they have not been confirmed within a configurable timeout.</p>
<p>The state of the sending actor, including which messages have been sent that have not been confirmed by the recipient must be persistent so that it can survive a crash of the sending actor or JVM. The <span class="group-scala"><code>AtLeastOnceDelivery</code> trait</span><span class="group-java"><code>AbstractPersistentActorWithAtLeastOnceDelivery</code> class</span> does not persist anything by itself. It is your responsibility to persist the intent that a message is sent and that a confirmation has been received.</p><div class="callout note "><div class="callout-title">Note</div>
<p>At-least-once delivery implies that original message sending order is not always preserved, and the destination may receive duplicate messages. Semantics do not match those of a normal <code>ActorRef</code> send operation:</p>
<ul>
  <li>it is not at-most-once delivery</li>
  <li>message order for the same sender–receiver pair is not preserved due to possible resends</li>
  <li>after a crash and restart of the destination messages are still delivered to the new actor incarnation</li>
</ul>
<p>These semantics are similar to what an <code>ActorPath</code> represents (see <a href="actors.html#actor-lifecycle">Actor Lifecycle</a>), therefore you need to supply a path and not a reference when delivering messages. The messages are sent to the path with an actor selection.</p></div>
<p>Use the <code>deliver</code> method to send a message to a destination. Call the <code>confirmDelivery</code> method when the destination has replied with a confirmation message.</p>
<h3><a href="#relationship-between-deliver-and-confirmdelivery" name="relationship-between-deliver-and-confirmdelivery" class="anchor"><span class="anchor-link"></span></a>Relationship between deliver and confirmDelivery</h3>
<p>To send messages to the destination path, use the <code>deliver</code> method after you have persisted the intent to send the message.</p>
<p>The destination actor must send back a confirmation message. When the sending actor receives this confirmation message you should persist the fact that the message was delivered successfully and then call the <code>confirmDelivery</code> method.</p>
<p>If the persistent actor is not currently recovering, the <code>deliver</code> method will send the message to the destination actor. When recovering, messages will be buffered until they have been confirmed using <code>confirmDelivery</code>. Once recovery has completed, if there are outstanding messages that have not been confirmed (during the message replay), the persistent actor will resend these before sending any other messages.</p>
<p>Deliver requires a <code>deliveryIdToMessage</code> function to pass the provided <code>deliveryId</code> into the message so that the correlation between <code>deliver</code> and <code>confirmDelivery</code> is possible. The <code>deliveryId</code> must do the round trip. Upon receipt of the message, the destination actor will send the same<code>deliveryId</code> wrapped in a confirmation message back to the sender. The sender will then use it to call <code>confirmDelivery</code> method to complete the delivery routine.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">import akka.actor.{ Actor, ActorSelection }
import akka.persistence.AtLeastOnceDelivery

case class Msg(deliveryId: Long, s: String)
case class Confirm(deliveryId: Long)

sealed trait Evt
case class MsgSent(s: String) extends Evt
case class MsgConfirmed(deliveryId: Long) extends Evt

class MyPersistentActor(destination: ActorSelection)
  extends PersistentActor with AtLeastOnceDelivery {

  override def persistenceId: String = &quot;persistence-id&quot;

  override def receiveCommand: Receive = {
    case s: String =&gt; persist(MsgSent(s))(updateState)
    case Confirm(deliveryId) =&gt; persist(MsgConfirmed(deliveryId))(updateState)
  }

  override def receiveRecover: Receive = {
    case evt: Evt =&gt; updateState(evt)
  }

  def updateState(evt: Evt): Unit = evt match {
    case MsgSent(s) =&gt;
      deliver(destination)(deliveryId =&gt; Msg(deliveryId, s))

    case MsgConfirmed(deliveryId) =&gt; confirmDelivery(deliveryId)
  }
}

class MyDestination extends Actor {
  def receive = {
    case Msg(deliveryId, s) =&gt;
      // ...
      sender() ! Confirm(deliveryId)
  }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java"><br/>class Msg implements Serializable {
  private static final long serialVersionUID = 1L;
  public final long deliveryId;
  public final String s;

  public Msg(long deliveryId, String s) {
    this.deliveryId = deliveryId;
    this.s = s;
  }
}

class Confirm implements Serializable {
  private static final long serialVersionUID = 1L;
  public final long deliveryId;

  public Confirm(long deliveryId) {
    this.deliveryId = deliveryId;
  }
}


class MsgSent implements Serializable {
  private static final long serialVersionUID = 1L;
  public final String s;

  public MsgSent(String s) {
    this.s = s;
  }
}
class MsgConfirmed implements Serializable {
  private static final long serialVersionUID = 1L;
  public final long deliveryId;

  public MsgConfirmed(long deliveryId) {
    this.deliveryId = deliveryId;
  }
}

class MyPersistentActor extends AbstractPersistentActorWithAtLeastOnceDelivery {
  private final ActorSelection destination;

  public MyPersistentActor(ActorSelection destination) {
      this.destination = destination;
  }

  @Override public String persistenceId() {
    return &quot;persistence-id&quot;;
  }

  @Override
  public Receive createReceive() {
    return receiveBuilder().
      match(String.class, s -&gt; {
        persist(new MsgSent(s), evt -&gt; updateState(evt));
      }).
      match(Confirm.class, confirm -&gt; {
        persist(new MsgConfirmed(confirm.deliveryId), evt -&gt; updateState(evt));
      }).
      build();
  }

  @Override
  public Receive createReceiveRecover() {
    return receiveBuilder().
        match(Object.class, evt -&gt; updateState(evt)).build();
  }

  void updateState(Object event) {
    if (event instanceof MsgSent) {
      final MsgSent evt = (MsgSent) event;
      deliver(destination, deliveryId -&gt; new Msg(deliveryId, evt.s));
    } else if (event instanceof MsgConfirmed) {
      final MsgConfirmed evt = (MsgConfirmed) event;
      confirmDelivery(evt.deliveryId);
    }
  }
}

class MyDestination extends AbstractActor {
  @Override
  public Receive createReceive() {
    return receiveBuilder()
      .match(Msg.class, msg -&gt; {
        // ...
        getSender().tell(new Confirm(msg.deliveryId), getSelf());
      })
      .build();
  }
}</code></pre></dd>
</dl>
<p>The <code>deliveryId</code> generated by the persistence module is a strictly monotonically increasing sequence number without gaps. The same sequence is used for all destinations of the actor, i.e. when sending to multiple destinations the destinations will see gaps in the sequence. It is not possible to use custom <code>deliveryId</code>. However, you can send a custom correlation identifier in the message to the destination. You must then retain a mapping between the internal <code>deliveryId</code> (passed into the <code>deliveryIdToMessage</code> function) and your custom correlation id (passed into the message). You can do this by storing such mapping in a <code>Map(correlationId -&gt; deliveryId)</code> from which you can retrieve the <code>deliveryId</code> to be passed into the <code>confirmDelivery</code> method once the receiver of your message has replied with your custom correlation id.</p>
<p>The <span class="group-scala"><code>AtLeastOnceDelivery</code> trait</span><span class="group-java"><code>AbstractPersistentActorWithAtLeastOnceDelivery</code> class</span> has a state consisting of unconfirmed messages and a sequence number. It does not store this state itself. You must persist events corresponding to the <code>deliver</code> and <code>confirmDelivery</code> invocations from your <code>PersistentActor</code> so that the state can be restored by calling the same methods during the recovery phase of the <code>PersistentActor</code>. Sometimes these events can be derived from other business level events, and sometimes you must create separate events. During recovery, calls to <code>deliver</code> will not send out messages, those will be sent later if no matching <code>confirmDelivery</code> will have been performed.</p>
<p>Support for snapshots is provided by <code>getDeliverySnapshot</code> and <code>setDeliverySnapshot</code>. The <code>AtLeastOnceDeliverySnapshot</code> contains the full delivery state, including unconfirmed messages. If you need a custom snapshot for other parts of the actor state you must also include the <code>AtLeastOnceDeliverySnapshot</code>. It is serialized using protobuf with the ordinary Akka serialization mechanism. It is easiest to include the bytes of the <code>AtLeastOnceDeliverySnapshot</code> as a blob in your custom snapshot.</p>
<p>The interval between redelivery attempts is defined by the <code>redeliverInterval</code> method. The default value can be configured with the <code>akka.persistence.at-least-once-delivery.redeliver-interval</code> configuration key. The method can be overridden by implementation classes to return non-default values.</p>
<p>The maximum number of messages that will be sent at each redelivery burst is defined by the <code>redeliveryBurstLimit</code> method (burst frequency is half of the redelivery interval). If there&rsquo;s a lot of unconfirmed messages (e.g. if the destination is not available for a long time), this helps to prevent an overwhelming amount of messages to be sent at once. The default value can be configured with the <code>akka.persistence.at-least-once-delivery.redelivery-burst-limit</code> configuration key. The method can be overridden by implementation classes to return non-default values.</p>
<p>After a number of delivery attempts a <code>AtLeastOnceDelivery.UnconfirmedWarning</code> message will be sent to <code>self</code>. The re-sending will still continue, but you can choose to call <code>confirmDelivery</code> to cancel the re-sending. The number of delivery attempts before emitting the warning is defined by the <code>warnAfterNumberOfUnconfirmedAttempts</code> method. The default value can be configured with the <code>akka.persistence.at-least-once-delivery.warn-after-number-of-unconfirmed-attempts</code> configuration key. The method can be overridden by implementation classes to return non-default values.</p>
<p>The <span class="group-scala"><code>AtLeastOnceDelivery</code> trait</span><span class="group-java"><code>AbstractPersistentActorWithAtLeastOnceDelivery</code> class</span> holds messages in memory until their successful delivery has been confirmed. The maximum number of unconfirmed messages that the actor is allowed to hold in memory is defined by the <code>maxUnconfirmedMessages</code> method. If this limit is exceed the <code>deliver</code> method will not accept more messages and it will throw <code>AtLeastOnceDelivery.MaxUnconfirmedMessagesExceededException</code>. The default value can be configured with the <code>akka.persistence.at-least-once-delivery.max-unconfirmed-messages</code> configuration key. The method can be overridden by implementation classes to return non-default values.</p>
<a id="event-adapters"></a>
<h2><a href="#event-adapters" name="event-adapters" class="anchor"><span class="anchor-link"></span></a>Event Adapters</h2>
<p>In long running projects using event sourcing sometimes the need arises to detach the data model from the domain model completely.</p>
<p>Event Adapters help in situations where:</p>
<ul>
  <li><strong>Version Migrations</strong> – existing events stored in <em>Version 1</em> should be &ldquo;upcasted&rdquo; to a new <em>Version 2</em> representation, and the process of doing so involves actual code, not just changes on the serialization layer. For these scenarios the <code>toJournal</code> function is usually an identity function, however the <code>fromJournal</code> is implemented as <code>v1.Event=&gt;v2.Event</code>, performing the neccessary mapping inside the fromJournal method. This technique is sometimes refered to as &ldquo;upcasting&rdquo; in other CQRS libraries.</li>
  <li><strong>Separating Domain and Data models</strong> – thanks to EventAdapters it is possible to completely separate the domain model from the model used to persist data in the Journals. For example one may want to use case classes in the domain model, however persist their protocol-buffer (or any other binary serialization format) counter-parts to the Journal. A simple <code>toJournal:MyModel=&gt;MyDataModel</code> and <code>fromJournal:MyDataModel=&gt;MyModel</code> adapter can be used to implement this feature.</li>
  <li><strong>Journal Specialized Data Types</strong> – exposing data types understood by the underlying Journal, for example for data stores which understand JSON it is possible to write an EventAdapter <code>toJournal:Any=&gt;JSON</code> such that the Journal can <em>directly</em> store the json instead of serializing the object to its binary representation.</li>
</ul>
<p>Implementing an EventAdapter is rather stright forward:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MyEventAdapter(system: ExtendedActorSystem) extends EventAdapter {
  override def manifest(event: Any): String =
    &quot;&quot; // when no manifest needed, return &quot;&quot;

  override def toJournal(event: Any): Any =
    event // identity

  override def fromJournal(event: Any, manifest: String): EventSeq =
    EventSeq.single(event) // identity
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyEventAdapter implements EventAdapter {
  @Override
  public String manifest(Object event) {
    return &quot;&quot;; // if no manifest needed, return &quot;&quot;
  }

  @Override
  public Object toJournal(Object event) {
    return event; // identity
  }

  @Override
  public EventSeq fromJournal(Object event, String manifest) {
    return EventSeq.single(event); // identity
  }
}</code></pre></dd>
</dl>
<p>Then in order for it to be used on events coming to and from the journal you must bind it using the below configuration syntax:</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.journal {
  inmem {
    event-adapters {
      tagging        = &quot;docs.persistence.MyTaggingEventAdapter&quot;
      user-upcasting = &quot;docs.persistence.UserUpcastingEventAdapter&quot;
      item-upcasting = &quot;docs.persistence.ItemUpcastingEventAdapter&quot;
    }

    event-adapter-bindings {
      &quot;docs.persistence.Item&quot;        = tagging
      &quot;docs.persistence.TaggedEvent&quot; = tagging
      &quot;docs.persistence.v1.Event&quot;    = [user-upcasting, item-upcasting]
    }
  }
}</code></pre>
<p>It is possible to bind multiple adapters to one class <em>for recovery</em>, in which case the <code>fromJournal</code> methods of all bound adapters will be applied to a given matching event (in order of definition in the configuration). Since each adapter may return from <code>0</code> to <code>n</code> adapted events (called as <code>EventSeq</code>), each adapter can investigate the event and if it should indeed adapt it return the adapted event(s) for it. Other adapters which do not have anything to contribute during this adaptation simply return <code>EventSeq.empty</code>. The adapted events are then delivered in-order to the <code>PersistentActor</code> during replay.</p><div class="callout note "><div class="callout-title">Note</div>
<p>For more advanced schema evolution techniques refer to the <a href="persistence-schema-evolution.html">Persistence - Schema Evolution</a> documentation.</p></div>
<a id="persistent-fsm"></a>
<h2><a href="#persistent-fsm" name="persistent-fsm" class="anchor"><span class="anchor-link"></span></a>Persistent FSM</h2>
<p><span class="group-scala"><code>PersistentFSM</code></span><span class="group-java"><code>AbstractPersistentFSM</code></span> handles the incoming messages in an FSM like fashion. Its internal state is persisted as a sequence of changes, later referred to as domain events. Relationship between incoming messages, FSM&rsquo;s states and transitions, persistence of domain events is defined by a DSL.</p>
<h3><a href="#a-simple-example" name="a-simple-example" class="anchor"><span class="anchor-link"></span></a>A Simple Example</h3>
<p>To demonstrate the features of the <span class="group-scala"><code>PersistentFSM</code> trait</span><span class="group-java"><code>AbstractPersistentFSM</code></span>, consider an actor which represents a Web store customer. The contract of our &ldquo;WebStoreCustomerFSMActor&rdquo; is that it accepts the following commands:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">sealed trait Command
case class AddItem(item: Item) extends Command
case object Buy extends Command
case object Leave extends Command
case object GetCurrentCart extends Command</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">public static final class AddItem implements Command {
    private final Item item;

    public AddItem(Item item) {
        this.item = item;
    }

    public Item getItem() {
        return item;
    }
}

public enum Buy implements Command {INSTANCE}

public enum Leave implements Command {INSTANCE}

public enum GetCurrentCart implements Command {INSTANCE}</code></pre></dd>
</dl>
<p><code>AddItem</code> sent when the customer adds an item to a shopping cart <code>Buy</code> - when the customer finishes the purchase <code>Leave</code> - when the customer leaves the store without purchasing anything <code>GetCurrentCart</code> allows to query the current state of customer&rsquo;s shopping cart</p>
<p>The customer can be in one of the following states:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">sealed trait UserState extends FSMState
case object LookingAround extends UserState {
  override def identifier: String = &quot;Looking Around&quot;
}
case object Shopping extends UserState {
  override def identifier: String = &quot;Shopping&quot;
}
case object Inactive extends UserState {
  override def identifier: String = &quot;Inactive&quot;
}
case object Paid extends UserState {
  override def identifier: String = &quot;Paid&quot;
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">enum UserState implements PersistentFSM.FSMState {
    LOOKING_AROUND(&quot;Looking Around&quot;),
    SHOPPING(&quot;Shopping&quot;),
    INACTIVE(&quot;Inactive&quot;),
    PAID(&quot;Paid&quot;);

    private final String stateIdentifier;

    UserState(String stateIdentifier) {
        this.stateIdentifier = stateIdentifier;
    }

    @Override
    public String identifier() {
        return stateIdentifier;
    }
}</code></pre></dd>
</dl>
<p><code>LookingAround</code> customer is browsing the site, but hasn&rsquo;t added anything to the shopping cart <code>Shopping</code> customer has recently added items to the shopping cart <code>Inactive</code> customer has items in the shopping cart, but hasn&rsquo;t added anything recently <code>Paid</code> customer has purchased the items</p><div class="callout note "><div class="callout-title">Note</div>
<p><span class="group-scala"><code>PersistentFSM</code></span><span class="group-java"><code>AbstractPersistentFSM</code></span> states must <span class="group-scala">inherit from trait</span><span class="group-java">implement interface</span> <code>PersistentFSM.FSMState</code> and implement the <span class="group-scala"><code>def identifier: String</code></span><span class="group-java"><code>String identifier()</code></span> method. This is required in order to simplify the serialization of FSM states. String identifiers should be unique!</p></div>
<p>Customer&rsquo;s actions are &ldquo;recorded&rdquo; as a sequence of &ldquo;domain events&rdquo; which are persisted. Those events are replayed on an actor&rsquo;s start in order to restore the latest customer&rsquo;s state:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">sealed trait DomainEvent
case class ItemAdded(item: Item) extends DomainEvent
case object OrderExecuted extends DomainEvent
case object OrderDiscarded extends DomainEvent</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">public static final class ItemAdded implements DomainEvent {
    private final Item item;

    public ItemAdded(Item item) {
        this.item = item;
    }

    public Item getItem() {
        return item;
    }
}

public enum OrderExecuted implements DomainEvent {INSTANCE}

public enum OrderDiscarded implements DomainEvent {INSTANCE}</code></pre></dd>
</dl>
<p>Customer state data represents the items in a customer&rsquo;s shopping cart:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">case class Item(id: String, name: String, price: Float)

sealed trait ShoppingCart {
  def addItem(item: Item): ShoppingCart
  def empty(): ShoppingCart
}
case object EmptyShoppingCart extends ShoppingCart {
  def addItem(item: Item) = NonEmptyShoppingCart(item :: Nil)
  def empty() = this
}
case class NonEmptyShoppingCart(items: Seq[Item]) extends ShoppingCart {
  def addItem(item: Item) = NonEmptyShoppingCart(items :+ item)
  def empty() = EmptyShoppingCart
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">static class ShoppingCart {
    private final List&lt;Item&gt; items = new ArrayList&lt;&gt;();

    public List&lt;Item&gt; getItems() {
        return Collections.unmodifiableList(items);
    }

    void addItem(Item item) {
        items.add(item);
    }

    void empty() {
        items.clear();
    }
}

static class Item implements Serializable {
    private final String id;
    private final String name;
    private final float price;

    Item(String id, String name, float price) {
        this.id = id;
        this.name = name;
        this.price = price;
    }

    public String getId() {
        return id;
    }

    public float getPrice() {
        return price;
    }

    public String getName() {
        return name;
    }

    @Override
    public String toString() {
        return String.format(&quot;Item{id=%s, name=%s, price=%s}&quot;, id, price, name);
    }

    @Override
    public boolean equals(Object o) {
        if (this == o) return true;
        if (o == null || getClass() != o.getClass()) return false;

        Item item = (Item) o;

        return item.price == price &amp;&amp; id.equals(item.id) &amp;&amp; name.equals(item.name);
    }
}</code></pre></dd>
</dl>
<p>Here is how everything is wired together:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">startWith(LookingAround, EmptyShoppingCart)

when(LookingAround) {
  case Event(AddItem(item), _) ⇒
    goto(Shopping) applying ItemAdded(item) forMax (1 seconds)
  case Event(GetCurrentCart, data) ⇒
    stay replying data
}

when(Shopping) {
  case Event(AddItem(item), _) ⇒
    stay applying ItemAdded(item) forMax (1 seconds)
  case Event(Buy, _) ⇒
    goto(Paid) applying OrderExecuted andThen {
      case NonEmptyShoppingCart(items) ⇒
        reportActor ! PurchaseWasMade(items)
        saveStateSnapshot()
      case EmptyShoppingCart ⇒ saveStateSnapshot()
    }
  case Event(Leave, _) ⇒
    stop applying OrderDiscarded andThen {
      case _ ⇒
        reportActor ! ShoppingCardDiscarded
        saveStateSnapshot()
    }
  case Event(GetCurrentCart, data) ⇒
    stay replying data
  case Event(StateTimeout, _) ⇒
    goto(Inactive) forMax (2 seconds)
}

when(Inactive) {
  case Event(AddItem(item), _) ⇒
    goto(Shopping) applying ItemAdded(item) forMax (1 seconds)
  case Event(StateTimeout, _) ⇒
    stop applying OrderDiscarded andThen {
      case _ ⇒ reportActor ! ShoppingCardDiscarded
    }
}

when(Paid) {
  case Event(Leave, _) ⇒ stop()
  case Event(GetCurrentCart, data) ⇒
    stay replying data
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">startWith(UserState.LOOKING_AROUND, new ShoppingCart());

when(UserState.LOOKING_AROUND,
    matchEvent(AddItem.class,
        (event, data) -&gt;
            goTo(UserState.SHOPPING).applying(new ItemAdded(event.getItem()))
                .forMax(Duration.create(1, TimeUnit.SECONDS))
    )
    .event(GetCurrentCart.class, (event, data) -&gt; stay().replying(data))
);

when(UserState.SHOPPING,
    matchEvent(AddItem.class,
        (event, data) -&gt;
            stay().applying(new ItemAdded(event.getItem()))
               .forMax(Duration.create(1, TimeUnit.SECONDS)))
    .event(Buy.class,
        (event, data) -&gt;
            goTo(UserState.PAID).applying(OrderExecuted.INSTANCE)
                .andThen(exec(cart -&gt; {
                    reportActor.tell(new PurchaseWasMade(cart.getItems()), self());
                    saveStateSnapshot();
                })))
    .event(Leave.class,
        (event, data) -&gt;
            stop().applying(OrderDiscarded.INSTANCE)
                .andThen(exec(cart -&gt; {
                    reportActor.tell(ShoppingCardDiscarded.INSTANCE, self());
                    saveStateSnapshot();
                })))
    .event(GetCurrentCart.class, (event, data) -&gt; stay().replying(data))
    .event(StateTimeout$.class,
        (event, data) -&gt;
            goTo(UserState.INACTIVE).forMax(Duration.create(2, TimeUnit.SECONDS)))
);


when(UserState.INACTIVE,
    matchEvent(AddItem.class,
        (event, data) -&gt;
            goTo(UserState.SHOPPING).applying(new ItemAdded(event.getItem()))
                .forMax(Duration.create(1, TimeUnit.SECONDS)))
    .event(GetCurrentCart.class, (event, data) -&gt; stay().replying(data))
    .event(StateTimeout$.class,
        (event, data) -&gt;
            stop().applying(OrderDiscarded.INSTANCE)
                .andThen(exec(cart -&gt;
                    reportActor.tell(ShoppingCardDiscarded.INSTANCE, self())
                )))
);

when(UserState.PAID,
    matchEvent(Leave.class, (event, data) -&gt; stop())
    .event(GetCurrentCart.class, (event, data) -&gt; stay().replying(data))
);</code></pre></dd>
</dl><div class="callout note "><div class="callout-title">Note</div>
<p>State data can only be modified directly on initialization. Later it&rsquo;s modified only as a result of applying domain events. Override the <code>applyEvent</code> method to define how state data is affected by domain events, see the example below</p></div>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">override def applyEvent(event: DomainEvent, cartBeforeEvent: ShoppingCart): ShoppingCart = {
  event match {
    case ItemAdded(item) ⇒ cartBeforeEvent.addItem(item)
    case OrderExecuted ⇒ cartBeforeEvent
    case OrderDiscarded ⇒ cartBeforeEvent.empty()
  }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public ShoppingCart applyEvent(DomainEvent event, ShoppingCart currentData) {
    if (event instanceof ItemAdded) {
        currentData.addItem(((ItemAdded) event).getItem());
        return currentData;
    } else if (event instanceof OrderExecuted) {
        return currentData;
    } else if (event instanceof OrderDiscarded) {
        currentData.empty();
        return currentData;
    }
    throw new RuntimeException(&quot;Unhandled&quot;);
}</code></pre></dd>
</dl>
<p><code>andThen</code> can be used to define actions which will be executed following event&rsquo;s persistence - convenient for &ldquo;side effects&rdquo; like sending a message or logging. Notice that actions defined in <code>andThen</code> block are not executed on recovery:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">goto(Paid) applying OrderExecuted andThen {
  case NonEmptyShoppingCart(items) ⇒
    reportActor ! PurchaseWasMade(items)
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">(event, data) -&gt;
    goTo(UserState.PAID).applying(OrderExecuted.INSTANCE)
        .andThen(exec(cart -&gt; {
            reportActor.tell(new PurchaseWasMade(cart.getItems()), self());
        })))</code></pre></dd>
</dl>
<p>A snapshot of state data can be persisted by calling the <code>saveStateSnapshot()</code> method:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">stop applying OrderDiscarded andThen {
  case _ ⇒
    reportActor ! ShoppingCardDiscarded
    saveStateSnapshot()
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">(event, data) -&gt;
    stop().applying(OrderDiscarded.INSTANCE)
        .andThen(exec(cart -&gt; {
            reportActor.tell(ShoppingCardDiscarded.INSTANCE, self());
            saveStateSnapshot();
        })))</code></pre></dd>
</dl>
<p>On recovery state data is initialized according to the latest available snapshot, then the remaining domain events are replayed, triggering the <code>applyEvent</code> method.</p>
<a id="periodical-snapshot"></a>
<h2><a href="#periodical-snapshot-by-snapshot-after" name="periodical-snapshot-by-snapshot-after" class="anchor"><span class="anchor-link"></span></a>Periodical snapshot by snapshot-after</h2>
<p>You can enable periodical <code>saveStateSnapshot()</code> calls in <code>PersistentFSM</code> if you turn the following flag on in <code>reference.conf</code></p>
<p><code>akka.persistence.fsm.snapshot-after = 1000</code></p>
<p>this means <code>saveStateSnapshot()</code> is called after the sequence number reaches multiple of 1000.</p><div class="callout note "><div class="callout-title">Note</div>
<p><code>saveStateSnapshot()</code> might not be called exactly at sequence numbers being multiple of the <code>snapshot-after</code> configuration value. This is because <code>PersistentFSM</code> works in a sort of &ldquo;batch&rdquo; mode when processing and persisting events, and <code>saveStateSnapshot()</code> is called only at the end of the &ldquo;batch&rdquo;. For example, if you set <code>akka.persistence.fsm.snapshot-after = 1000</code>, it is possible that <code>saveStateSnapshot()</code> is called at <code>lastSequenceNr = 1005, 2003, ...</code> A single batch might persist state transition, also there could be multiple domain events to be persisted if you pass them to <code>applying</code> method in the <code>PersistFSM</code> DSL.</p></div>
<a id="storage-plugins"></a>
<h2><a href="#storage-plugins" name="storage-plugins" class="anchor"><span class="anchor-link"></span></a>Storage plugins</h2>
<p>Storage backends for journals and snapshot stores are pluggable in the Akka persistence extension.</p>
<p>A directory of persistence journal and snapshot store plugins is available at the Akka Community Projects page, see <a href="https://akka.io/community/">Community plugins</a></p>
<p>Plugins can be selected either by &ldquo;default&rdquo; for all persistent actors, or &ldquo;individually&rdquo;, when a persistent actor defines its own set of plugins.</p>
<p>When a persistent actor does NOT override the <code>journalPluginId</code> and <code>snapshotPluginId</code> methods, the persistence extension will use the &ldquo;default&rdquo; journal and snapshot-store plugins configured in <code>reference.conf</code>:</p>
<pre><code>akka.persistence.journal.plugin = &quot;&quot;
akka.persistence.snapshot-store.plugin = &quot;&quot;
</code></pre>
<p>However, these entries are provided as empty &quot;&quot;, and require explicit user configuration via override in the user <code>application.conf</code>. For an example of a journal plugin which writes messages to LevelDB see <a href="#local-leveldb-journal">Local LevelDB journal</a>. For an example of a snapshot store plugin which writes snapshots as individual files to the local filesystem see <a href="#local-snapshot-store">Local snapshot store</a>.</p>
<p>Applications can provide their own plugins by implementing a plugin API and activating them by configuration. Plugin development requires the following imports:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">import akka.persistence._
import akka.persistence.journal._
import akka.persistence.snapshot._
</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">import akka.dispatch.Futures;
import akka.persistence.*;
import akka.persistence.journal.japi.*;
import akka.persistence.snapshot.japi.*;</code></pre></dd>
</dl>
<h3><a href="#eager-initialization-of-persistence-plugin" name="eager-initialization-of-persistence-plugin" class="anchor"><span class="anchor-link"></span></a>Eager initialization of persistence plugin</h3>
<p>By default, persistence plugins are started on-demand, as they are used. In some case, however, it might be beneficial to start a certain plugin eagerly. In order to do that, you should first add <code>akka.persistence.Persistence</code> under the <code>akka.extensions</code> key. Then, specify the IDs of plugins you wish to start automatically under <code>akka.persistence.journal.auto-start-journals</code> and <code>akka.persistence.snapshot-store.auto-start-snapshot-stores</code>.</p>
<p>For example, if you want eager initialization for the leveldb journal plugin and the local snapshot store plugin, your configuration should look like this: </p>
<pre><code>akka {

  extensions = [akka.persistence.Persistence]

  persistence {

    journal {
      plugin = &quot;akka.persistence.journal.leveldb&quot;
      auto-start-journals = [&quot;akka.persistence.journal.leveldb&quot;]
    }

    snapshot-store {
      plugin = &quot;akka.persistence.snapshot-store.local&quot;
      auto-start-snapshot-stores = [&quot;akka.persistence.snapshot-store.local&quot;]
    }
  
  }

}
</code></pre>
<a id="journal-plugin-api"></a>
<h3><a href="#journal-plugin-api" name="journal-plugin-api" class="anchor"><span class="anchor-link"></span></a>Journal plugin API</h3>
<p>A journal plugin extends <code>AsyncWriteJournal</code>.</p>
<p><code>AsyncWriteJournal</code> is an actor and the methods to be implemented are:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">/**
 * Plugin API: asynchronously writes a batch (`Seq`) of persistent messages to the
 * journal.
 *
 * The batch is only for performance reasons, i.e. all messages don&#39;t have to be written
 * atomically. Higher throughput can typically be achieved by using batch inserts of many
 * records compared to inserting records one-by-one, but this aspect depends on the
 * underlying data store and a journal implementation can implement it as efficient as
 * possible. Journals should aim to persist events in-order for a given `persistenceId`
 * as otherwise in case of a failure, the persistent state may be end up being inconsistent.
 *
 * Each `AtomicWrite` message contains the single `PersistentRepr` that corresponds to
 * the event that was passed to the `persist` method of the `PersistentActor`, or it
 * contains several `PersistentRepr` that corresponds to the events that were passed
 * to the `persistAll` method of the `PersistentActor`. All `PersistentRepr` of the
 * `AtomicWrite` must be written to the data store atomically, i.e. all or none must
 * be stored. If the journal (data store) cannot support atomic writes of multiple
 * events it should reject such writes with a `Try` `Failure` with an
 * `UnsupportedOperationException` describing the issue. This limitation should
 * also be documented by the journal plugin.
 *
 * If there are failures when storing any of the messages in the batch the returned
 * `Future` must be completed with failure. The `Future` must only be completed with
 * success when all messages in the batch have been confirmed to be stored successfully,
 * i.e. they will be readable, and visible, in a subsequent replay. If there is
 * uncertainty about if the messages were stored or not the `Future` must be completed
 * with failure.
 *
 * Data store connection problems must be signaled by completing the `Future` with
 * failure.
 *
 * The journal can also signal that it rejects individual messages (`AtomicWrite`) by
 * the returned `immutable.Seq[Try[Unit]]`. It is possible but not mandatory to reduce
 * number of allocations by returning `Future.successful(Nil)` for the happy path,
 * i.e. when no messages are rejected. Otherwise the returned `Seq` must have as many elements
 * as the input `messages` `Seq`. Each `Try` element signals if the corresponding
 * `AtomicWrite` is rejected or not, with an exception describing the problem. Rejecting
 * a message means it was not stored, i.e. it must not be included in a later replay.
 * Rejecting a message is typically done before attempting to store it, e.g. because of
 * serialization error.
 *
 * Data store connection problems must not be signaled as rejections.
 *
 * It is possible but not mandatory to reduce number of allocations by returning
 * `Future.successful(Nil)` for the happy path, i.e. when no messages are rejected.
 *
 * Calls to this method are serialized by the enclosing journal actor. If you spawn
 * work in asynchronous tasks it is alright that they complete the futures in any order,
 * but the actual writes for a specific persistenceId should be serialized to avoid
 * issues such as events of a later write are visible to consumers (query side, or replay)
 * before the events of an earlier write are visible.
 * A PersistentActor will not send a new WriteMessages request before the previous one
 * has been completed.
 *
 * Please note that the `sender` field of the contained PersistentRepr objects has been
 * nulled out (i.e. set to `ActorRef.noSender`) in order to not use space in the journal
 * for a sender reference that will likely be obsolete during replay.
 *
 * Please also note that requests for the highest sequence number may be made concurrently
 * to this call executing for the same `persistenceId`, in particular it is possible that
 * a restarting actor tries to recover before its outstanding writes have completed. In
 * the latter case it is highly desirable to defer reading the highest sequence number
 * until all outstanding writes have completed, otherwise the PersistentActor may reuse
 * sequence numbers.
 *
 * This call is protected with a circuit-breaker.
 */
def asyncWriteMessages(messages: immutable.Seq[AtomicWrite]): Future[immutable.Seq[Try[Unit]]]

/**
 * Plugin API: asynchronously deletes all persistent messages up to `toSequenceNr`
 * (inclusive).
 *
 * This call is protected with a circuit-breaker.
 * Message deletion doesn&#39;t affect the highest sequence number of messages, journal must maintain the highest sequence number and never decrease it.
 */
def asyncDeleteMessagesTo(persistenceId: String, toSequenceNr: Long): Future[Unit]

/**
 * Plugin API
 *
 * Allows plugin implementers to use `f pipeTo self` and
 * handle additional messages for implementing advanced features
 *
 */
def receivePluginInternal: Actor.Receive = Actor.emptyBehavior</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">/**
 * Java API, Plugin API: asynchronously writes a batch (`Iterable`) of
 * persistent messages to the journal.
 *
 * The batch is only for performance reasons, i.e. all messages don&#39;t have to
 * be written atomically. Higher throughput can typically be achieved by using
 * batch inserts of many records compared to inserting records one-by-one, but
 * this aspect depends on the underlying data store and a journal
 * implementation can implement it as efficient as possible. Journals should
 * aim to persist events in-order for a given `persistenceId` as otherwise in
 * case of a failure, the persistent state may be end up being inconsistent.
 * 
 * Each `AtomicWrite` message contains the single `PersistentRepr` that
 * corresponds to the event that was passed to the `persist` method of the
 * `PersistentActor`, or it contains several `PersistentRepr` that corresponds
 * to the events that were passed to the `persistAll` method of the
 * `PersistentActor`. All `PersistentRepr` of the `AtomicWrite` must be
 * written to the data store atomically, i.e. all or none must be stored. If
 * the journal (data store) cannot support atomic writes of multiple events it
 * should reject such writes with an `Optional` with an
 * `UnsupportedOperationException` describing the issue. This limitation
 * should also be documented by the journal plugin.
 *
 * If there are failures when storing any of the messages in the batch the
 * returned `Future` must be completed with failure. The `Future` must only be
 * completed with success when all messages in the batch have been confirmed
 * to be stored successfully, i.e. they will be readable, and visible, in a
 * subsequent replay. If there is uncertainty about if the messages were
 * stored or not the `Future` must be completed with failure.
 *
 * Data store connection problems must be signaled by completing the `Future`
 * with failure.
 *
 * The journal can also signal that it rejects individual messages
 * (`AtomicWrite`) by the returned
 * `Iterable&amp;lt;Optional&amp;lt;Exception&amp;gt;&amp;gt;`. The returned `Iterable` must
 * have as many elements as the input `messages` `Iterable`. Each `Optional`
 * element signals if the corresponding `AtomicWrite` is rejected or not, with
 * an exception describing the problem. Rejecting a message means it was not
 * stored, i.e. it must not be included in a later replay. Rejecting a message
 * is typically done before attempting to store it, e.g. because of
 * serialization error.
 *
 * Data store connection problems must not be signaled as rejections.
 *
 * Note that it is possible to reduce number of allocations by caching some
 * result `Iterable` for the happy path, i.e. when no messages are rejected.
 *
 * Calls to this method are serialized by the enclosing journal actor. If you spawn
 * work in asynchronous tasks it is alright that they complete the futures in any order,
 * but the actual writes for a specific persistenceId should be serialized to avoid 
 * issues such as events of a later write are visible to consumers (query side, or replay)
 * before the events of an earlier write are visible. This can also be done with
 * consistent hashing if it is too fine grained to do it on the persistenceId level.
 * Normally a `PersistentActor` will only have one outstanding write request to the journal but 
 * it may emit several write requests when `persistAsync` is used and the max batch size
 * is reached.
 *
 * This call is protected with a circuit-breaker.
 */
Future&lt;Iterable&lt;Optional&lt;Exception&gt;&gt;&gt; doAsyncWriteMessages(Iterable&lt;AtomicWrite&gt; messages);

/**
 * Java API, Plugin API: synchronously deletes all persistent messages up to
 * `toSequenceNr`.
 *
 * This call is protected with a circuit-breaker.
 *
 * @see AsyncRecoveryPlugin
 */
Future&lt;Void&gt; doAsyncDeleteMessagesTo(String persistenceId, long toSequenceNr);</code></pre></dd>
</dl>
<p>If the storage backend API only supports synchronous, blocking writes, the methods should be implemented as:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">def asyncWriteMessages(messages: immutable.Seq[AtomicWrite]): Future[immutable.Seq[Try[Unit]]] =
  Future.fromTry(Try {
    // blocking call here
    ???
  })</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">@Override
public Future&lt;Iterable&lt;Optional&lt;Exception&gt;&gt;&gt; doAsyncWriteMessages(
    Iterable&lt;AtomicWrite&gt; messages) {
  try {
    Iterable&lt;Optional&lt;Exception&gt;&gt; result = new ArrayList&lt;Optional&lt;Exception&gt;&gt;();
    // blocking call here...
    // result.add(..)
    return Futures.successful(result);
  } catch (Exception e) {
    return Futures.failed(e);
  }
}</code></pre></dd>
</dl>
<p>A journal plugin must also implement the methods defined in <code>AsyncRecovery</code> for replays and sequence number recovery:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">/**
 * Plugin API: asynchronously replays persistent messages. Implementations replay
 * a message by calling `replayCallback`. The returned future must be completed
 * when all messages (matching the sequence number bounds) have been replayed.
 * The future must be completed with a failure if any of the persistent messages
 * could not be replayed.
 *
 * The `replayCallback` must also be called with messages that have been marked
 * as deleted. In this case a replayed message&#39;s `deleted` method must return
 * `true`.
 *
 * The `toSequenceNr` is the lowest of what was returned by [[#asyncReadHighestSequenceNr]]
 * and what the user specified as recovery [[akka.persistence.Recovery]] parameter.
 * This does imply that this call is always preceded by reading the highest sequence
 * number for the given `persistenceId`.
 *
 * This call is NOT protected with a circuit-breaker because it may take long time
 * to replay all events. The plugin implementation itself must protect against
 * an unresponsive backend store and make sure that the returned Future is
 * completed with success or failure within reasonable time. It is not allowed
 * to ignore completing the future.
 *
 * @param persistenceId persistent actor id.
 * @param fromSequenceNr sequence number where replay should start (inclusive).
 * @param toSequenceNr sequence number where replay should end (inclusive).
 * @param max maximum number of messages to be replayed.
 * @param recoveryCallback called to replay a single message. Can be called from any
 *                       thread.
 *
 * @see [[AsyncWriteJournal]]
 */
def asyncReplayMessages(persistenceId: String, fromSequenceNr: Long, toSequenceNr: Long,
  max: Long)(recoveryCallback: PersistentRepr ⇒ Unit): Future[Unit]

/**
 * Plugin API: asynchronously reads the highest stored sequence number for the
 * given `persistenceId`. The persistent actor will use the highest sequence
 * number after recovery as the starting point when persisting new events.
 * This sequence number is also used as `toSequenceNr` in subsequent call
 * to [[#asyncReplayMessages]] unless the user has specified a lower `toSequenceNr`.
 * Journal must maintain the highest sequence number and never decrease it.
 *
 * This call is protected with a circuit-breaker.
 *
 * Please also note that requests for the highest sequence number may be made concurrently
 * to writes executing for the same `persistenceId`, in particular it is possible that
 * a restarting actor tries to recover before its outstanding writes have completed.
 *
 * @param persistenceId persistent actor id.
 * @param fromSequenceNr hint where to start searching for the highest sequence
 *                       number. When a persistent actor is recovering this
 *                       `fromSequenceNr` will be the sequence number of the used
 *                       snapshot or `0L` if no snapshot is used.
 */
def asyncReadHighestSequenceNr(persistenceId: String, fromSequenceNr: Long): Future[Long]</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">/**
 * Java API, Plugin API: asynchronously replays persistent messages.
 * Implementations replay a message by calling `replayCallback`. The returned
 * future must be completed when all messages (matching the sequence number
 * bounds) have been replayed. The future must be completed with a failure if
 * any of the persistent messages could not be replayed.
 *
 * The `replayCallback` must also be called with messages that have been
 * marked as deleted. In this case a replayed message&#39;s `deleted` method must
 * return `true`.
 *
 * The `toSequenceNr` is the lowest of what was returned by
 * {@link #doAsyncReadHighestSequenceNr} and what the user specified as
 * recovery {@link akka.persistence.Recovery} parameter.
 *
 * @param persistenceId
 *          id of the persistent actor.
 * @param fromSequenceNr
 *          sequence number where replay should start (inclusive).
 * @param toSequenceNr
 *          sequence number where replay should end (inclusive).
 * @param max
 *          maximum number of messages to be replayed.
 * @param replayCallback
 *          called to replay a single message. Can be called from any thread.
 */
Future&lt;Void&gt; doAsyncReplayMessages(String persistenceId, long fromSequenceNr,
    long toSequenceNr, long max, Consumer&lt;PersistentRepr&gt; replayCallback);

/**
 * Java API, Plugin API: asynchronously reads the highest stored sequence
 * number for the given `persistenceId`. The persistent actor will use the
 * highest sequence number after recovery as the starting point when
 * persisting new events. This sequence number is also used as `toSequenceNr`
 * in subsequent call to [[#asyncReplayMessages]] unless the user has
 * specified a lower `toSequenceNr`.
 *
 * @param persistenceId
 *          id of the persistent actor.
 * @param fromSequenceNr
 *          hint where to start searching for the highest sequence number.
 */
Future&lt;Long&gt; doAsyncReadHighestSequenceNr(String persistenceId, long fromSequenceNr);</code></pre></dd>
</dl>
<p>A journal plugin can be activated with the following minimal configuration:</p>
<pre class="prettyprint"><code class="language-scala"># Path to the journal plugin to be used
akka.persistence.journal.plugin = &quot;my-journal&quot;

# My custom journal plugin
my-journal {
  # Class name of the plugin.
  class = &quot;docs.persistence.MyJournal&quot;
  # Dispatcher for the plugin actor.
  plugin-dispatcher = &quot;akka.actor.default-dispatcher&quot;
}</code></pre>
<p>The journal plugin instance is an actor so the methods corresponding to requests from persistent actors are executed sequentially. It may delegate to asynchronous libraries, spawn futures, or delegate to other actors to achieve parallelism.</p>
<p>The journal plugin class must have a constructor with one of these signatures:</p>
<ul>
  <li>constructor with one <code>com.typesafe.config.Config</code> parameter and a <code>String</code> parameter for the config path</li>
  <li>constructor with one <code>com.typesafe.config.Config</code> parameter</li>
  <li>constructor without parameters</li>
</ul>
<p>The plugin section of the actor system&rsquo;s config will be passed in the config constructor parameter. The config path of the plugin is passed in the <code>String</code> parameter.</p>
<p>The <code>plugin-dispatcher</code> is the dispatcher used for the plugin actor. If not specified, it defaults to <code>akka.persistence.dispatchers.default-plugin-dispatcher</code>.</p>
<p>Don&rsquo;t run journal tasks/futures on the system default dispatcher, since that might starve other tasks.</p>
<h3><a href="#snapshot-store-plugin-api" name="snapshot-store-plugin-api" class="anchor"><span class="anchor-link"></span></a>Snapshot store plugin API</h3>
<p>A snapshot store plugin must extend the <code>SnapshotStore</code> actor and implement the following methods:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala"><br/>/**
 * Plugin API: asynchronously loads a snapshot.
 *
 * If the future `Option` is `None` then all events will be replayed,
 * i.e. there was no snapshot. If snapshot could not be loaded the `Future`
 * should be completed with failure. That is important because events may
 * have been deleted and just replaying the events might not result in a valid
 * state.
 *
 * This call is protected with a circuit-breaker.
 *
 * @param persistenceId id of the persistent actor.
 * @param criteria selection criteria for loading.
 */
def loadAsync(persistenceId: String, criteria: SnapshotSelectionCriteria): Future[Option[SelectedSnapshot]]

/**
 * Plugin API: asynchronously saves a snapshot.
 *
 * This call is protected with a circuit-breaker.
 *
 * @param metadata snapshot metadata.
 * @param snapshot snapshot.
 */
def saveAsync(metadata: SnapshotMetadata, snapshot: Any): Future[Unit]

/**
 * Plugin API: deletes the snapshot identified by `metadata`.
 *
 * This call is protected with a circuit-breaker.
 *
 * @param metadata snapshot metadata.
 */
def deleteAsync(metadata: SnapshotMetadata): Future[Unit]

/**
 * Plugin API: deletes all snapshots matching `criteria`.
 *
 * This call is protected with a circuit-breaker.
 *
 * @param persistenceId id of the persistent actor.
 * @param criteria selection criteria for deleting.
 */
def deleteAsync(persistenceId: String, criteria: SnapshotSelectionCriteria): Future[Unit]

/**
 * Plugin API
 * Allows plugin implementers to use `f pipeTo self` and
 * handle additional messages for implementing advanced features
 */
def receivePluginInternal: Actor.Receive = Actor.emptyBehavior</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">/**
 * Java API, Plugin API: asynchronously loads a snapshot.
 *
 * @param persistenceId
 *          id of the persistent actor.
 * @param criteria
 *          selection criteria for loading.
 */
Future&lt;Optional&lt;SelectedSnapshot&gt;&gt; doLoadAsync(String persistenceId, 
    SnapshotSelectionCriteria criteria);

/**
 * Java API, Plugin API: asynchronously saves a snapshot.
 *
 * @param metadata
 *          snapshot metadata.
 * @param snapshot
 *          snapshot.
 */
Future&lt;Void&gt; doSaveAsync(SnapshotMetadata metadata, Object snapshot);

/**
 * Java API, Plugin API: deletes the snapshot identified by `metadata`.
 *
 * @param metadata
 *          snapshot metadata.
 */
Future&lt;Void&gt; doDeleteAsync(SnapshotMetadata metadata);

/**
 * Java API, Plugin API: deletes all snapshots matching `criteria`.
 *
 * @param persistenceId
 *          id of the persistent actor.
 * @param criteria
 *          selection criteria for deleting.
 */
Future&lt;Void&gt; doDeleteAsync(String persistenceId, SnapshotSelectionCriteria criteria);</code></pre></dd>
</dl>
<p>A snapshot store plugin can be activated with the following minimal configuration:</p>
<pre class="prettyprint"><code class="language-scala"># Path to the snapshot store plugin to be used
akka.persistence.snapshot-store.plugin = &quot;my-snapshot-store&quot;

# My custom snapshot store plugin
my-snapshot-store {
  # Class name of the plugin.
  class = &quot;docs.persistence.MySnapshotStore&quot;
  # Dispatcher for the plugin actor.
  plugin-dispatcher = &quot;akka.persistence.dispatchers.default-plugin-dispatcher&quot;
}</code></pre>
<p>The snapshot store instance is an actor so the methods corresponding to requests from persistent actors are executed sequentially. It may delegate to asynchronous libraries, spawn futures, or delegate to other actors to achive parallelism.</p>
<p>The snapshot store plugin class must have a constructor with one of these signatures:</p>
<ul>
  <li>constructor with one <code>com.typesafe.config.Config</code> parameter and a <code>String</code> parameter for the config path</li>
  <li>constructor with one <code>com.typesafe.config.Config</code> parameter</li>
  <li>constructor without parameters</li>
</ul>
<p>The plugin section of the actor system&rsquo;s config will be passed in the config constructor parameter. The config path of the plugin is passed in the <code>String</code> parameter.</p>
<p>The <code>plugin-dispatcher</code> is the dispatcher used for the plugin actor. If not specified, it defaults to <code>akka.persistence.dispatchers.default-plugin-dispatcher</code>.</p>
<p>Don&rsquo;t run snapshot store tasks/futures on the system default dispatcher, since that might starve other tasks.</p>
<h3><a href="#plugin-tck" name="plugin-tck" class="anchor"><span class="anchor-link"></span></a>Plugin TCK</h3>
<p>In order to help developers build correct and high quality storage plugins, we provide a Technology Compatibility Kit (<a href="http://en.wikipedia.org/wiki/Technology_Compatibility_Kit">TCK</a> for short).</p>
<p>The TCK is usable from Java as well as Scala projects. To test your implementation (independently of language) you need to include the akka-persistence-tck dependency:</p>
<dl>
  <dt>sbt</dt>
  <dd>
  <pre><code>&quot;com.typesafe.akka&quot; %% &quot;akka-persistence-tck&quot; % &quot;2.5.5&quot; % &quot;test&quot;
</code></pre></dd>
  <dt>Gradle</dt>
  <dd>
  <pre><code>testCompile group: &#39;com.typesafe.akka&#39;, name: &#39;akka-persistence-tck_2.12&#39;, version: &#39;2.5.5&#39;
</code></pre></dd>
  <dt>Maven</dt>
  <dd>
  <pre><code>&lt;dependency&gt;
  &lt;groupId&gt;com.typesafe.akka&lt;/groupId&gt;
  &lt;artifactId&gt;akka-persistence-tck_2.12&lt;/artifactId&gt;
  &lt;version&gt;2.5.5&lt;/version&gt;
  &lt;scope&gt;test&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre></dd>
</dl>
<p>To include the Journal TCK tests in your test suite simply extend the provided <span class="group-scala"><code>JournalSpec</code></span><span class="group-java"><code>JavaJournalSpec</code></span>:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MyJournalSpec extends JournalSpec(
  config = ConfigFactory.parseString(
    &quot;&quot;&quot;akka.persistence.journal.plugin = &quot;my.journal.plugin&quot;&quot;&quot;&quot;)) {

  override def supportsRejectingNonSerializableObjects: CapabilityFlag =
    false // or CapabilityFlag.off
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyJournalSpecTest extends JavaJournalSpec {

  public MyJournalSpecTest() {
    super(ConfigFactory.parseString(
      &quot;persistence.journal.plugin = &quot; +
        &quot;\&quot;akka.persistence.journal.leveldb-shared\&quot;&quot;));
  }

  @Override
  public CapabilityFlag supportsRejectingNonSerializableObjects() {
    return CapabilityFlag.off();
  }
}</code></pre></dd>
</dl>
<p>Please note that some of the tests are optional, and by overriding the <code>supports...</code> methods you give the TCK the needed information about which tests to run. You can implement these methods using <span class="group-scala">boolean values or</span> the provided <code>CapabilityFlag.on</code> / <code>CapabilityFlag.off</code> values.</p>
<p>We also provide a simple benchmarking class <span class="group-scala"><code>JournalPerfSpec</code></span><span class="group-java"><code>JavaJournalPerfSpec</code></span> which includes all the tests that <span class="group-scala"><code>JournalSpec</code></span><span class="group-java"><code>JavaJournalSpec</code></span> has, and also performs some longer operations on the Journal while printing its performance stats. While it is NOT aimed to provide a proper benchmarking environment it can be used to get a rough feel about your journal&rsquo;s performance in the most typical scenarios.</p>
<p>In order to include the <code>SnapshotStore</code> TCK tests in your test suite simply extend the <code>SnapshotStoreSpec</code>:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MySnapshotStoreSpec extends SnapshotStoreSpec(
  config = ConfigFactory.parseString(
    &quot;&quot;&quot;
    akka.persistence.snapshot-store.plugin = &quot;my.snapshot-store.plugin&quot;
    &quot;&quot;&quot;))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MySnapshotStoreTest extends JavaSnapshotStoreSpec {

  public MySnapshotStoreTest() {
    super(ConfigFactory.parseString(
      &quot;akka.persistence.snapshot-store.plugin = &quot; +
        &quot;\&quot;akka.persistence.snapshot-store.local\&quot;&quot;));
  }
}</code></pre></dd>
</dl>
<p>In case your plugin requires some setting up (starting a mock database, removing temporary files etc.) you can override the <code>beforeAll</code> and <code>afterAll</code> methods to hook into the tests lifecycle:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">class MyJournalSpec extends JournalSpec(
  config = ConfigFactory.parseString(
    &quot;&quot;&quot;
    akka.persistence.journal.plugin = &quot;my.journal.plugin&quot;
    &quot;&quot;&quot;)) {

  override def supportsRejectingNonSerializableObjects: CapabilityFlag =
    true // or CapabilityFlag.on

  val storageLocations = List(
    new File(system.settings.config.getString(&quot;akka.persistence.journal.leveldb.dir&quot;)),
    new File(config.getString(&quot;akka.persistence.snapshot-store.local.dir&quot;)))

  override def beforeAll() {
    super.beforeAll()
    storageLocations foreach FileUtils.deleteRecursively
  }

  override def afterAll() {
    storageLocations foreach FileUtils.deleteRecursively
    super.afterAll()
  }

}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class MyJournalSpecTest extends JavaJournalSpec {

  List&lt;File&gt; storageLocations = new ArrayList&lt;File&gt;();

  public MyJournalSpecTest() {
    super(ConfigFactory.parseString(
      &quot;persistence.journal.plugin = &quot; +
        &quot;\&quot;akka.persistence.journal.leveldb-shared\&quot;&quot;));

    Config config = system().settings().config();
    storageLocations.add(new File(
      config.getString(&quot;akka.persistence.journal.leveldb.dir&quot;)));
    storageLocations.add(new File(
      config.getString(&quot;akka.persistence.snapshot-store.local.dir&quot;)));
  }


  @Override
  public CapabilityFlag supportsRejectingNonSerializableObjects() {
    return CapabilityFlag.on();
  }

  @Override
  public void beforeAll() {
    for (File storageLocation : storageLocations) {
      FileUtils.deleteRecursively(storageLocation);
    }
    super.beforeAll();
  }

  @Override
  public void afterAll() {
    super.afterAll();
    for (File storageLocation : storageLocations) {
      FileUtils.deleteRecursively(storageLocation);
    }
  }
}</code></pre></dd>
</dl>
<p>We <em>highly recommend</em> including these specifications in your test suite, as they cover a broad range of cases you might have otherwise forgotten to test for when writing a plugin from scratch.</p>
<a id="pre-packaged-plugins"></a>
<h2><a href="#pre-packaged-plugins" name="pre-packaged-plugins" class="anchor"><span class="anchor-link"></span></a>Pre-packaged plugins</h2>
<a id="local-leveldb-journal"></a>
<h3><a href="#local-leveldb-journal" name="local-leveldb-journal" class="anchor"><span class="anchor-link"></span></a>Local LevelDB journal</h3>
<p>The LevelDB journal plugin config entry is <code>akka.persistence.journal.leveldb</code>. It writes messages to a local LevelDB instance. Enable this plugin by defining config property:</p>
<pre class="prettyprint"><code class="language-scala"># Path to the journal plugin to be used
akka.persistence.journal.plugin = &quot;akka.persistence.journal.leveldb&quot;</code></pre>
<p>LevelDB based plugins will also require the following additional dependency declaration:</p>
<dl>
  <dt>sbt</dt>
  <dd>
  <pre><code>&quot;org.iq80.leveldb&quot;            % &quot;leveldb&quot;          % &quot;0.9&quot;
&quot;org.fusesource.leveldbjni&quot;   % &quot;leveldbjni-all&quot;   % &quot;1.8&quot;
</code></pre></dd>
  <dt>Gradle</dt>
  <dd>
  <pre><code>compile group: &#39;org.iq80.leveldb&#39;, name: &#39;leveldb&#39;, version: &#39;0.9&#39;
compile group: &#39;org.fusesource.leveldbjni&#39;, name: &#39;leveldbjni-all&#39;, version: &#39;1.8&#39; 
</code></pre></dd>
  <dt>Maven</dt>
  <dd>
  <pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.iq80.leveldb&lt;/groupId&gt;
  &lt;artifactId&gt;leveldb&lt;/artifactId&gt;
  &lt;version&gt;0.9&lt;/version&gt;
&lt;/dependency&gt;
&lt;dependency&gt;
  &lt;groupId&gt;org.fusesource.leveldbjni&lt;/groupId&gt;
  &lt;artifactId&gt;leveldbjni-all&lt;/artifactId&gt;
  &lt;version&gt;1.8&lt;/version&gt;
&lt;/dependency&gt;
</code></pre></dd>
</dl>
<p>The default location of LevelDB files is a directory named <code>journal</code> in the current working directory. This location can be changed by configuration where the specified path can be relative or absolute:</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.journal.leveldb.dir = &quot;target/journal&quot;</code></pre>
<p>With this plugin, each actor system runs its own private LevelDB instance.</p>
<p>One peculiarity of LevelDB is that the deletion operation does not remove messages from the journal, but adds a &ldquo;tombstone&rdquo; for each deleted message instead. In the case of heavy journal usage, especially one including frequent deletes, this may be an issue as users may find themselves dealing with continuously increasing journal sizes. To this end, LevelDB offers a special journal compaction function that is exposed via the following configuration:</p>
<pre class="prettyprint"><code class="language-scala"># Number of deleted messages per persistence id that will trigger journal compaction
akka.persistence.journal.leveldb.compaction-intervals {
  persistence-id-1 = 100
  persistence-id-2 = 200
  # ...
  persistence-id-N = 1000
  # use wildcards to match unspecified persistence ids, if any
  &quot;*&quot; = 250
}</code></pre>
<a id="shared-leveldb-journal"></a>
<h3><a href="#shared-leveldb-journal" name="shared-leveldb-journal" class="anchor"><span class="anchor-link"></span></a>Shared LevelDB journal</h3>
<p>A LevelDB instance can also be shared by multiple actor systems (on the same or on different nodes). This, for example, allows persistent actors to failover to a backup node and continue using the shared journal instance from the backup node.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>A shared LevelDB instance is a single point of failure and should therefore only be used for testing purposes. Highly-available, replicated journals are available as <a href="https://akka.io/community/">Community plugins</a>.</p></div><div class="callout note "><div class="callout-title">Note</div>
<p>This plugin has been supplanted by <a href="#persistence-plugin-proxy">Persistence Plugin Proxy</a>.</p></div>
<p>A shared LevelDB instance is started by instantiating the <code>SharedLeveldbStore</code> actor.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">import akka.persistence.journal.leveldb.SharedLeveldbStore

val store = system.actorOf(Props[SharedLeveldbStore], &quot;store&quot;)</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">final ActorRef store = system.actorOf(Props.create(SharedLeveldbStore.class), &quot;store&quot;);</code></pre></dd>
</dl>
<p>By default, the shared instance writes journaled messages to a local directory named <code>journal</code> in the current working directory. The storage location can be changed by configuration:</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.journal.leveldb-shared.store.dir = &quot;target/shared&quot;</code></pre>
<p>Actor systems that use a shared LevelDB store must activate the <code>akka.persistence.journal.leveldb-shared</code> plugin.</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.journal.plugin = &quot;akka.persistence.journal.leveldb-shared&quot;</code></pre>
<p>This plugin must be initialized by injecting the (remote) <code>SharedLeveldbStore</code> actor reference. Injection is done by calling the <code>SharedLeveldbJournal.setStore</code> method with the actor reference as argument.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">trait SharedStoreUsage extends Actor {
  override def preStart(): Unit = {
    context.actorSelection(&quot;akka.tcp://example@127.0.0.1:2552/user/store&quot;) ! Identify(1)
  }

  def receive = {
    case ActorIdentity(1, Some(store)) =&gt;
      SharedLeveldbJournal.setStore(store, context.system)
  }
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">class SharedStorageUsage extends AbstractActor {
  @Override
  public void preStart() throws Exception {
    String path = &quot;akka.tcp://example@127.0.0.1:2552/user/store&quot;;
    ActorSelection selection = getContext().actorSelection(path);
    selection.tell(new Identify(1), getSelf());
  }

  @Override
  public Receive createReceive() {
    return receiveBuilder()
      .match(ActorIdentity.class, ai -&gt; {
        if (ai.correlationId().equals(1)) {
          Optional&lt;ActorRef&gt; store = ai.getActorRef();
          if (store.isPresent()) {
            SharedLeveldbJournal.setStore(store.get(), getContext().getSystem());
          } else {
            throw new RuntimeException(&quot;Couldn&#39;t identify store&quot;);
          }
        }
      })
      .build();
  }
}</code></pre></dd>
</dl>
<p>Internal journal commands (sent by persistent actors) are buffered until injection completes. Injection is idempotent i.e. only the first injection is used.</p>
<a id="local-snapshot-store"></a>
<h3><a href="#local-snapshot-store" name="local-snapshot-store" class="anchor"><span class="anchor-link"></span></a>Local snapshot store</h3>
<p>The local snapshot store plugin config entry is <code>akka.persistence.snapshot-store.local</code>. It writes snapshot files to the local filesystem. Enable this plugin by defining config property:</p>
<pre class="prettyprint"><code class="language-scala"># Path to the snapshot store plugin to be used
akka.persistence.snapshot-store.plugin = &quot;akka.persistence.snapshot-store.local&quot;</code></pre>
<p>The default storage location is a directory named <code>snapshots</code> in the current working directory. This can be changed by configuration where the specified path can be relative or absolute:</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.snapshot-store.local.dir = &quot;target/snapshots&quot;</code></pre>
<p>Note that it is not mandatory to specify a snapshot store plugin. If you don&rsquo;t use snapshots you don&rsquo;t have to configure it.</p>
<a id="persistence-plugin-proxy"></a>
<h3><a href="#persistence-plugin-proxy" name="persistence-plugin-proxy" class="anchor"><span class="anchor-link"></span></a>Persistence Plugin Proxy</h3>
<p>A persistence plugin proxy allows sharing of journals and snapshot stores across multiple actor systems (on the same or on different nodes). This, for example, allows persistent actors to failover to a backup node and continue using the shared journal instance from the backup node. The proxy works by forwarding all the journal/snapshot store messages to a single, shared, persistence plugin instance, and therefore supports any use case supported by the proxied plugin.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>A shared journal/snapshot store is a single point of failure and should therefore only be used for testing purposes. Highly-available, replicated persistence plugins are available as <a href="https://akka.io/community/">Community plugins</a>.</p></div>
<p>The journal and snapshot store proxies are controlled via the <code>akka.persistence.journal.proxy</code> and <code>akka.persistence.snapshot-store.proxy</code> configuration entries, respectively. Set the <code>target-journal-plugin</code> or <code>target-snapshot-store-plugin</code> keys to the underlying plugin you wish to use (for example: <code>akka.persistence.journal.leveldb</code>). The <code>start-target-journal</code> and <code>start-target-snapshot-store</code> keys should be set to <code>on</code> in exactly one actor system - this is the system that will instantiate the shared persistence plugin. Next, the proxy needs to be told how to find the shared plugin. This can be done by setting the <code>target-journal-address</code> and <code>target-snapshot-store-address</code> configuration keys, or programmatically by calling the <code>PersistencePluginProxy.setTargetLocation</code> method.</p><div class="callout note "><div class="callout-title">Note</div>
<p>Akka starts extensions lazily when they are required, and this includes the proxy. This means that in order for the proxy to work, the persistence plugin on the target node must be instantiated. This can be done by instantiating the <code>PersistencePluginProxyExtension</code> <a href="extending-akka.html">extension</a>, or by calling the <code>PersistencePluginProxy.start</code> method.</p></div><div class="callout note "><div class="callout-title">Note</div>
<p>The proxied persistence plugin can (and should) be configured using its original configuration keys.</p></div>
<a id="custom-serialization"></a>
<h2><a href="#custom-serialization" name="custom-serialization" class="anchor"><span class="anchor-link"></span></a>Custom serialization</h2>
<p>Serialization of snapshots and payloads of <code>Persistent</code> messages is configurable with Akka&rsquo;s <a href="serialization.html">Serialization</a> infrastructure. For example, if an application wants to serialize</p>
<ul>
  <li>payloads of type <code>MyPayload</code> with a custom <code>MyPayloadSerializer</code> and</li>
  <li>snapshots of type <code>MySnapshot</code> with a custom <code>MySnapshotSerializer</code></li>
</ul>
<p>it must add</p>
<pre class="prettyprint"><code class="language-scala">akka.actor {
  serializers {
    my-payload = &quot;docs.persistence.MyPayloadSerializer&quot;
    my-snapshot = &quot;docs.persistence.MySnapshotSerializer&quot;
  }
  serialization-bindings {
    &quot;docs.persistence.MyPayload&quot; = my-payload
    &quot;docs.persistence.MySnapshot&quot; = my-snapshot
  }
}</code></pre>
<p>to the application configuration. If not specified, a default serializer is used.</p>
<p>For more advanced schema evolution techniques refer to the <a href="persistence-schema-evolution.html">Persistence - Schema Evolution</a> documentation.</p>
<h2><a href="#testing" name="testing" class="anchor"><span class="anchor-link"></span></a>Testing</h2>
<p>When running tests with LevelDB default settings in <code>sbt</code>, make sure to set <code>fork := true</code> in your sbt project. Otherwise, you&rsquo;ll see an <code>UnsatisfiedLinkError</code>. Alternatively, you can switch to a LevelDB Java port by setting</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.journal.leveldb.native = off</code></pre>
<p>or</p>
<pre class="prettyprint"><code class="language-scala">akka.persistence.journal.leveldb-shared.store.native = off</code></pre>
<p>in your Akka configuration. The LevelDB Java port is for testing purposes only.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>It is not possible to test persistence provided classes (i.e. <a href="#event-sourcing">PersistentActor</a> and <a href="#at-least-once-delivery">AtLeastOnceDelivery</a>) using <code>TestActorRef</code> due to its <em>synchronous</em> nature. These traits need to be able to perform asynchronous tasks in the background in order to handle internal persistence related events.</p>
<p>When testing Persistence based projects always rely on <a href="testing.html#async-integration-testing">asynchronous messaging using the TestKit</a>.</p></div>
<h2><a href="#configuration" name="configuration" class="anchor"><span class="anchor-link"></span></a>Configuration</h2>
<p>There are several configuration properties for the persistence module, please refer to the <a href="general/configuration.html#config-akka-persistence">reference configuration</a>.</p>
<h2><a href="#multiple-persistence-plugin-configurations" name="multiple-persistence-plugin-configurations" class="anchor"><span class="anchor-link"></span></a>Multiple persistence plugin configurations</h2>
<p>By default, a persistent actor will use the &ldquo;default&rdquo; journal and snapshot store plugins configured in the following sections of the <code>reference.conf</code> configuration resource:</p>
<pre class="prettyprint"><code class="language-scala"># Absolute path to the default journal plugin configuration entry.
akka.persistence.journal.plugin = &quot;akka.persistence.journal.inmem&quot;
# Absolute path to the default snapshot store plugin configuration entry.
akka.persistence.snapshot-store.plugin = &quot;akka.persistence.snapshot-store.local&quot;</code></pre>
<p>Note that in this case the actor overrides only the <code>persistenceId</code> method:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">trait ActorWithDefaultPlugins extends PersistentActor {
  override def persistenceId = &quot;123&quot;
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">abstract class ActorWithDefaultPlugins extends UntypedPersistentActor {
    @Override
    public String persistenceId() { return &quot;123&quot;; }
}</code></pre></dd>
</dl>
<p>When the persistent actor overrides the <code>journalPluginId</code> and <code>snapshotPluginId</code> methods, the actor will be serviced by these specific persistence plugins instead of the defaults:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">trait ActorWithOverridePlugins extends PersistentActor {
  override def persistenceId = &quot;123&quot;
  // Absolute path to the journal plugin configuration entry in the `reference.conf`.
  override def journalPluginId = &quot;akka.persistence.chronicle.journal&quot;
  // Absolute path to the snapshot store plugin configuration entry in the `reference.conf`.
  override def snapshotPluginId = &quot;akka.persistence.chronicle.snapshot-store&quot;
}</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">abstract class ActorWithOverridePlugins extends UntypedPersistentActor {
    @Override
    public String persistenceId() { return &quot;123&quot;; }
    // Absolute path to the journal plugin configuration entry in the `reference.conf`
    @Override
    public String journalPluginId() { return &quot;akka.persistence.chronicle.journal&quot;; }
    // Absolute path to the snapshot store plugin configuration entry in the `reference.conf`
    @Override
    public String snapshotPluginId() { return &quot;akka.persistence.chronicle.snapshot-store&quot;; }
}</code></pre></dd>
</dl>
<p>Note that <code>journalPluginId</code> and <code>snapshotPluginId</code> must refer to properly configured <code>reference.conf</code> plugin entries with a standard <code>class</code> property as well as settings which are specific for those plugins, i.e.:</p>
<pre class="prettyprint"><code class="language-scala"># Configuration entry for the custom journal plugin, see `journalPluginId`.
akka.persistence.chronicle.journal {
  # Standard persistence extension property: provider FQCN.
  class = &quot;akka.persistence.chronicle.ChronicleSyncJournal&quot;
  # Custom setting specific for the journal `ChronicleSyncJournal`.
  folder = $${user.dir}/store/journal
}
# Configuration entry for the custom snapshot store plugin, see `snapshotPluginId`.
akka.persistence.chronicle.snapshot-store {
  # Standard persistence extension property: provider FQCN.
  class = &quot;akka.persistence.chronicle.ChronicleSnapshotStore&quot;
  # Custom setting specific for the snapshot store `ChronicleSnapshotStore`.
  folder = $${user.dir}/store/snapshot
}</code></pre>
</div>
</article>

<div class="row">
<div class="small-12 large-9 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="../scala/fsm.html"><i class="icon-prev"></i> <span class="link-prev">FSM</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="../scala/persistence-schema-evolution.html">Persistence - Schema Evolution <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>

<div class="source-github row">
The source code for this page can be found <a href="http://github.com/akka/akka/tree/master/akka-docs/src/main/paradox/scala/persistence.md">here</a>.
</div>


<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="../images/akka-icon.svg">
<section class="copyright">
<div>&copy; 2011-2017 <a href="https://www.lightbend.com">Lightbend</a></div>
<div>Akka is Open Source and available under the Apache 2 License.</div>
</section>
</footer>

</section>
</main>

<script type="text/javascript" src="../js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="../js/groups.js"></script>
<script type="text/javascript" src="../js/page.js"></script>
<script type="text/javascript" src="../js/magellan.js"></script>

<style type="text/css">@import "../lib/prettify/prettify.css";</style>
<script type="text/javascript" src="../lib/prettify/prettify.js"></script>
<script type="text/javascript" src="../lib/prettify/lang-scala.js"></script>
<script type="text/javascript">jQuery(function(){window.prettyPrint && prettyPrint()});</script>

<!-- Algolia docs search -->
<script type="text/javascript" src="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.js"></script>
<style>.algolia-autocomplete { display: block !important }</style>
<script type="text/javascript">
var lang = "scala";
var path = window.location.pathname;
if (path.includes("/java/") || path.includes("java.html")) {
lang = "java";
}

docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#search',
algoliaOptions: {
hitsPerPage: 5,
facetFilters: ["language:" + lang]
}
});

docsearch({
apiKey: '543bad5ad786495d9ccd445ed34ed082',
indexName: 'akka_io',
inputSelector: '#overlay-search',
algoliaOptions: {
hitsPerPage: 5,
facetFilters: ["language:" + lang]
}
});

// set up "/" as global shortcut for focusing on search
jQuery(document).keypress(function (event) {
if (event.keyCode == 47) {
jQuery("#search").focus();
return false; // swallow key event, otherwise the / char would be input into the search box
}
});
</script>


</body>
</html>
