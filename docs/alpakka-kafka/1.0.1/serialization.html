<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Serialization &bull; Alpakka Kafka Documentation</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="Alpakka Kafka"/>
<link rel="canonical" href="https://doc.akka.io/docs/alpakka-kafka/current/serialization.html"/>
<script type="text/javascript" src="lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="css/icons.css"/>
<link rel="stylesheet" type="text/css" href="css/page.css"/>
<link rel="shortcut icon" href="images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png"/>
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png"/>
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png"/>
<link rel="manifest" href="images/manifest.json"/>
<meta name="msapplication-TileImage" content="images/mstile-150x150.png"/>
<meta name="msapplication-TileColor" content="#15a9ce"/>
<meta name="theme-color" content="#15a9ce"/>
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', '']);
_gaq.push(['_setDomainName', '']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<script type="text/plain" class="optanon-category-2">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-23127719-1', 'lightbend.com', {'allowLinker': true, 'name': 'tsTracker'});
ga('tsTracker.require', 'linker');
ga('tsTracker.linker:autoLink', ['lightbend.com','playframework.com','scala-lang.org','scaladays.org','spray.io','akka.io','scala-sbt.org','scala-ide.org']);
ga('tsTracker.send', 'pageview');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="http://akka.io"><img class="logo" src="images/akka-alpakka-reverse.svg"></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka Kafka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 1.0.1
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="home.html" class="page">Overview</a></li>
  <li><a href="producer.html" class="page">Producer</a></li>
  <li><a href="consumer.html" class="page">Consumer</a></li>
  <li><a href="errorhandling.html" class="page">Error handling</a></li>
  <li><a href="atleastonce.html" class="page">At-Least-Once Delivery</a></li>
  <li><a href="transactions.html" class="page">Transactions</a></li>
  <li><a href="serialization.html#serialization" class="active page">Serialization</a>
  <ul>
    <li><a href="serialization.html#jackson-json" class="header">Jackson JSON</a></li>
    <li><a href="serialization.html#spray-json" class="header">Spray JSON</a></li>
    <li><a href="serialization.html#avro-with-schema-registry" class="header">Avro with Schema Registry</a></li>
  </ul></li>
  <li><a href="debugging.html" class="page">Debugging</a></li>
  <li><a href="testing.html" class="page">Testing</a></li>
  <li><a href="production.html" class="page">Production considerations</a></li>
  <li><a href="snapshots.html" class="page">Snapshots</a></li>
</ul>
</nav>
</div>
</header>

<aside class="show-for-large">
<header class="nav-header fixed-sidebar-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka Kafka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 1.0.1
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="site-nav fixed-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="home.html" class="page">Overview</a></li>
  <li><a href="producer.html" class="page">Producer</a></li>
  <li><a href="consumer.html" class="page">Consumer</a></li>
  <li><a href="errorhandling.html" class="page">Error handling</a></li>
  <li><a href="atleastonce.html" class="page">At-Least-Once Delivery</a></li>
  <li><a href="transactions.html" class="page">Transactions</a></li>
  <li><a href="serialization.html#serialization" class="active page">Serialization</a>
  <ul>
    <li><a href="serialization.html#jackson-json" class="header">Jackson JSON</a></li>
    <li><a href="serialization.html#spray-json" class="header">Spray JSON</a></li>
    <li><a href="serialization.html#avro-with-schema-registry" class="header">Avro with Schema Registry</a></li>
  </ul></li>
  <li><a href="debugging.html" class="page">Debugging</a></li>
  <li><a href="testing.html" class="page">Testing</a></li>
  <li><a href="production.html" class="page">Production considerations</a></li>
  <li><a href="snapshots.html" class="page">Snapshots</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer fixed-sidebar-footer">
<a href="http://akka.io"><img class="logo" src="images/akka-alpakka-reverse.svg"></a>

</footer>
</aside>

<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">

<article class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#serialization" name="serialization" class="anchor"><span class="anchor-link"></span></a>Serialization</h1>
<p>The general recommendation for de-/serialization of messages is to use byte arrays (or Strings) as value and do the de-/serialization in a <code>map</code> operation in the Akka Stream instead of implementing it directly in Kafka de-/serializers. When deserialization is handled explicitly within the Akka Stream, it is easier to implement the desired error handling strategy as the examples below show.</p>
<h2><a href="#jackson-json" name="jackson-json" class="anchor"><span class="anchor-link"></span></a>Jackson JSON</h2>
<p>Serializing data to JSON text with <a href="https://github.com/FasterXML/jackson">Jackson</a> in a <code>map</code> operator will turn the object instance into a String which is used as value in the <code>ProducerRecord</code>.</p>
<dl>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/java/docs/javadsl/SerializationTest.java#L23-L26" target="_blank" title="Go to snippet source"></a><code class="language-java">import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectReader;
import com.fasterxml.jackson.databind.ObjectWriter;
import com.fasterxml.jackson.core.JsonParseException;

final ObjectMapper mapper = new ObjectMapper();
final ObjectWriter sampleDataWriter = mapper.writerFor(SampleData.class);

CompletionStage&lt;Done&gt; producerCompletion =
    Source.from(samples)
        .map(sampleDataWriter::writeValueAsString)
        .map(json -&gt; new ProducerRecord&lt;String, String&gt;(topic, json))
        .runWith(Producer.plainSink(producerDefaults()), mat);</code></pre></dd>
</dl>
<p>To de-serialize a JSON String with Jackson in a <code>map</code> operator, extract the String and apply the Jackson object reader in a <code>map</code> operator. Amend the <code>map</code> operator with the extracted type as the object reader is not generic.</p>
<p>This example uses resuming to react on data which can&rsquo;t be parsed correctly and ignores faulty elements.</p>
<dl>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/java/docs/javadsl/SerializationTest.java#L23-L26" target="_blank" title="Go to snippet source"></a><code class="language-java">import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectReader;
import com.fasterxml.jackson.databind.ObjectWriter;
import com.fasterxml.jackson.core.JsonParseException;

final ObjectMapper mapper = new ObjectMapper();
final ObjectReader sampleDataReader = mapper.readerFor(SampleData.class);

final Attributes resumeOnParseException =
    ActorAttributes.withSupervisionStrategy(
        exception -&gt; {
          if (exception instanceof JsonParseException) {
            return Supervision.resume();
          } else {
            return Supervision.stop();
          }
        });

Consumer.DrainingControl&lt;List&lt;SampleData&gt;&gt; control =
    Consumer.plainSource(consumerSettings, Subscriptions.topics(topic))
        .map(ConsumerRecord::value)
        .&lt;SampleData&gt;map(sampleDataReader::readValue)
        .withAttributes(resumeOnParseException) // drop faulty elements
        .toMat(Sink.seq(), Keep.both())
        .mapMaterializedValue(Consumer::createDrainingControl)
        .run(mat);</code></pre></dd>
</dl>
<h2><a href="#spray-json" name="spray-json" class="anchor"><span class="anchor-link"></span></a>Spray JSON</h2>
<p>To de-serialize a JSON String with <a href="https://github.com/spray/spray-json">Spray JSON</a> in a <code>map</code> operator, extract the String and use the Spray-provided implicits <code>parseJson</code> and <code>convertTo</code> in a <code>map</code> operator. </p>
<p>This example uses resuming to react on data which can&rsquo;t be parsed correctly and ignores faulty elements.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/scala/docs/scaladsl/SerializationSpec.scala#L47" target="_blank" title="Go to snippet source"></a><code class="language-scala">import spray.json._

final case class SampleData(name: String, value: Int)

object SampleDataSprayProtocol extends DefaultJsonProtocol {
  implicit val sampleDataProtocol: RootJsonFormat[SampleData] = jsonFormat2(SampleData)
}

import SampleDataSprayProtocol._

    val resumeOnParsingException = ActorAttributes.withSupervisionStrategy {
      new akka.japi.function.Function[Throwable, Supervision.Directive] {
        override def apply(t: Throwable): Supervision.Directive = t match {
          case _: spray.json.JsonParser.ParsingException =&gt; Supervision.Resume
          case _ =&gt; Supervision.stop
        }
      }
    }

    val consumer = Consumer
      .plainSource(consumerSettings, Subscriptions.topics(topic))
      .map { consumerRecord =&gt;
        val value = consumerRecord.value()
        val sampleData = value.parseJson.convertTo[SampleData]
        sampleData
      }
      .withAttributes(resumeOnParsingException)
      .toMat(Sink.seq)(Keep.both)
      .mapMaterializedValue(DrainingControl.apply)
      .run()</code></pre></dd>
</dl>
<h2><a href="#avro-with-schema-registry" name="avro-with-schema-registry" class="anchor"><span class="anchor-link"></span></a>Avro with Schema Registry</h2>
<p>If you want to use <a href="https://docs.confluent.io/current/schema-registry/docs/index.html">Confluent&rsquo;s Schema Registry</a>, you need to include the dependency on <code>kafka-avro-serializer</code> as shown below. It is not available from Maven Central, that&rsquo;s why Confluent&rsquo;s repository has to be specified. These examples use <code>kafka-avro-seriazlizer</code> version 5.0.1.</p>
<dl>
  <dt>Maven</dt>
  <dd>
  <pre class="prettyprint"><code class="language-xml">&lt;project&gt;
...
  &lt;dependencies&gt;
    ...
    &lt;dependency&gt;
      &lt;groupId&gt;io.confluent&lt;/groupId&gt;
      &lt;artifactId&gt;kafka-avro-serializer&lt;/artifactId&gt;
      &lt;version&gt;confluent.version (eg. 5.0.0)&lt;/version&gt;
    &lt;/dependency&gt;
    ...
  &lt;/dependencies&gt;
  ...
  &lt;repositories&gt;
    &lt;repository&gt;
      &lt;id&gt;confluent-maven-repo&lt;/id&gt;
      &lt;name&gt;Confluent Maven Repository&lt;/name&gt;
      &lt;url&gt;https://packages.confluent.io/maven/&lt;/url&gt;
    &lt;/repository&gt;
  &lt;/repositories&gt;
...
&lt;/project&gt;
</code></pre></dd>
  <dt>sbt</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">libraryDependencies += &quot;io.confluent&quot; % &quot;kafka-avro-serializer&quot; % confluentAvroVersion, //  eg. 5.0.0
resolvers += &quot;Confluent Maven Repository&quot; at &quot;https://packages.confluent.io/maven/&quot;,
</code></pre></dd>
  <dt>Gradle</dt>
  <dd>
  <pre class="prettyprint"><code class="language-gradle">dependencies {
  compile group: &#39;io.confluent&#39;, name: &#39;kafka-avro-serializer&#39;, version: confluentAvroVersion // eg. 5.0.0
}
repositories {
  maven {
    url  &quot;https://packages.confluent.io/maven/&quot;
  }
}
</code></pre></dd>
</dl>
<h3><a href="#producer" name="producer" class="anchor"><span class="anchor-link"></span></a>Producer</h3>
<p>To create serializers that use the Schema Registry, its URL needs to be provided as configuration <code>AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG</code> to the serializer and that serializer is used in the <code>ProducerSettings</code>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/scala/docs/scaladsl/SerializationSpec.scala#L23-L35" target="_blank" title="Go to snippet source"></a><code class="language-scala">import io.confluent.kafka.serializers.{AbstractKafkaAvroSerDeConfig, KafkaAvroDeserializer, KafkaAvroSerializer}
import org.apache.avro.specific.SpecificRecord
import org.apache.kafka.common.serialization._

val kafkaAvroSerDeConfig = Map[String, Any] {
  AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG -&gt; schemaRegistryUrl
}
val producerSettings: ProducerSettings[String, SpecificRecord] = {
  val kafkaAvroSerializer = new KafkaAvroSerializer()
  kafkaAvroSerializer.configure(kafkaAvroSerDeConfig.asJava, false)
  val serializer = kafkaAvroSerializer.asInstanceOf[Serializer[SpecificRecord]]

  ProducerSettings(system, new StringSerializer, serializer)
    .withBootstrapServers(bootstrapServers)
}

val sample = new SampleAvroClass(&quot;key&quot;, &quot;name&quot;)
val samples = immutable.Seq(sample, sample, sample)
val producerCompletion =
  Source(samples)
    .map(n =&gt; new ProducerRecord[String, SpecificRecord](topic, n.key, n))
    .runWith(Producer.plainSink(producerSettings))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/java/docs/javadsl/SerializationTest.java#L30-L41" target="_blank" title="Go to snippet source"></a><code class="language-java">import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

Map&lt;String, Object&gt; kafkaAvroSerDeConfig = new HashMap&lt;&gt;();
kafkaAvroSerDeConfig.put(
    AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, schemaRegistryUrl);
KafkaAvroSerializer kafkaAvroSerializer = new KafkaAvroSerializer();
kafkaAvroSerializer.configure(kafkaAvroSerDeConfig, false);
Serializer&lt;Object&gt; serializer = kafkaAvroSerializer;

ProducerSettings&lt;String, Object&gt; producerSettings =
    ProducerSettings.create(sys, new StringSerializer(), serializer)
        .withBootstrapServers(bootstrapServers());

SampleAvroClass sample = new SampleAvroClass(&quot;key&quot;, &quot;name&quot;);
List&lt;SampleAvroClass&gt; samples = Arrays.asList(sample, sample, sample);
CompletionStage&lt;Done&gt; producerCompletion =
    Source.from(samples)
        .map(n -&gt; new ProducerRecord&lt;String, Object&gt;(topic, n.key(), n))
        .runWith(Producer.plainSink(producerSettings), mat);</code></pre></dd>
</dl>
<h3><a href="#consumer" name="consumer" class="anchor"><span class="anchor-link"></span></a>Consumer</h3>
<p>To create deserializers that use the Schema Registry, its URL needs to be provided as configuration <code>AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG</code> to the deserializer and that deserializer is used in the <code>ConsumerSettings</code>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/scala/docs/scaladsl/SerializationSpec.scala#L23-L35" target="_blank" title="Go to snippet source"></a><code class="language-scala">import io.confluent.kafka.serializers.{AbstractKafkaAvroSerDeConfig, KafkaAvroDeserializer, KafkaAvroSerializer}
import org.apache.avro.specific.SpecificRecord
import org.apache.kafka.common.serialization._

val kafkaAvroSerDeConfig = Map[String, Any] {
  AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG -&gt; schemaRegistryUrl
}
val consumerSettings: ConsumerSettings[String, SpecificRecord] = {
  val kafkaAvroDeserializer = new KafkaAvroDeserializer()
  kafkaAvroDeserializer.configure(kafkaAvroSerDeConfig.asJava, false)
  val deserializer = kafkaAvroDeserializer.asInstanceOf[Deserializer[SpecificRecord]]

  ConsumerSettings(system, new StringDeserializer, deserializer)
    .withBootstrapServers(bootstrapServers)
    .withGroupId(group)
    .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)
}

val (control, result) =
  Consumer
    .plainSource(consumerSettings, Subscriptions.topics(topic))
    .take(samples.size.toLong)
    .toMat(Sink.seq)(Keep.both)
    .run()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/tests/src/test/java/docs/javadsl/SerializationTest.java#L30-L41" target="_blank" title="Go to snippet source"></a><code class="language-java">import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

Map&lt;String, Object&gt; kafkaAvroSerDeConfig = new HashMap&lt;&gt;();
kafkaAvroSerDeConfig.put(
    AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, schemaRegistryUrl);
KafkaAvroDeserializer kafkaAvroDeserializer = new KafkaAvroDeserializer();
kafkaAvroDeserializer.configure(kafkaAvroSerDeConfig, false);
Deserializer&lt;Object&gt; deserializer = kafkaAvroDeserializer;

ConsumerSettings&lt;String, Object&gt; consumerSettings =
    ConsumerSettings.create(sys, new StringDeserializer(), deserializer)
        .withBootstrapServers(bootstrapServers())
        .withGroupId(group)
        .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);

Consumer.DrainingControl&lt;List&lt;ConsumerRecord&lt;String, Object&gt;&gt;&gt; controlCompletionStagePair =
    Consumer.plainSource(consumerSettings, Subscriptions.topics(topic))
        .take(samples.size())
        .toMat(Sink.seq(), Keep.both())
        .mapMaterializedValue(Consumer::createDrainingControl)
        .run(mat);</code></pre></dd>
</dl>
</div>
</article>

<div class="row">
<div class="small-12 large-9 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="transactions.html"><i class="icon-prev"></i> <span class="link-prev">Transactions</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="debugging.html">Debugging <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>

<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/akka/alpakka-kafka/tree/v1.0.1/docs/src/main/paradox/serialization.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>


<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="images/akka-icon.svg"/>
<section class="copyright">
<div>Alpakka Kafka is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2019 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> | 
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> | 
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> | 
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> | 
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> | 
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>
</footer>

</section>
</main>

<script type="text/javascript" src="js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="js/groups.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<script type="text/javascript" src="js/magellan.js"></script>

<style type="text/css">@import "lib/prettify/prettify.css";</style>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">//<![CDATA[
jQuery(function(){window.prettyPrint && prettyPrint()});
//]]></script>
<script type="text/javascript" src="assets/js/warnOldVersion.js"></script>
<script type="text/javascript">jQuery(function(jq){initOldVersionWarnings(jq, '1.0.1', 'https://doc.akka.io/docs/alpakka-kafka/current/')});</script>


</body>
</html>
