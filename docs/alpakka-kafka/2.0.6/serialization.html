<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Serialization &bull; Alpakka Kafka Documentation</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="Alpakka is a Reactive Enterprise Integration library for Java and Scala, based on Reactive Streams and Akka."/>
<link rel="canonical" href="https://doc.akka.io/docs/alpakka-kafka/current/serialization.html"/>
<script type="text/javascript" src="lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="css/icons.css"/>
<link rel="stylesheet" type="text/css" href="css/page-7.css"/>
<link rel="stylesheet" type="text/css" href="css/banner-1.css"/>
<link rel="shortcut icon" href="images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png"/>
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png"/>
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png"/>
<link rel="manifest" href="images/manifest.json"/>
<meta name="msapplication-TileImage" content="images/mstile-150x150.png"/>
<meta name="msapplication-TileColor" content="#15a9ce"/>
<meta name="theme-color" content="#15a9ce"/>
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"/>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', '']);
_gaq.push(['_setDomainName', '']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<!-- Google Tag Manager -->
<script type="text/plain" class="optanon-category-2">
(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-KBJGH35');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">
<div id="lightbend-banner" class="lightbend-banner akka full-width" data-category="OSS Lightbend Banner Impression" data-label="Akka Banner Impression">
<div class="wrapper">
<div class="brand">
<a class="oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Lightbend Logo - Akka Banner" href="https://www.lightbend.com?r=oss-banner-akka" target="_blank">
<img class="lightbend-logo" src="images/banner-logos/lightbend-reverse.svg" alt="Lightbend" title="Lightbend">
</a>
</div>
<div class="nav">
<a class="banner-btn oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Enhance your Akka systems with Akka Platform [Button] - Akka Banner" href="https://www.lightbend.com/akka-platform?r=oss-banner-akka" target="_blank">
<span>Enhance your Akka systems with</span>
<img class="akka-platform-reverse-logo" src="images/banner-logos/akka-platform-reverse.svg" alt="Akka Platform" title="Akka Platform">
</a>
<div class="drop-down">
<svg class="svg-chevon-circle-down" version="1.1" id="Chevron_circled_down" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 20 20" enable-background="new 0 0 20 20" xml:space="preserve">
<path fill="#ffffff" d="M12.505,8.698L10,11L7.494,8.698c-0.198-0.196-0.518-0.196-0.718,0c-0.197,0.196-0.197,0.515,0,0.71l2.864,2.807
c0.199,0.196,0.52,0.196,0.717,0l2.864-2.807c0.199-0.195,0.198-0.514,0-0.71C13.024,8.502,12.704,8.502,12.505,8.698z M10,0.4
c-5.302,0-9.6,4.298-9.6,9.6c0,5.303,4.298,9.6,9.6,9.6s9.6-4.297,9.6-9.6C19.6,4.698,15.302,0.4,10,0.4z M10,18.354
c-4.615,0-8.354-3.74-8.354-8.354c0-4.614,3.739-8.354,8.354-8.354c4.613,0,8.354,3.74,8.354,8.354
C18.354,14.614,14.613,18.354,10,18.354z" />
</svg>
<div class="drop-down-content">
<div class="lightbend-family">
<a href="https://cloudflow.io" class="cloudflow oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Cloudflow - Logo Tag Line - Akka Banner">
<img class="cloudflow-full-color-logo" src="images/banner-logos/cloudflow-full-color.svg" alt="Cloudflow by Lightbend" title="Cloudflow by Lightbend">
</a>
<a href="https://cloudstate.io" class="cloudstate oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Cloudstate - Logo Tag Line - Akka Banner">
<img class="cloudstate-full-color-logo" src="images/banner-logos/cloudstate-full-color.svg" alt="Cloudstate by Lightbend" title="Cloudstate by Lightbend">
</a>
<a href="https://www.lagomframework.com" class="lagom oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Lagom - Logo Tag Line - Akka Banner">
<img class="lagom-full-color-logo" src="images/banner-logos/lagom-full-color.svg" alt="Lagom Framework by Lightbend" title="Lagom Framework by Lightbend">
</a>
<a href="https://www.playframework.com" class="play oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Play - Logo Tag Line - Akka Banner">
<img class="play-full-color-logo" src="images/banner-logos/play-full-color.svg" alt="Play Framework by Lightbend" title="Play Framework by Lightbend">
</a>
<a href="https://www.scala-lang.org" class="scala oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Scala - Logo Tag Line - Akka Banner">
<img class="scala-full-color-logo" src="images/banner-logos/scala-full-color.svg" alt="Scala by Lightbend" title="Scala by Lightbend">
</a>
<div class="akka current">
<img class="akka-full-color-logo" src="images/banner-logos/akka-full-color.svg" alt="Akka by Lightbend" title="Akka by Lightbend">
<span>From the creators of <strong>Akka</strong>, get technology enhancements, monitoring, and expert support with Akka Platform from Lightbend.</span>
<a class="oss-track-link-label" data-category="OSS Lightbend Banner Clicks" data-label="Learn More [Button] - Akka Banner" href="https://www.lightbend.com/akka-platform?r=oss-banner-akka" target="_blank">Learn More</a>
</div>
</div>
<div class="title">The Lightbend Family</div>
</div>      
</div>
</div>
</div>
</div>

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="https://akka.io"><img class="logo" src="images/akka-alpakka-reverse.svg"></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka Kafka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 2.0.6
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="home.html" class="page">Overview</a></li>
  <li><a href="producer.html" class="page">Producer</a></li>
  <li><a href="consumer.html" class="page">Consumer</a></li>
  <li><a href="discovery.html" class="page">Service discovery</a></li>
  <li><a href="cluster-sharding.html" class="page">Akka Cluster Sharding</a></li>
  <li><a href="errorhandling.html" class="page">Error handling</a></li>
  <li><a href="atleastonce.html" class="page">At-Least-Once Delivery</a></li>
  <li><a href="transactions.html" class="page">Transactions</a></li>
  <li><a href="serialization.html#serialization" class="active page">Serialization</a>
  <ul>
    <li><a href="serialization.html#protocol-buffers" class="header">Protocol buffers</a></li>
    <li><a href="serialization.html#jackson-json" class="header">Jackson JSON</a></li>
    <li><a href="serialization.html#spray-json" class="header">Spray JSON</a></li>
    <li><a href="serialization.html#avro-with-schema-registry" class="header">Avro with Schema Registry</a></li>
  </ul></li>
  <li><a href="debugging.html" class="page">Debugging</a></li>
  <li><a href="testing.html" class="page">Testing</a></li>
  <li><a href="production.html" class="page">Production considerations</a></li>
  <li><a href="snapshots.html" class="page">Snapshots</a></li>
</ul>
</nav>
</div>
</header>
<div class="site-content-wrapper">
<aside class="sticky-sidebar show-for-large">
<header class="nav-header sticky-sidebar-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka Kafka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 2.0.6
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="site-nav sticky-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="home.html" class="page">Overview</a></li>
  <li><a href="producer.html" class="page">Producer</a></li>
  <li><a href="consumer.html" class="page">Consumer</a></li>
  <li><a href="discovery.html" class="page">Service discovery</a></li>
  <li><a href="cluster-sharding.html" class="page">Akka Cluster Sharding</a></li>
  <li><a href="errorhandling.html" class="page">Error handling</a></li>
  <li><a href="atleastonce.html" class="page">At-Least-Once Delivery</a></li>
  <li><a href="transactions.html" class="page">Transactions</a></li>
  <li><a href="serialization.html#serialization" class="active page">Serialization</a>
  <ul>
    <li><a href="serialization.html#protocol-buffers" class="header">Protocol buffers</a></li>
    <li><a href="serialization.html#jackson-json" class="header">Jackson JSON</a></li>
    <li><a href="serialization.html#spray-json" class="header">Spray JSON</a></li>
    <li><a href="serialization.html#avro-with-schema-registry" class="header">Avro with Schema Registry</a></li>
  </ul></li>
  <li><a href="debugging.html" class="page">Debugging</a></li>
  <li><a href="testing.html" class="page">Testing</a></li>
  <li><a href="production.html" class="page">Production considerations</a></li>
  <li><a href="snapshots.html" class="page">Snapshots</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer sticky-sidebar-footer">
<a href="https://akka.io"><img class="logo" src="images/akka-alpakka-reverse.svg"></a>

</footer>
</aside>
<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">
<article class="page-content row">
<div class="small-12 column" id="docs">
<h1><a href="#serialization" name="serialization" class="anchor"><span class="anchor-link"></span></a>Serialization</h1>
<p>The general recommendation for de-/serialization of messages is to use byte arrays (or Strings) as value and do the de-/serialization in a <code>map</code> operation in the Akka Stream instead of implementing it directly in Kafka de-/serializers. When deserialization is handled explicitly within the Akka Stream, it is easier to implement the desired error handling strategy as the examples below show.</p>
<h2><a href="#protocol-buffers" name="protocol-buffers" class="anchor"><span class="anchor-link"></span></a>Protocol buffers</h2>
<p><a href="https://developers.google.com/protocol-buffers">Protocol Buffers</a> offer a language-neutral, platform-neutral, extensible mechanism for serializing structured data and allow consumers and producers to rely on the message format.</p>
<p>The easiest way to use Protocol Buffers with Alpakka Kafka is to serialize and deserialize the Kafka message payload as a byte array and call the Protocol Buffers serialization and deserialization in a regular <code>map</code> operator. To serialize the Protobuf-defined type <code>Order</code> into a byte array use the <code>.toByteArray()</code> method which gets generated by the Protobuf compiler.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/scala/docs/scaladsl/SerializationSpec.scala#L77-L79" target="_blank" title="Go to snippet source"></a><code class="language-scala">// the Protobuf generated class
import docs.scaladsl.proto.Order

val producerSettings: ProducerSettings[String, Array[Byte]] = // ...

val producerCompletion =
  Source(samples)
    .map(order =&gt; new ProducerRecord(topic, order.id, order.toByteArray))
    .runWith(Producer.plainSink(producerSettings))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/java/docs/javadsl/SerializationTest.java#L28-L31" target="_blank" title="Go to snippet source"></a><code class="language-java">// the Protobuf generated class
import docs.javadsl.proto.OrderMessages;
import org.apache.kafka.common.serialization.ByteArrayDeserializer;
import org.apache.kafka.common.serialization.ByteArraySerializer;

ProducerSettings&lt;String, byte[]&gt; producerSettings = // ...

CompletionStage&lt;Done&gt; producerCompletion =
    Source.from(samples)
        .map(order -&gt; new ProducerRecord&lt;&gt;(topic, order.getId(), order.toByteArray()))
        .runWith(Producer.plainSink(producerSettings), mat);</code></pre></dd>
</dl>
<p>To de-serialize a Protocol Buffers message in a <code>map</code> operator, convert the received byte array to the designated type with the generated <code>parseFrom()</code> method.</p>
<p>This example uses resuming to react on data which can&rsquo;t be deserialized and ignores faulty elements.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/scala/docs/scaladsl/SerializationSpec.scala#L77-L79" target="_blank" title="Go to snippet source"></a><code class="language-scala">// the Protobuf generated class
import docs.scaladsl.proto.Order

val resumeOnParsingException = ActorAttributes.supervisionStrategy {
  case _: com.google.protobuf.InvalidProtocolBufferException =&gt; Supervision.Resume
  case _ =&gt; Supervision.stop
}

val consumerSettings: ConsumerSettings[String, Array[Byte]] = // ...

val consumer = Consumer
  .plainSource(consumerSettings, Subscriptions.topics(topic))
  .map { consumerRecord =&gt;
    Order.parseFrom(consumerRecord.value())
  }
  .withAttributes(resumeOnParsingException)
  .toMat(Sink.seq)(DrainingControl.apply)
  .run()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/java/docs/javadsl/SerializationTest.java#L28-L31" target="_blank" title="Go to snippet source"></a><code class="language-java">// the Protobuf generated class
import docs.javadsl.proto.OrderMessages;
import org.apache.kafka.common.serialization.ByteArrayDeserializer;
import org.apache.kafka.common.serialization.ByteArraySerializer;

final Attributes resumeOnParseException =
    ActorAttributes.withSupervisionStrategy(
        exception -&gt; {
          if (exception instanceof com.google.protobuf.InvalidProtocolBufferException) {
            return Supervision.resume();
          } else {
            return Supervision.stop();
          }
        });

ConsumerSettings&lt;String, byte[]&gt; consumerSettings = // ...

Consumer.DrainingControl&lt;List&lt;OrderMessages.Order&gt;&gt; control =
    Consumer.plainSource(consumerSettings, Subscriptions.topics(topic))
        .map(ConsumerRecord::value)
        .map(OrderMessages.Order::parseFrom)
        .withAttributes(resumeOnParseException) // drop faulty elements
        .toMat(Sink.seq(), Consumer::createDrainingControl)
        .run(mat);</code></pre></dd>
</dl>
<h2><a href="#jackson-json" name="jackson-json" class="anchor"><span class="anchor-link"></span></a>Jackson JSON</h2>
<p>Serializing data to JSON text with <a href="https://github.com/FasterXML/jackson">Jackson</a> in a <code>map</code> operator will turn the object instance into a String which is used as value in the <a href="https://kafka.apache.org/24/javadoc/?org/apache/kafka/clients/producer/ProducerRecord.html" title="org.apache.kafka.clients.producer.ProducerRecord"><code>ProducerRecord</code></a>.</p>
<dl>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/java/docs/javadsl/SerializationTest.java#L22-L25" target="_blank" title="Go to snippet source"></a><code class="language-java">import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectReader;
import com.fasterxml.jackson.databind.ObjectWriter;
import com.fasterxml.jackson.core.JsonParseException;

final ObjectMapper mapper = new ObjectMapper();
final ObjectWriter sampleDataWriter = mapper.writerFor(SampleData.class);

CompletionStage&lt;Done&gt; producerCompletion =
    Source.from(samples)
        .map(sampleDataWriter::writeValueAsString)
        .map(json -&gt; new ProducerRecord&lt;String, String&gt;(topic, json))
        .runWith(Producer.plainSink(producerDefaults()), mat);</code></pre></dd>
</dl>
<p>To de-serialize a JSON String with Jackson in a <code>map</code> operator, extract the String and apply the Jackson object reader in a <code>map</code> operator. Amend the <code>map</code> operator with the extracted type as the object reader is not generic.</p>
<p>This example uses resuming to react on data which can&rsquo;t be parsed correctly and ignores faulty elements.</p>
<dl>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/java/docs/javadsl/SerializationTest.java#L22-L25" target="_blank" title="Go to snippet source"></a><code class="language-java">import com.fasterxml.jackson.databind.ObjectMapper;
import com.fasterxml.jackson.databind.ObjectReader;
import com.fasterxml.jackson.databind.ObjectWriter;
import com.fasterxml.jackson.core.JsonParseException;

final ObjectMapper mapper = new ObjectMapper();
final ObjectReader sampleDataReader = mapper.readerFor(SampleData.class);

final Attributes resumeOnParseException =
    ActorAttributes.withSupervisionStrategy(
        exception -&gt; {
          if (exception instanceof JsonParseException) {
            return Supervision.resume();
          } else {
            return Supervision.stop();
          }
        });

Consumer.DrainingControl&lt;List&lt;SampleData&gt;&gt; control =
    Consumer.plainSource(consumerSettings, Subscriptions.topics(topic))
        .map(ConsumerRecord::value)
        .&lt;SampleData&gt;map(sampleDataReader::readValue)
        .withAttributes(resumeOnParseException) // drop faulty elements
        .toMat(Sink.seq(), Consumer::createDrainingControl)
        .run(mat);</code></pre></dd>
</dl>
<h2><a href="#spray-json" name="spray-json" class="anchor"><span class="anchor-link"></span></a>Spray JSON</h2>
<p>To de-serialize a JSON String with <a href="https://github.com/spray/spray-json">Spray JSON</a> in a <code>map</code> operator, extract the String and use the Spray-provided implicits <code>parseJson</code> and <code>convertTo</code> in a <code>map</code> operator. </p>
<p>This example uses resuming to react on data which can&rsquo;t be parsed correctly and ignores faulty elements.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/scala/docs/scaladsl/SerializationSpec.scala#L20" target="_blank" title="Go to snippet source"></a><code class="language-scala">import spray.json._

final case class SampleData(name: String, value: Int)

object SampleDataSprayProtocol extends DefaultJsonProtocol {
  implicit val sampleDataProtocol: RootJsonFormat[SampleData] = jsonFormat2(SampleData)
}

import SampleDataSprayProtocol._

    val resumeOnParsingException = ActorAttributes.supervisionStrategy {
      case _: spray.json.JsonParser.ParsingException =&gt; Supervision.Resume
      case _ =&gt; Supervision.stop
    }

    val consumer = Consumer
      .plainSource(consumerSettings, Subscriptions.topics(topic))
      .map { consumerRecord =&gt;
        val value = consumerRecord.value()
        val sampleData = value.parseJson.convertTo[SampleData]
        sampleData
      }
      .withAttributes(resumeOnParsingException)
      .toMat(Sink.seq)(DrainingControl.apply)
      .run()</code></pre></dd>
</dl>
<h2><a href="#avro-with-schema-registry" name="avro-with-schema-registry" class="anchor"><span class="anchor-link"></span></a>Avro with Schema Registry</h2>
<p>If you want to use <a href="https://docs.confluent.io/current/schema-registry/docs/index.html">Confluent&rsquo;s Schema Registry</a>, you need to include the dependency on <code>kafka-avro-serializer</code> as shown below. It is not available from Maven Central, that&rsquo;s why Confluent&rsquo;s repository has to be specified. These examples use <code>kafka-avro-seriazlizer</code> version 5.4.1.</p>
<dl>
  <dt>Maven</dt>
  <dd>
  <pre class="prettyprint"><code class="language-xml">&lt;project&gt;
...
  &lt;dependencies&gt;
    ...
    &lt;dependency&gt;
      &lt;groupId&gt;io.confluent&lt;/groupId&gt;
      &lt;artifactId&gt;kafka-avro-serializer&lt;/artifactId&gt;
      &lt;version&gt;confluent.version (eg. 5.0.0)&lt;/version&gt;
    &lt;/dependency&gt;
    ...
  &lt;/dependencies&gt;
  ...
  &lt;repositories&gt;
    &lt;repository&gt;
      &lt;id&gt;confluent-maven-repo&lt;/id&gt;
      &lt;name&gt;Confluent Maven Repository&lt;/name&gt;
      &lt;url&gt;https://packages.confluent.io/maven/&lt;/url&gt;
    &lt;/repository&gt;
  &lt;/repositories&gt;
...
&lt;/project&gt;
</code></pre></dd>
  <dt>sbt</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">libraryDependencies += &quot;io.confluent&quot; % &quot;kafka-avro-serializer&quot; % confluentAvroVersion, //  eg. 5.0.0
resolvers += &quot;Confluent Maven Repository&quot; at &quot;https://packages.confluent.io/maven/&quot;,
</code></pre></dd>
  <dt>Gradle</dt>
  <dd>
  <pre class="prettyprint"><code class="language-gradle">dependencies {
  compile group: &#39;io.confluent&#39;, name: &#39;kafka-avro-serializer&#39;, version: confluentAvroVersion // eg. 5.0.0
}
repositories {
  maven {
    url  &quot;https://packages.confluent.io/maven/&quot;
  }
}
</code></pre></dd>
</dl>
<h3><a href="#producer" name="producer" class="anchor"><span class="anchor-link"></span></a>Producer</h3>
<p>To create serializers that use the Schema Registry, its URL needs to be provided as configuration <code>AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG</code> to the serializer and that serializer is used in the <span class="group-scala"><a href="/api/alpakka-kafka/2.0.6/akka/kafka/ProducerSettings$.html" title="akka.kafka.ProducerSettings"><code>ProducerSettings</code></a></span><span class="group-java"><a href="/api/alpakka-kafka/2.0.6/akka/kafka/ProducerSettings$.html" title="akka.kafka.ProducerSettings"><code>ProducerSettings</code></a></span>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/scala/docs/scaladsl/SchemaRegistrySerializationSpec.scala#L27-L33" target="_blank" title="Go to snippet source"></a><code class="language-scala">import io.confluent.kafka.serializers.{AbstractKafkaAvroSerDeConfig, KafkaAvroDeserializer, KafkaAvroSerializer}
import org.apache.avro.specific.SpecificRecord
import org.apache.kafka.common.serialization._

val kafkaAvroSerDeConfig = Map[String, Any](
  AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG -&gt; schemaRegistryUrl,
  KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG -&gt; true.toString
)
val producerSettings: ProducerSettings[String, SpecificRecord] = {
  val kafkaAvroSerializer = new KafkaAvroSerializer()
  kafkaAvroSerializer.configure(kafkaAvroSerDeConfig.asJava, false)
  val serializer = kafkaAvroSerializer.asInstanceOf[Serializer[SpecificRecord]]

  ProducerSettings(system, new StringSerializer, serializer)
    .withBootstrapServers(bootstrapServers)
}

val samples = (1 to 3).map(i =&gt; SampleAvroClass(s&quot;key_$i&quot;, s&quot;name_$i&quot;))
val producerCompletion =
  Source(samples)
    .map(n =&gt; new ProducerRecord[String, SpecificRecord](topic, n.key, n))
    .runWith(Producer.plainSink(producerSettings))</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/java/docs/javadsl/SchemaRegistrySerializationTest.java#L24-L35" target="_blank" title="Go to snippet source"></a><code class="language-java">import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

Map&lt;String, Object&gt; kafkaAvroSerDeConfig = new HashMap&lt;&gt;();
kafkaAvroSerDeConfig.put(
    AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, getSchemaRegistryUrl());
KafkaAvroSerializer kafkaAvroSerializer = new KafkaAvroSerializer();
kafkaAvroSerializer.configure(kafkaAvroSerDeConfig, false);
Serializer&lt;Object&gt; serializer = kafkaAvroSerializer;

ProducerSettings&lt;String, Object&gt; producerSettings =
    ProducerSettings.create(sys, new StringSerializer(), serializer)
        .withBootstrapServers(bootstrapServers());

SampleAvroClass sample = new SampleAvroClass(&quot;key&quot;, &quot;name&quot;);
List&lt;SampleAvroClass&gt; samples = Arrays.asList(sample, sample, sample);
CompletionStage&lt;Done&gt; producerCompletion =
    Source.from(samples)
        .map(n -&gt; new ProducerRecord&lt;String, Object&gt;(topic, n.key(), n))
        .runWith(Producer.plainSink(producerSettings), mat);</code></pre></dd>
</dl>
<h3><a href="#consumer" name="consumer" class="anchor"><span class="anchor-link"></span></a>Consumer</h3>
<p>To create deserializers that use the Schema Registry, its URL needs to be provided as configuration <code>AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG</code> to the deserializer and that deserializer is used in the <span class="group-scala"><a href="/api/alpakka-kafka/2.0.6/akka/kafka/ConsumerSettings$.html" title="akka.kafka.ConsumerSettings"><code>ConsumerSettings</code></a></span><span class="group-java"><a href="/api/alpakka-kafka/2.0.6/akka/kafka/ConsumerSettings$.html" title="akka.kafka.ConsumerSettings"><code>ConsumerSettings</code></a></span>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/scala/docs/scaladsl/SchemaRegistrySerializationSpec.scala#L27-L33" target="_blank" title="Go to snippet source"></a><code class="language-scala">import io.confluent.kafka.serializers.{AbstractKafkaAvroSerDeConfig, KafkaAvroDeserializer, KafkaAvroSerializer}
import org.apache.avro.specific.SpecificRecord
import org.apache.kafka.common.serialization._

val kafkaAvroSerDeConfig = Map[String, Any](
  AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG -&gt; schemaRegistryUrl,
  KafkaAvroDeserializerConfig.SPECIFIC_AVRO_READER_CONFIG -&gt; true.toString
)
val consumerSettings: ConsumerSettings[String, SpecificRecord] = {
  val kafkaAvroDeserializer = new KafkaAvroDeserializer()
  kafkaAvroDeserializer.configure(kafkaAvroSerDeConfig.asJava, false)
  val deserializer = kafkaAvroDeserializer.asInstanceOf[Deserializer[SpecificRecord]]

  ConsumerSettings(system, new StringDeserializer, deserializer)
    .withBootstrapServers(bootstrapServers)
    .withGroupId(group)
    .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;)
}

val (control, result) =
  Consumer
    .plainSource(consumerSettings, Subscriptions.topics(topic))
    .take(samples.size.toLong)
    .map(_.value())
    .toMat(Sink.seq)(Keep.both)
    .run()</code></pre></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><a class="icon go-to-source" href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/tests/src/test/java/docs/javadsl/SchemaRegistrySerializationTest.java#L24-L35" target="_blank" title="Go to snippet source"></a><code class="language-java">import io.confluent.kafka.serializers.AbstractKafkaAvroSerDeConfig;
import io.confluent.kafka.serializers.KafkaAvroDeserializer;
import io.confluent.kafka.serializers.KafkaAvroSerializer;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.kafka.common.serialization.Serializer;
import org.apache.kafka.common.serialization.StringDeserializer;
import org.apache.kafka.common.serialization.StringSerializer;

Map&lt;String, Object&gt; kafkaAvroSerDeConfig = new HashMap&lt;&gt;();
kafkaAvroSerDeConfig.put(
    AbstractKafkaAvroSerDeConfig.SCHEMA_REGISTRY_URL_CONFIG, getSchemaRegistryUrl());
KafkaAvroDeserializer kafkaAvroDeserializer = new KafkaAvroDeserializer();
kafkaAvroDeserializer.configure(kafkaAvroSerDeConfig, false);
Deserializer&lt;Object&gt; deserializer = kafkaAvroDeserializer;

ConsumerSettings&lt;String, Object&gt; consumerSettings =
    ConsumerSettings.create(sys, new StringDeserializer(), deserializer)
        .withBootstrapServers(bootstrapServers())
        .withGroupId(group)
        .withProperty(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG, &quot;earliest&quot;);

Consumer.DrainingControl&lt;List&lt;ConsumerRecord&lt;String, Object&gt;&gt;&gt; controlCompletionStagePair =
    Consumer.plainSource(consumerSettings, Subscriptions.topics(topic))
        .take(samples.size())
        .toMat(Sink.seq(), Consumer::createDrainingControl)
        .run(mat);</code></pre></dd>
</dl>
</div>
</article>
<div class="row">
<div class="small-12 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="transactions.html"><i class="icon-prev"></i> <span class="link-prev">Transactions</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="debugging.html">Debugging <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>
<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/akka/alpakka-kafka/tree/v2.0.6/docs/src/main/paradox/serialization.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>

<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="images/akka-icon.svg" />
<section class="copyright">
<div>Alpakka Kafka is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2020 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> |
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> |
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> |
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> |
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> |
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>

</footer>
</section>
</main>
</div>

<script type="text/javascript" src="js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="js/groups.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<script type="text/javascript" src="js/magellan.js"></script>
<script type="text/javascript" src="js/metadata-toggle.js"></script>

<style type="text/css">@import "lib/prettify/prettify.css";</style>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">//<![CDATA[
jQuery(function(){window.prettyPrint && prettyPrint()});
//]]></script>
<script type="text/javascript" src="assets/js/warnOldVersion.js"></script>
<script type="text/javascript">jQuery(function(jq){initOldVersionWarnings(jq, '2.0.6', 'https://doc.akka.io/docs/alpakka-kafka/current')});</script>


</body>
</html>
