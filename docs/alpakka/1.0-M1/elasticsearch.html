<!DOCTYPE html>
<html class="no-js" lang="en">

<head>
<title>Elasticsearch &bull; Alpakka Documentation</title>
<meta charset="utf-8"/>
<meta name="viewport" content="width=device-width, initial-scale=1.0"/>
<meta name="description" content="Alpakka is a Reactive Enterprise Integration library for Java and Scala, based on Reactive Streams and Akka."/><link rel="canonical" href="https://doc.akka.io/docs/alpakka/current/elasticsearch.html"/>
<script type="text/javascript" src="lib/jquery/jquery.min.js"></script>
<script type="text/javascript" src="lib/foundation/dist/js/foundation.min.js"></script>
<link rel="stylesheet" type="text/css" href="lib/normalize.css/normalize.css"/>
<link rel="stylesheet" type="text/css" href="lib/foundation/dist/css/foundation.min.css"/>
<link rel="stylesheet" type="text/css" href="https://cdn.jsdelivr.net/docsearch.js/2/docsearch.min.css" />
<link rel="stylesheet" type="text/css" href="css/icons.css"/>
<link rel="stylesheet" type="text/css" href="css/page.css"/>
<link rel="shortcut icon" href="images/favicon.ico" />
<link rel="apple-touch-icon" sizes="180x180" href="images/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="images/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="images/favicon-16x16.png">
<link rel="manifest" href="images/manifest.json">
<meta name="msapplication-TileImage" content="images/mstile-150x150.png">
<meta name="msapplication-TileColor" content="#15a9ce">
<meta name="theme-color" content="#15a9ce">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) start -->
<script src="https://optanon.blob.core.windows.net/consent/159bb13d-6748-4399-806e-ac28db879785.js" type="text/javascript" charset="UTF-8"></script>
<script type="text/javascript">
function OptanonWrapper() { }
</script>
<!-- OneTrust Cookies Consent Notice (Production Standard, akka.io, en-GB) end -->
<!--Google Analytics-->
<script type="text/plain" class="optanon-category-2">
var _gaq = _gaq || [];
_gaq.push(['_setAccount', '']);
_gaq.push(['_setDomainName', '']);
_gaq.push(['_trackPageview']);
(function() {
var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
})()
</script>
<script type="text/plain" class="optanon-category-2">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-23127719-1', 'lightbend.com', {'allowLinker': true, 'name': 'tsTracker'});
ga('tsTracker.require', 'linker');
ga('tsTracker.linker:autoLink', ['lightbend.com','playframework.com','scala-lang.org','scaladays.org','spray.io','akka.io','scala-sbt.org','scala-ide.org']);
ga('tsTracker.send', 'pageview');
</script>
<!--Marketo-->
<script type="text/plain" class="optanon-category-3">
(function() {
var didInit = false;
function initMunchkin() {
if(didInit === false) {
didInit = true;
Munchkin.init('558-NCX-702', { 'asyncOnly': true, 'disableClickDelay': true });
}
}
var s = document.createElement('script');
s.type = 'text/javascript';
s.async = true;
s.src = '//munchkin.marketo.net/munchkin.js';
s.onreadystatechange = function() {
if (this.readyState == 'complete' || this.readyState == 'loaded') {
initMunchkin();
}
};
s.onload = initMunchkin;
document.getElementsByTagName('head')[0].appendChild(s);
})();
</script>
</head>

<body id="underlay" data-toggler="nav-open">

<header class="site-header hide-for-large">
<div class="sticky-header clearfix">
<a href="https://akka.io"><img class="logo" src="images/akka-alpakka-reverse.svg"></a>

<button class="menu-icon float-right" type="button" data-toggle="underlay overlay"></button>
</div>
<div id="overlay" class="overlay-nav" data-toggler="nav-open">
<header class="nav-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 1.0-M1
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="nav-toc">
<ul>
  <li><a href="overview.html" class="page">Overview</a></li>
  <li><a href="data-transformations/index.html" class="page">Data Transformations</a></li>
  <li><a href="amqp.html" class="page">AMQP</a></li>
  <li><a href="external/apache-camel.html" class="page">Apache Camel</a></li>
  <li><a href="cassandra.html" class="page">Apache Cassandra</a></li>
  <li><a href="geode.html" class="page">Apache Geode</a></li>
  <li><a href="kafka.html" class="page">Apache Kafka</a></li>
  <li><a href="kudu.html" class="page">Apache Kudu</a></li>
  <li><a href="solr.html" class="page">Apache Solr</a></li>
  <li><a href="avroparquet.html" class="page">Avro Parquet</a></li>
  <li><a href="dynamodb.html" class="page">AWS DynamoDB</a></li>
  <li><a href="kinesis.html" class="page">AWS Kinesis</a></li>
  <li><a href="awslambda.html" class="page">AWS Lambda</a></li>
  <li><a href="s3.html" class="page">AWS S3</a></li>
  <li><a href="sns.html" class="page">AWS SNS</a></li>
  <li><a href="sqs.html" class="page">AWS SQS</a></li>
  <li><a href="external/azure-event-hubs.html" class="page">Azure Event Hubs</a></li>
  <li><a href="external/azure-iot-hub.html" class="page">Azure IoT Hub</a></li>
  <li><a href="azure-storage-queue.html" class="page">Azure Storage Queue</a></li>
  <li><a href="external/couchbase.html" class="page">Couchbase</a></li>
  <li><a href="elasticsearch.html#elasticsearch" class="active page">Elasticsearch</a>
  <ul>
    <li><a href="elasticsearch.html#reported-issues" class="header">Reported issues</a></li>
    <li><a href="elasticsearch.html#artifacts" class="header">Artifacts</a></li>
    <li><a href="elasticsearch.html#set-up-rest-client" class="header">Set up REST client</a></li>
    <li><a href="elasticsearch.html#elasticsearch-as-source-and-sink" class="header">Elasticsearch as Source and Sink</a></li>
    <li><a href="elasticsearch.html#elasticsearch-as-flow" class="header">Elasticsearch as Flow</a></li>
  </ul></li>
  <li><a href="external/eventuate.html" class="page">Eventuate</a></li>
  <li><a href="file.html" class="page">Files</a></li>
  <li><a href="external/fs2.html" class="page">FS2</a></li>
  <li><a href="ftp.html" class="page">FTP</a></li>
  <li><a href="google-cloud-pub-sub.html" class="page">Google Cloud Pub/Sub</a></li>
  <li><a href="google-cloud-pub-sub-grpc.html" class="page">Google Cloud Pub/Sub gRPC</a></li>
  <li><a href="google-fcm.html" class="page">Google Firebase Cloud Messaging</a></li>
  <li><a href="external/grpc.html" class="page">gRPC</a></li>
  <li><a href="hdfs.html" class="page">Hadoop Distributed File System - HDFS</a></li>
  <li><a href="hbase.html" class="page">HBase</a></li>
  <li><a href="external/http.html" class="page">HTTP</a></li>
  <li><a href="ironmq.html" class="page">IronMQ</a></li>
  <li><a href="jms.html" class="page">JMS</a></li>
  <li><a href="mongodb.html" class="page">MongoDB</a></li>
  <li><a href="mqtt.html" class="page">MQTT</a></li>
  <li><a href="orientdb.html" class="page">OrientDB</a></li>
  <li><a href="external/pulsar.html" class="page">Pulsar</a></li>
  <li><a href="sse.html" class="page">Server-sent Events (SSE)</a></li>
  <li><a href="slick.html" class="page">Slick (JDBC)</a></li>
  <li><a href="spring-web.html" class="page">Spring Web</a></li>
  <li><a href="external/tcp.html" class="page">TCP</a></li>
  <li><a href="udp.html" class="page">UDP</a></li>
  <li><a href="unix-domain-socket.html" class="page">Unix Domain Socket</a></li>
</ul>
</nav>
</div>
</header>

<aside class="show-for-large">
<header class="nav-header fixed-sidebar-header">
<div class="nav-header-title">
<h1><a href="index.html">Alpakka Documentation</a></h1>
</div>
<div class="nav-header-version">
Version 1.0-M1
</div>
<div class="nav-header-groups">
<select class="supergroup" name="Language"><option class="group" value="group-java">Java</option><option class="group" value="group-scala">Scala</option></select>
</div>
</header>
<nav class="site-nav fixed-sidebar-contents">
<div class="nav-toc">
<ul>
  <li><a href="overview.html" class="page">Overview</a></li>
  <li><a href="data-transformations/index.html" class="page">Data Transformations</a></li>
  <li><a href="amqp.html" class="page">AMQP</a></li>
  <li><a href="external/apache-camel.html" class="page">Apache Camel</a></li>
  <li><a href="cassandra.html" class="page">Apache Cassandra</a></li>
  <li><a href="geode.html" class="page">Apache Geode</a></li>
  <li><a href="kafka.html" class="page">Apache Kafka</a></li>
  <li><a href="kudu.html" class="page">Apache Kudu</a></li>
  <li><a href="solr.html" class="page">Apache Solr</a></li>
  <li><a href="avroparquet.html" class="page">Avro Parquet</a></li>
  <li><a href="dynamodb.html" class="page">AWS DynamoDB</a></li>
  <li><a href="kinesis.html" class="page">AWS Kinesis</a></li>
  <li><a href="awslambda.html" class="page">AWS Lambda</a></li>
  <li><a href="s3.html" class="page">AWS S3</a></li>
  <li><a href="sns.html" class="page">AWS SNS</a></li>
  <li><a href="sqs.html" class="page">AWS SQS</a></li>
  <li><a href="external/azure-event-hubs.html" class="page">Azure Event Hubs</a></li>
  <li><a href="external/azure-iot-hub.html" class="page">Azure IoT Hub</a></li>
  <li><a href="azure-storage-queue.html" class="page">Azure Storage Queue</a></li>
  <li><a href="external/couchbase.html" class="page">Couchbase</a></li>
  <li><a href="elasticsearch.html#elasticsearch" class="active page">Elasticsearch</a>
  <ul>
    <li><a href="elasticsearch.html#reported-issues" class="header">Reported issues</a></li>
    <li><a href="elasticsearch.html#artifacts" class="header">Artifacts</a></li>
    <li><a href="elasticsearch.html#set-up-rest-client" class="header">Set up REST client</a></li>
    <li><a href="elasticsearch.html#elasticsearch-as-source-and-sink" class="header">Elasticsearch as Source and Sink</a></li>
    <li><a href="elasticsearch.html#elasticsearch-as-flow" class="header">Elasticsearch as Flow</a></li>
  </ul></li>
  <li><a href="external/eventuate.html" class="page">Eventuate</a></li>
  <li><a href="file.html" class="page">Files</a></li>
  <li><a href="external/fs2.html" class="page">FS2</a></li>
  <li><a href="ftp.html" class="page">FTP</a></li>
  <li><a href="google-cloud-pub-sub.html" class="page">Google Cloud Pub/Sub</a></li>
  <li><a href="google-cloud-pub-sub-grpc.html" class="page">Google Cloud Pub/Sub gRPC</a></li>
  <li><a href="google-fcm.html" class="page">Google Firebase Cloud Messaging</a></li>
  <li><a href="external/grpc.html" class="page">gRPC</a></li>
  <li><a href="hdfs.html" class="page">Hadoop Distributed File System - HDFS</a></li>
  <li><a href="hbase.html" class="page">HBase</a></li>
  <li><a href="external/http.html" class="page">HTTP</a></li>
  <li><a href="ironmq.html" class="page">IronMQ</a></li>
  <li><a href="jms.html" class="page">JMS</a></li>
  <li><a href="mongodb.html" class="page">MongoDB</a></li>
  <li><a href="mqtt.html" class="page">MQTT</a></li>
  <li><a href="orientdb.html" class="page">OrientDB</a></li>
  <li><a href="external/pulsar.html" class="page">Pulsar</a></li>
  <li><a href="sse.html" class="page">Server-sent Events (SSE)</a></li>
  <li><a href="slick.html" class="page">Slick (JDBC)</a></li>
  <li><a href="spring-web.html" class="page">Spring Web</a></li>
  <li><a href="external/tcp.html" class="page">TCP</a></li>
  <li><a href="udp.html" class="page">UDP</a></li>
  <li><a href="unix-domain-socket.html" class="page">Unix Domain Socket</a></li>
</ul>
</div>
</nav>
<footer class="nav-footer fixed-sidebar-footer">
<a href="https://akka.io"><img class="logo" src="images/akka-alpakka-reverse.svg"></a>

</footer>
</aside>

<main class="fixed-shift-for-large expanded row">
<section class="site-content small-12 column">

<article class="page-content row">
<div class="small-12 large-9 column" id="docs">
<h1><a href="#elasticsearch" name="elasticsearch" class="anchor"><span class="anchor-link"></span></a>Elasticsearch</h1>
<p>The Alpakka Elasticsearch connector provides Akka Streams integration for Elasticsearch.</p>
<p>For more information about Elasticsearch, please visit the <a href="https://www.elastic.co/guide/index.html">Elasticsearch documentation</a>.</p>
<h3><a href="#reported-issues" name="reported-issues" class="anchor"><span class="anchor-link"></span></a>Reported issues</h3>
<p><a href="https://github.com/akka/alpakka/labels/p%3Aelasticsearch">Tagged issues at Github</a></p>
<h2><a href="#artifacts" name="artifacts" class="anchor"><span class="anchor-link"></span></a>Artifacts</h2><dl class="dependency"><dt>sbt</dt><dd><pre class="prettyprint"><code class="language-scala">libraryDependencies += "com.lightbend.akka" %% "akka-stream-alpakka-elasticsearch" % "1.0-M1"</code></pre></dd><dt>Maven</dt><dd><pre class="prettyprint"><code class="language-xml">&lt;dependency&gt;
  &lt;groupId&gt;com.lightbend.akka&lt;/groupId&gt;
  &lt;artifactId&gt;akka-stream-alpakka-elasticsearch_2.12&lt;/artifactId&gt;
  &lt;version&gt;1.0-M1&lt;/version&gt;
&lt;/dependency&gt;</code></pre></dd><dt>Gradle</dt><dd><pre class="prettyprint"><code class="language-gradle">dependencies {
  compile group: 'com.lightbend.akka', name: 'akka-stream-alpakka-elasticsearch_2.12', version: '1.0-M1'
}</code></pre></dd></dl>
<h2><a href="#set-up-rest-client" name="set-up-rest-client" class="anchor"><span class="anchor-link"></span></a>Set up REST client</h2>
<p>Sources, Flows and Sinks provided by this connector need a prepared <code>org.elasticsearch.client.RestClient</code> to access to Elasticsearch.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">import org.apache.http.HttpHost
import org.elasticsearch.client.RestClient

implicit val client: RestClient = RestClient.builder(new HttpHost(&quot;localhost&quot;, 9201)).build()</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L33-L36" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">import akka.stream.alpakka.elasticsearch.*;
import akka.stream.alpakka.elasticsearch.javadsl.*;

import org.elasticsearch.client.RestClient;
import org.apache.http.HttpHost;

client = RestClient.builder(new HttpHost(&quot;localhost&quot;, 9201)).build();</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L12-L71" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h2><a href="#elasticsearch-as-source-and-sink" name="elasticsearch-as-source-and-sink" class="anchor"><span class="anchor-link"></span></a>Elasticsearch as Source and Sink</h2>
<p>Now we can stream messages from or to Elasticsearch by providing the <code>RestClient</code> to the <span class="group-scala"><a href="https://doc.akka.io/api/alpakka/1.0-M1/akka/stream/alpakka/elasticsearch/scaladsl/ElasticsearchSource$.html">ElasticsearchSource</a></span> <span class="group-java"><a href="https://doc.akka.io/api/alpakka/1.0-M1/akka/stream/alpakka/elasticsearch/javadsl/ElasticsearchSource$.html">ElasticsearchSource</a></span> or the <span class="group-scala"><a href="https://doc.akka.io/api/alpakka/1.0-M1/akka/stream/alpakka/elasticsearch/scaladsl/ElasticsearchSink$.html">ElasticsearchSink</a>.</span> <span class="group-java"><a href="https://doc.akka.io/api/alpakka/1.0-M1/akka/stream/alpakka/elasticsearch/javadsl/ElasticsearchSink$.html">ElasticsearchSink</a>.</span></p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">import spray.json._
import DefaultJsonProtocol._

case class Book(title: String)

implicit val format: JsonFormat[Book] = jsonFormat1(Book)</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L40-L45" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">public static class Book {
  public String title;

  public Book() {}

  public Book(String title) {
    this.title = title;
  }
}</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L47-L55" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#with-typed-source" name="with-typed-source" class="anchor"><span class="anchor-link"></span></a>With typed source</h3>
<p>Use <code>ElasticsearchSource.typed</code> and <code>ElasticsearchSink.create</code> to create source and sink. <span class="group-scala">The data is converted to and from JSON by Spray JSON.</span> <span class="group-java">The data is converted to and from JSON by Jackson&rsquo;s ObjectMapper.</span></p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val f1 = ElasticsearchSource
  .typed[Book](
    indexName = &quot;source&quot;,
    typeName = &quot;_doc&quot;,
    query = &quot;&quot;&quot;{&quot;match_all&quot;: {}}&quot;&quot;&quot;
  )
  .map { message: ReadResult[Book] =&gt;
    WriteMessage.createIndexMessage(message.id, message.source)
  }
  .runWith(
    ElasticsearchSink.create[Book](
      indexName = &quot;sink2&quot;,
      typeName = &quot;_doc&quot;
    )
  )</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L174-L188" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">ElasticsearchSourceSettings sourceSettings = ElasticsearchSourceSettings.create();
ElasticsearchWriteSettings sinkSettings = ElasticsearchWriteSettings.create();

Source&lt;ReadResult&lt;Book&gt;, NotUsed&gt; source =
    ElasticsearchSource.typed(
        &quot;source&quot;, &quot;_doc&quot;, &quot;{\&quot;match_all\&quot;: {}}&quot;, sourceSettings, client, Book.class);
CompletionStage&lt;Done&gt; f1 =
    source
        .map(m -&gt; WriteMessage.createIndexMessage(m.id(), m.source()))
        .runWith(
            ElasticsearchSink.create(&quot;sink2&quot;, &quot;_doc&quot;, sinkSettings, client, new ObjectMapper()),
            materializer);</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L176-L187" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#with-json-source" name="with-json-source" class="anchor"><span class="anchor-link"></span></a>With JSON source</h3>
<p>Use <code>ElasticsearchSource.create</code> and <code>ElasticsearchSink.create</code> to create source and sink.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val f1 = ElasticsearchSource
  .create(
    indexName = &quot;source&quot;,
    typeName = &quot;_doc&quot;,
    query = &quot;&quot;&quot;{&quot;match_all&quot;: {}}&quot;&quot;&quot;
  )
  .map { message: ReadResult[spray.json.JsObject] =&gt;
    val book: Book = jsonReader[Book].read(message.source)
    WriteMessage.createIndexMessage(message.id, book)
  }
  .runWith(
    ElasticsearchSink.create[Book](
      indexName = &quot;sink2&quot;,
      typeName = &quot;_doc&quot;
    )
  )</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L122-L137" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">ElasticsearchSourceSettings sourceSettings = ElasticsearchSourceSettings.create();
ElasticsearchWriteSettings sinkSettings = ElasticsearchWriteSettings.create();

Source&lt;ReadResult&lt;Map&lt;String, Object&gt;&gt;, NotUsed&gt; source =
    ElasticsearchSource.create(&quot;source&quot;, &quot;_doc&quot;, &quot;{\&quot;match_all\&quot;: {}}&quot;, sourceSettings, client);
CompletionStage&lt;Done&gt; f1 =
    source
        .map(m -&gt; WriteMessage.createIndexMessage(m.id(), m.source()))
        .runWith(
            ElasticsearchSink.create(&quot;sink1&quot;, &quot;_doc&quot;, sinkSettings, client, new ObjectMapper()),
            materializer);</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L128-L138" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#writing-to-elasticsearch" name="writing-to-elasticsearch" class="anchor"><span class="anchor-link"></span></a>Writing to Elasticsearch</h3>
<p>In the above examples, <code>WriteMessage</code> is used as the input to <code>ElasticsearchSink</code> and <code>ElasticsearchFlow</code>. This means requesting <code>index</code> operation to Elasticsearch. It&rsquo;s possible to request other operations using following message types:</p>
<table>
  <thead>
    <tr>
      <th>Message factory </th>
      <th>Description </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>WriteMessage.createIndexMessage </td>
      <td>Create a new document. If <code>id</code> is specified and it already exists, do nothing. </td>
    </tr>
    <tr>
      <td>WriteMessage.createUpdateMessage </td>
      <td>Update an existing document. If there is no document with the specified <code>id</code>, do nothing. </td>
    </tr>
    <tr>
      <td>WriteMessage.createUpsertMessage </td>
      <td>Update an existing document. If there is no document with the specified <code>id</code>, create a new document. </td>
    </tr>
    <tr>
      <td>WriteMessage.createDeleteMessage </td>
      <td>Delete an existing document. If there is no document with the specified <code>id</code>, do nothing. </td>
    </tr>
  </tbody>
</table>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">// Create, update, upsert and delete documents in sink8/_doc
val requests = List[WriteMessage[Book, NotUsed]](
  WriteMessage.createIndexMessage(id = &quot;00001&quot;, source = Book(&quot;Book 1&quot;)),
  WriteMessage.createUpsertMessage(id = &quot;00002&quot;, source = Book(&quot;Book 2&quot;)),
  WriteMessage.createUpsertMessage(id = &quot;00003&quot;, source = Book(&quot;Book 3&quot;)),
  WriteMessage.createUpdateMessage(id = &quot;00004&quot;, source = Book(&quot;Book 4&quot;)),
  WriteMessage.createDeleteMessage(id = &quot;00002&quot;)
)

val f1 = Source(requests)
  .via(
    ElasticsearchFlow.create[Book](
      &quot;sink8&quot;,
      &quot;_doc&quot;
    )
  )
  .runWith(Sink.seq)</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L556-L572" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">// Create, update, upsert and delete documents in sink8/book
List&lt;WriteMessage&lt;Book, NotUsed&gt;&gt; requests =
    Arrays.asList(
        WriteMessage.createIndexMessage(&quot;00001&quot;, new Book(&quot;Book 1&quot;)),
        WriteMessage.createUpsertMessage(&quot;00002&quot;, new Book(&quot;Book 2&quot;)),
        WriteMessage.createUpsertMessage(&quot;00003&quot;, new Book(&quot;Book 3&quot;)),
        WriteMessage.createUpdateMessage(&quot;00004&quot;, new Book(&quot;Book 4&quot;)),
        WriteMessage.createDeleteMessage(&quot;00002&quot;));

Source.from(requests)
    .via(
        ElasticsearchFlow.create(
            &quot;sink8&quot;, &quot;_doc&quot;, ElasticsearchWriteSettings.create(), client, new ObjectMapper()))
    .runWith(Sink.seq(), materializer)
    .toCompletableFuture()
    .get();</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L283-L298" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#source-configuration" name="source-configuration" class="anchor"><span class="anchor-link"></span></a>Source configuration</h3>
<p>We can configure the source by <code>ElasticsearchSourceSettings</code>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val sourceSettings = ElasticsearchSourceSettings().withBufferSize(10)</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L107" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">ElasticsearchSourceSettings sourceSettings =
    ElasticsearchSourceSettings.create().withBufferSize(10);</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L112-L113" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<table>
  <thead>
    <tr>
      <th>Parameter </th>
      <th>Default </th>
      <th>Description </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bufferSize </td>
      <td>10 </td>
      <td><code>ElasticsearchSource</code> retrieves messages from Elasticsearch by scroll scan. This buffer size is used as the scroll size. </td>
    </tr>
    <tr>
      <td>includeDocumentVersion </td>
      <td>false </td>
      <td>Tell Elasticsearch to return the documents <code>_version</code> property with the search results. See <a href="http://nocf-www.elastic.co/guide/en/elasticsearch/reference/current/search-request-version.html">Version</a> and <a href="https://www.elastic.co/guide/en/elasticsearch/guide/current/optimistic-concurrency-control.html">Optimistic Concurrenct Control</a> to know about this property. </td>
    </tr>
  </tbody>
</table>
<h3><a href="#sink-and-flow-configuration" name="sink-and-flow-configuration" class="anchor"><span class="anchor-link"></span></a>Sink and flow configuration</h3>
<p>Sinks and flows are configured with <code>ElasticsearchWriteSettings</code>.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val sinkSettings =
  ElasticsearchWriteSettings()
    .withBufferSize(10)
    .withVersionType(&quot;internal&quot;)
    .withRetryLogic(RetryAtFixedRate(maxRetries = 5, retryInterval = 1.second))</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L110-L114" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">ElasticsearchWriteSettings settings =
    ElasticsearchWriteSettings.create()
        .withBufferSize(10)
        .withVersionType(&quot;internal&quot;)
        .withRetryLogic(RetryAtFixedRate.create(5, Duration.ofSeconds(1)));</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L116-L120" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<table>
  <thead>
    <tr>
      <th>Parameter </th>
      <th>Default </th>
      <th>Description </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>bufferSize </td>
      <td>10 </td>
      <td><code>ElasticsearchSink</code> puts messages by one bulk request per messages of this buffer size. </td>
    </tr>
    <tr>
      <td>versionType </td>
      <td>None </td>
      <td>If set, <code>ElasticsearchSink</code> uses the chosen versionType to index documents. See <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/docs-index_.html#_version_types">Version types</a> for accepted settings. </td>
    </tr>
    <tr>
      <td>retryLogic </td>
      <td>No retries </td>
      <td>See below </td>
    </tr>
  </tbody>
</table>
<p>A bulk request might fail partially for some reason. To retry failed writes to Elasticsearch, a <code>RetryLogic</code> can be specified. The provided implementation is <code>RetryAtFixedRate</code>.</p><div class="callout warning "><div class="callout-title">Warning</div>
<p>If using retries, you will receive messages out of order downstream in cases where elastic returns an error one some of the documents in a bulk request.</p></div>
<table>
  <thead>
    <tr>
      <th>Parameter </th>
      <th>Description </th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>maxRetries </td>
      <td>The stage fails, if it gets this number of consecutive failures. </td>
    </tr>
    <tr>
      <td>retryInterval </td>
      <td>Failing writes are retried after this duration. </td>
    </tr>
  </tbody>
</table>
<h2><a href="#elasticsearch-as-flow" name="elasticsearch-as-flow" class="anchor"><span class="anchor-link"></span></a>Elasticsearch as Flow</h2>
<p>You can also build flow stages with <span class="group-scala"><a href="https://doc.akka.io/api/alpakka/1.0-M1/akka/stream/alpakka/elasticsearch/scaladsl/ElasticsearchFlow$.html">ElasticsearchFlow</a>.</span> <span class="group-java"><a href="https://doc.akka.io/api/alpakka/1.0-M1/akka/stream/alpakka/elasticsearch/javadsl/ElasticsearchFlow$.html">ElasticsearchFlow</a>.</span> The API is similar to creating Sinks.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val f1 = ElasticsearchSource
  .typed[Book](
    indexName = &quot;source&quot;,
    typeName = &quot;_doc&quot;,
    query = &quot;&quot;&quot;{&quot;match_all&quot;: {}}&quot;&quot;&quot;
  )
  .map { message: ReadResult[Book] =&gt;
    WriteMessage.createIndexMessage(message.id, message.source)
  }
  .via(
    ElasticsearchFlow.create[Book](
      indexName = &quot;sink3&quot;,
      typeName = &quot;_doc&quot;
    )
  )
  .runWith(Sink.seq)</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L225-L240" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">CompletionStage&lt;List&lt;List&lt;WriteResult&lt;Book, NotUsed&gt;&gt;&gt;&gt; f1 =
    ElasticsearchSource.typed(
            &quot;source&quot;,
            &quot;_doc&quot;,
            &quot;{\&quot;match_all\&quot;: {}}&quot;,
            ElasticsearchSourceSettings.create().withBufferSize(5),
            client,
            Book.class)
        .map(m -&gt; WriteMessage.createIndexMessage(m.id(), m.source()))
        .via(
            ElasticsearchFlow.create(
                &quot;sink3&quot;,
                &quot;_doc&quot;,
                ElasticsearchWriteSettings.create().withBufferSize(5),
                client,
                new ObjectMapper()))
        .runWith(Sink.seq(), materializer);</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L226-L242" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#passing-data-through-elasticsearchflow" name="passing-data-through-elasticsearchflow" class="anchor"><span class="anchor-link"></span></a>Passing data through ElasticsearchFlow</h3>
<p>When streaming documents from Kafka, you might want to commit to Kafka <strong>AFTER</strong> the document has been written to Elastic.</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">// We&#39;re going to pretend we got messages from kafka.
// After we&#39;ve written them to Elastic, we want
// to commit the offset to Kafka

case class KafkaOffset(offset: Int)
case class KafkaMessage(book: Book, offset: KafkaOffset)

val messagesFromKafka = List(
  KafkaMessage(Book(&quot;Book 1&quot;), KafkaOffset(0)),
  KafkaMessage(Book(&quot;Book 2&quot;), KafkaOffset(1)),
  KafkaMessage(Book(&quot;Book 3&quot;), KafkaOffset(2))
)

var committedOffsets = List[KafkaOffset]()

def commitToKafka(offset: KafkaOffset): Unit =
  committedOffsets = committedOffsets :+ offset

val f1 = Source(messagesFromKafka) // Assume we get this from Kafka
  .map { kafkaMessage: KafkaMessage =&gt;
    val book = kafkaMessage.book
    val id = book.title
    println(&quot;title: &quot; + book.title)

    // Transform message so that we can write to elastic
    WriteMessage.createIndexMessage(id, book).withPassThrough(kafkaMessage.offset)
  }
  .via( // write to elastic
    ElasticsearchFlow.createWithPassThrough[Book, KafkaOffset](
      indexName = &quot;sink6&quot;,
      typeName = &quot;_doc&quot;
    )
  )
  .map { messageResults =&gt;
    messageResults.foreach { result =&gt;
      if (!result.success) throw new Exception(&quot;Failed to write message to elastic&quot;)
      // Commit to kafka
      commitToKafka(result.message.passThrough)
    }
  }
  .runWith(Sink.seq)

Await.ready(f1, Duration.Inf)</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L393-L435" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">// We&#39;re going to pretend we got messages from kafka.
// After we&#39;ve written them to Elastic, we want
// to commit the offset to Kafka

List&lt;KafkaMessage&gt; messagesFromKafka =
    Arrays.asList(
        new KafkaMessage(new Book(&quot;Book 1&quot;), new KafkaOffset(0)),
        new KafkaMessage(new Book(&quot;Book 2&quot;), new KafkaOffset(1)),
        new KafkaMessage(new Book(&quot;Book 3&quot;), new KafkaOffset(2)));

final KafkaCommitter kafkaCommitter = new KafkaCommitter();

Source.from(messagesFromKafka) // Assume we get this from Kafka
    .map(
        kafkaMessage -&gt; {
          Book book = kafkaMessage.book;
          String id = book.title;

          // Transform message so that we can write to elastic
          return WriteMessage.createIndexMessage(id, book).withPassThrough(kafkaMessage.offset);
        })
    .via( // write to elastic
        ElasticsearchFlow.createWithPassThrough(
            &quot;sink6&quot;,
            &quot;_doc&quot;,
            ElasticsearchWriteSettings.create().withBufferSize(5),
            client,
            new ObjectMapper()))
    .map(
        messageResults -&gt; {
          messageResults
              .stream()
              .forEach(
                  result -&gt; {
                    if (!result.success())
                      throw new RuntimeException(&quot;Failed to write message to elastic&quot;);
                    // Commit to kafka
                    kafkaCommitter.commit(result.message().passThrough());
                  });
          return NotUsed.getInstance();
        })
    .runWith(Sink.seq(), materializer) // Run it
    .toCompletableFuture()
    .get(); // Wait for it to complete
</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L325-L369" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#specifying-custom-index-name-for-every-document" name="specifying-custom-index-name-for-every-document" class="anchor"><span class="anchor-link"></span></a>Specifying custom index-name for every document</h3>
<p>When working with index-patterns using wildcards, you might need to specify a custom index-name for each document:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val customIndexName = &quot;custom-index&quot;

val f1 = ElasticsearchSource
  .typed[Book](
    indexName = &quot;source&quot;,
    typeName = &quot;_doc&quot;,
    query = &quot;&quot;&quot;{&quot;match_all&quot;: {}}&quot;&quot;&quot;
  )
  .map { message: ReadResult[Book] =&gt;
    WriteMessage
      .createIndexMessage(message.id, message.source)
      .withIndexName(customIndexName) // Setting the index-name to use for this document
  }
  .runWith(
    ElasticsearchSink.create[Book](
      indexName = &quot;this-is-not-the-index-we-are-using&quot;,
      typeName = &quot;_doc&quot;
    )
  )</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L764-L782" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">WriteMessage msg = WriteMessage.createIndexMessage(doc).withIndexName(&quot;my-index&quot;);</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L631" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#specifying-custom-metadata-for-every-document" name="specifying-custom-metadata-for-every-document" class="anchor"><span class="anchor-link"></span></a>Specifying custom metadata for every document</h3>
<p>In some cases you might want to specify custom metadata per document you are inserting, for example a <code>pipeline</code>, this can be done like so:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">val msg = WriteMessage
  .createIndexMessage(doc)
  .withCustomMetadata(Map(&quot;pipeline&quot; -&gt; &quot;myPipeline&quot;))</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L906-L908" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">Map&lt;String, String&gt; metadata = new HashMap&lt;&gt;();
metadata.put(&quot;pipeline&quot;, &quot;myPipeline&quot;);
WriteMessage msgWithMetadata =
    WriteMessage.createIndexMessage(doc).withCustomMetadata(metadata);</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L635-L638" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
<h3><a href="#more-custom-searching" name="more-custom-searching" class="anchor"><span class="anchor-link"></span></a>More custom searching</h3>
<p>The easiest way of using ElasticSearch-source, is to just specify the query-param. Sometimes you need more control, like specifying which fields to return and so on. In such cases you can instead use &lsquo;searchParams&rsquo; instead:</p>
<dl>
  <dt>Scala</dt>
  <dd>
  <pre class="prettyprint"><code class="language-scala">case class TestDoc(id: String, a: String, b: Option[String], c: String)
// Search for docs and ask elastic to only return some fields

val f3 = ElasticsearchSource
  .typed[TestDoc](indexName,
                  Some(typeName),
                  searchParams = Map(
                    &quot;query&quot; -&gt; &quot;&quot;&quot; {&quot;match_all&quot;: {}} &quot;&quot;&quot;,
                    &quot;_source&quot; -&gt; &quot;&quot;&quot; [&quot;id&quot;, &quot;a&quot;, &quot;c&quot;] &quot;&quot;&quot;
                  ),
                  ElasticsearchSourceSettings.Default)
  .map { message =&gt;
    message.source
  }
  .runWith(Sink.seq)
</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/scala/docs/scaladsl/ElasticsearchSpec.scala#L845-L894" class="snippet-full-source github">Full source at GitHub</a></dd>
  <dt>Java</dt>
  <dd>
  <pre class="prettyprint"><code class="language-java">public static class TestDoc {
  public String id;
  public String a;
  public String b;
  public String c;

}
  // Search for docs and ask elastic to only return some fields

  Map&lt;String, String&gt; searchParams = new HashMap&lt;&gt;();
  searchParams.put(&quot;query&quot;, &quot;{\&quot;match_all\&quot;: {}}&quot;);
  searchParams.put(&quot;_source&quot;, &quot;[\&quot;id\&quot;, \&quot;a\&quot;, \&quot;c\&quot;]&quot;);

  List&lt;TestDoc&gt; result =
      ElasticsearchSource.&lt;TestDoc&gt;typed(
              indexName,
              typeName,
              searchParams, // &lt;-- Using searchParams
              ElasticsearchSourceSettings.create(),
              client,
              TestDoc.class,
              new ObjectMapper())
          .map(
              o -&gt; {
                return o.source(); // These documents will only have property id, a and c (not b)
              })
          .runWith(Sink.seq(), materializer)
          .toCompletableFuture()
          .get();</code></pre><a href="https://github.com/akka/alpakka/tree/v1.0-M1/elasticsearch/src/test/java/docs/javadsl/ElasticsearchTest.java#L514-L583" class="snippet-full-source github">Full source at GitHub</a></dd>
</dl>
</div>
</article>

<div class="row">
<div class="small-12 large-9 column">
<section class="nav-prev-next row">
<div class="nav-prev small-6 column">
<a href="external/couchbase.html"><i class="icon-prev"></i> <span class="link-prev">Couchbase</span></a>
</div>
<div class="nav-next small-6 column clearfix">
<a class="float-right" href="external/eventuate.html">Eventuate <i class="icon-next"></i></a>
</div>
</section>
</div>
</div>

<div class="source-github row">
Found an error in this documentation? The source code for this page can be found <a href="https://github.com/akka/alpakka/tree/v1.0-M1/docs/src/main/paradox/elasticsearch.md">here</a>.
Please feel free to edit and contribute a pull request.
</div>


<footer class="page-footer row clearfix">
<img class="akka-icon float-left show-for-medium" src="images/akka-icon.svg">
<section class="copyright">
<div>Alpakka is Open Source and available under the Apache 2 License.</div>
<p class="legal">
&copy; 2011-2019 <a href="https://www.lightbend.com" target="_blank">Lightbend, Inc.</a> | 
<a href="https://www.lightbend.com/legal/licenses" target="_blank">Licenses</a> | 
<a href="https://www.lightbend.com/legal/terms" target="_blank">Terms</a> | 
<a href="https://www.lightbend.com/legal/privacy" target="_blank">Privacy Policy</a> | 
<a href="https://akka.io/cookie/" target="_blank">Cookie Listing</a> | 
<a class="optanon-toggle-display">Cookie Settings</a>
</p>
</section>
</footer>

</section>
</main>

<script type="text/javascript" src="js/scrollsneak.js"></script>
<script type="text/javascript">jQuery(document).foundation();</script>
<script type="text/javascript" src="js/groups.js"></script>
<script type="text/javascript" src="js/page.js"></script>
<script type="text/javascript" src="js/magellan.js"></script>

<style type="text/css">@import "lib/prettify/prettify.css";</style>
<script type="text/javascript" src="lib/prettify/prettify.js"></script>
<script type="text/javascript" src="lib/prettify/lang-scala.js"></script>
<script type="text/javascript">jQuery(function(){window.prettyPrint && prettyPrint()});</script>

<script type="text/javascript" src="assets/js/warnOldVersion.js"></script>
<script type="text/javascript">jQuery(function(jq){initOldVersionWarnings(jq, '1.0-M1', 'https://doc.akka.io/docs/alpakka/current/')});</script>


</body>
</html>
